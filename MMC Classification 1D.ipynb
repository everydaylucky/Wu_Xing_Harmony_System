{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ea7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32e9d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''--------- 1. Data Manipulation ---------'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "'''--------- 2. Data Preprocessing ---------'''\n",
    "from sklearn.preprocessing import LabelEncoder #Encode Non-numeric Var\n",
    "from sklearn.preprocessing import MinMaxScaler # Feature Scaling\n",
    "from sklearn.model_selection import train_test_split #Train Test Validation Split\n",
    "'''--------- 3. Data Visualization ---------'''\n",
    "import matplotlib.pyplot as plt\n",
    "'''--------- 4. Model Training ---------'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "'''--------- 5. Model Evluation ---------'''\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e803fa86",
   "metadata": {},
   "source": [
    "### Dataset 2\n",
    "**About dataset**\n",
    "- 400 ~30 second audio clips gathered from erbal and non-verbal music from different genres of Turkish music\n",
    "- Annotated into 4 quadrants based on valance and arousal according to Russell's model.\n",
    "- Audios are organized in 4 categories - Happy, Sad, Angry, Relax\n",
    "- Equally stratified dataset with each classes 100 songs\n",
    "\n",
    "**Acknowledgements**<br>\n",
    "source:https://www.kaggle.com/datasets/blaler/turkish-music-emotion-dataset\n",
    "\n",
    "**If you use it, please cite the following article(s):**<br>\n",
    "Bilal Er, M., & Aydilek, I. B. (2019). Music emotion recognition by using chroma spectrogram and deep visual features. Journal of Computational Intelligent Systems, 12(2), 1622–1634. International Journal of Computational Intelligence Systems, DOI: [Web Link] https://doi.org/10.2991/ijcis.d.191216.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "926d715e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>scale</th>\n",
       "      <th>key</th>\n",
       "      <th>tempo</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>chroma_mean</th>\n",
       "      <th>chroma_var</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_var_16</th>\n",
       "      <th>mfcc_mean_17</th>\n",
       "      <th>mfcc_var_17</th>\n",
       "      <th>mfcc_mean_18</th>\n",
       "      <th>mfcc_var_18</th>\n",
       "      <th>mfcc_mean_19</th>\n",
       "      <th>mfcc_var_19</th>\n",
       "      <th>mfcc_mean_20</th>\n",
       "      <th>mfcc_var_20</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dataset25/angry\\adanali.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>123.046875</td>\n",
       "      <td>0.127807</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.425633</td>\n",
       "      <td>0.086968</td>\n",
       "      <td>2105.443209</td>\n",
       "      <td>...</td>\n",
       "      <td>25.576569</td>\n",
       "      <td>-0.016703</td>\n",
       "      <td>25.722586</td>\n",
       "      <td>2.201685</td>\n",
       "      <td>22.017639</td>\n",
       "      <td>-1.431247</td>\n",
       "      <td>28.176865</td>\n",
       "      <td>-1.176676</td>\n",
       "      <td>20.433548</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dataset25/angry\\adanli2.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>D</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>0.128979</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.420374</td>\n",
       "      <td>0.074643</td>\n",
       "      <td>1000.227413</td>\n",
       "      <td>...</td>\n",
       "      <td>31.241302</td>\n",
       "      <td>-1.229543</td>\n",
       "      <td>35.786133</td>\n",
       "      <td>1.883627</td>\n",
       "      <td>39.709461</td>\n",
       "      <td>-1.683304</td>\n",
       "      <td>23.725592</td>\n",
       "      <td>0.727901</td>\n",
       "      <td>31.463917</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dataset25/angry\\adini_Feriha_koydum.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>B</td>\n",
       "      <td>135.999178</td>\n",
       "      <td>0.075881</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.394874</td>\n",
       "      <td>0.077484</td>\n",
       "      <td>1843.214438</td>\n",
       "      <td>...</td>\n",
       "      <td>21.989450</td>\n",
       "      <td>-4.449482</td>\n",
       "      <td>21.054407</td>\n",
       "      <td>2.660801</td>\n",
       "      <td>17.766880</td>\n",
       "      <td>-6.313827</td>\n",
       "      <td>22.356897</td>\n",
       "      <td>-0.020581</td>\n",
       "      <td>24.623358</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Dataset25/angry\\aksiyon_gerilim.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>151.999081</td>\n",
       "      <td>0.381500</td>\n",
       "      <td>0.017487</td>\n",
       "      <td>0.511473</td>\n",
       "      <td>0.086292</td>\n",
       "      <td>3106.736263</td>\n",
       "      <td>...</td>\n",
       "      <td>104.935028</td>\n",
       "      <td>8.481378</td>\n",
       "      <td>100.465881</td>\n",
       "      <td>9.546239</td>\n",
       "      <td>68.734306</td>\n",
       "      <td>1.664868</td>\n",
       "      <td>43.591545</td>\n",
       "      <td>3.473514</td>\n",
       "      <td>49.230965</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dataset25/angry\\araf_zaman_dizi_muzigi.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>123.046875</td>\n",
       "      <td>0.202227</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.377677</td>\n",
       "      <td>0.072657</td>\n",
       "      <td>1589.239435</td>\n",
       "      <td>...</td>\n",
       "      <td>23.533150</td>\n",
       "      <td>-1.828742</td>\n",
       "      <td>26.620646</td>\n",
       "      <td>4.007443</td>\n",
       "      <td>26.666252</td>\n",
       "      <td>-0.988054</td>\n",
       "      <td>23.702585</td>\n",
       "      <td>4.246670</td>\n",
       "      <td>26.136576</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>Dataset25/sad\\yazimi_kisa_cevirdin_muhlis_berb...</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>151.999081</td>\n",
       "      <td>0.097105</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.293956</td>\n",
       "      <td>0.088207</td>\n",
       "      <td>1997.276683</td>\n",
       "      <td>...</td>\n",
       "      <td>52.399574</td>\n",
       "      <td>-18.951229</td>\n",
       "      <td>71.105469</td>\n",
       "      <td>-6.146902</td>\n",
       "      <td>61.915462</td>\n",
       "      <td>-16.994026</td>\n",
       "      <td>55.398777</td>\n",
       "      <td>-14.183487</td>\n",
       "      <td>64.577766</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>Dataset25/sad\\yemen_turkusu.mp3</td>\n",
       "      <td>minor</td>\n",
       "      <td>G#</td>\n",
       "      <td>89.102909</td>\n",
       "      <td>0.083837</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.272150</td>\n",
       "      <td>0.084929</td>\n",
       "      <td>1331.011559</td>\n",
       "      <td>...</td>\n",
       "      <td>37.900272</td>\n",
       "      <td>-11.959914</td>\n",
       "      <td>43.625828</td>\n",
       "      <td>-5.335443</td>\n",
       "      <td>40.348934</td>\n",
       "      <td>-10.943409</td>\n",
       "      <td>37.393105</td>\n",
       "      <td>-15.349642</td>\n",
       "      <td>56.387405</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>Dataset25/sad\\yol_ver_daglar_arif_sag.mp3</td>\n",
       "      <td>major</td>\n",
       "      <td>E</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>0.076661</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.237400</td>\n",
       "      <td>0.089330</td>\n",
       "      <td>1681.161502</td>\n",
       "      <td>...</td>\n",
       "      <td>46.293671</td>\n",
       "      <td>-5.706831</td>\n",
       "      <td>39.779736</td>\n",
       "      <td>-3.286500</td>\n",
       "      <td>47.729607</td>\n",
       "      <td>1.990399</td>\n",
       "      <td>70.187508</td>\n",
       "      <td>5.452133</td>\n",
       "      <td>70.151512</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>Dataset25/sad\\yuce_dag_basinda_yanar_bir_isik_...</td>\n",
       "      <td>major</td>\n",
       "      <td>A</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>0.071242</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.263051</td>\n",
       "      <td>0.092084</td>\n",
       "      <td>2075.571372</td>\n",
       "      <td>...</td>\n",
       "      <td>45.630795</td>\n",
       "      <td>-16.532892</td>\n",
       "      <td>45.669136</td>\n",
       "      <td>-11.235711</td>\n",
       "      <td>48.995541</td>\n",
       "      <td>-15.730806</td>\n",
       "      <td>54.862488</td>\n",
       "      <td>-15.158969</td>\n",
       "      <td>68.118652</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>Dataset25/sad\\zuluf_dokmus_yuze_feyzi_yagci.mp3</td>\n",
       "      <td>minor</td>\n",
       "      <td>F#</td>\n",
       "      <td>99.384014</td>\n",
       "      <td>0.054451</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.226404</td>\n",
       "      <td>0.087524</td>\n",
       "      <td>1857.736709</td>\n",
       "      <td>...</td>\n",
       "      <td>46.131039</td>\n",
       "      <td>-5.977736</td>\n",
       "      <td>78.518753</td>\n",
       "      <td>2.433602</td>\n",
       "      <td>74.181198</td>\n",
       "      <td>-2.228050</td>\n",
       "      <td>73.092354</td>\n",
       "      <td>-5.549421</td>\n",
       "      <td>73.862915</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               file  scale key  \\\n",
       "0             0                        Dataset25/angry\\adanali.mp3  major   A   \n",
       "1             1                        Dataset25/angry\\adanli2.mp3  major   D   \n",
       "2             2            Dataset25/angry\\adini_Feriha_koydum.mp3  major   B   \n",
       "3             3                Dataset25/angry\\aksiyon_gerilim.mp3  major   A   \n",
       "4             4         Dataset25/angry\\araf_zaman_dizi_muzigi.mp3  major   A   \n",
       "..          ...                                                ...    ...  ..   \n",
       "495         495  Dataset25/sad\\yazimi_kisa_cevirdin_muhlis_berb...  major   A   \n",
       "496         496                    Dataset25/sad\\yemen_turkusu.mp3  minor  G#   \n",
       "497         497          Dataset25/sad\\yol_ver_daglar_arif_sag.mp3  major   E   \n",
       "498         498  Dataset25/sad\\yuce_dag_basinda_yanar_bir_isik_...  major   A   \n",
       "499         499    Dataset25/sad\\zuluf_dokmus_yuze_feyzi_yagci.mp3  minor  F#   \n",
       "\n",
       "          tempo  rms_mean   rms_var  chroma_mean  chroma_var  centroid_mean  \\\n",
       "0    123.046875  0.127807  0.002374     0.425633    0.086968    2105.443209   \n",
       "1     99.384014  0.128979  0.002421     0.420374    0.074643    1000.227413   \n",
       "2    135.999178  0.075881  0.000777     0.394874    0.077484    1843.214438   \n",
       "3    151.999081  0.381500  0.017487     0.511473    0.086292    3106.736263   \n",
       "4    123.046875  0.202227  0.001329     0.377677    0.072657    1589.239435   \n",
       "..          ...       ...       ...          ...         ...            ...   \n",
       "495  151.999081  0.097105  0.000582     0.293956    0.088207    1997.276683   \n",
       "496   89.102909  0.083837  0.001618     0.272150    0.084929    1331.011559   \n",
       "497   99.384014  0.076661  0.000290     0.237400    0.089330    1681.161502   \n",
       "498   99.384014  0.071242  0.001089     0.263051    0.092084    2075.571372   \n",
       "499   99.384014  0.054451  0.000717     0.226404    0.087524    1857.736709   \n",
       "\n",
       "     ...  mfcc_var_16  mfcc_mean_17  mfcc_var_17  mfcc_mean_18  mfcc_var_18  \\\n",
       "0    ...    25.576569     -0.016703    25.722586      2.201685    22.017639   \n",
       "1    ...    31.241302     -1.229543    35.786133      1.883627    39.709461   \n",
       "2    ...    21.989450     -4.449482    21.054407      2.660801    17.766880   \n",
       "3    ...   104.935028      8.481378   100.465881      9.546239    68.734306   \n",
       "4    ...    23.533150     -1.828742    26.620646      4.007443    26.666252   \n",
       "..   ...          ...           ...          ...           ...          ...   \n",
       "495  ...    52.399574    -18.951229    71.105469     -6.146902    61.915462   \n",
       "496  ...    37.900272    -11.959914    43.625828     -5.335443    40.348934   \n",
       "497  ...    46.293671     -5.706831    39.779736     -3.286500    47.729607   \n",
       "498  ...    45.630795    -16.532892    45.669136    -11.235711    48.995541   \n",
       "499  ...    46.131039     -5.977736    78.518753      2.433602    74.181198   \n",
       "\n",
       "     mfcc_mean_19  mfcc_var_19  mfcc_mean_20  mfcc_var_20   mood  \n",
       "0       -1.431247    28.176865     -1.176676    20.433548  angry  \n",
       "1       -1.683304    23.725592      0.727901    31.463917  angry  \n",
       "2       -6.313827    22.356897     -0.020581    24.623358  angry  \n",
       "3        1.664868    43.591545      3.473514    49.230965  angry  \n",
       "4       -0.988054    23.702585      4.246670    26.136576  angry  \n",
       "..            ...          ...           ...          ...    ...  \n",
       "495    -16.994026    55.398777    -14.183487    64.577766    sad  \n",
       "496    -10.943409    37.393105    -15.349642    56.387405    sad  \n",
       "497      1.990399    70.187508      5.452133    70.151512    sad  \n",
       "498    -15.730806    54.862488    -15.158969    68.118652    sad  \n",
       "499     -2.228050    73.092354     -5.549421    73.862915    sad  \n",
       "\n",
       "[500 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset2\n",
    "df2 = pd.read_excel(\"Features1D/Features.xlsx\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a463b2c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 60 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     500 non-null    int64  \n",
      " 1   file           500 non-null    object \n",
      " 2   scale          500 non-null    object \n",
      " 3   key            500 non-null    object \n",
      " 4   tempo          500 non-null    float64\n",
      " 5   rms_mean       500 non-null    float64\n",
      " 6   rms_var        500 non-null    float64\n",
      " 7   chroma_mean    500 non-null    float64\n",
      " 8   chroma_var     500 non-null    float64\n",
      " 9   centroid_mean  500 non-null    float64\n",
      " 10  centroid_var   500 non-null    float64\n",
      " 11  rolloff_mean   500 non-null    float64\n",
      " 12  roll_off_var   500 non-null    float64\n",
      " 13  zcr_mean       500 non-null    float64\n",
      " 14  zcr_var        500 non-null    float64\n",
      " 15  tonnetz_mean   500 non-null    float64\n",
      " 16  tonnetz_var    500 non-null    float64\n",
      " 17  mel_mean       500 non-null    float64\n",
      " 18  mel_var        500 non-null    float64\n",
      " 19  mfcc_mean_1    500 non-null    float64\n",
      " 20  mfcc_var_1     500 non-null    float64\n",
      " 21  mfcc_mean_2    500 non-null    float64\n",
      " 22  mfcc_var_2     500 non-null    float64\n",
      " 23  mfcc_mean_3    500 non-null    float64\n",
      " 24  mfcc_var_3     500 non-null    float64\n",
      " 25  mfcc_mean_4    500 non-null    float64\n",
      " 26  mfcc_var_4     500 non-null    float64\n",
      " 27  mfcc_mean_5    500 non-null    float64\n",
      " 28  mfcc_var_5     500 non-null    float64\n",
      " 29  mfcc_mean_6    500 non-null    float64\n",
      " 30  mfcc_var_6     500 non-null    float64\n",
      " 31  mfcc_mean_7    500 non-null    float64\n",
      " 32  mfcc_var_7     500 non-null    float64\n",
      " 33  mfcc_mean_8    500 non-null    float64\n",
      " 34  mfcc_var_8     500 non-null    float64\n",
      " 35  mfcc_mean_9    500 non-null    float64\n",
      " 36  mfcc_var_9     500 non-null    float64\n",
      " 37  mfcc_mean_10   500 non-null    float64\n",
      " 38  mfcc_var_10    500 non-null    float64\n",
      " 39  mfcc_mean_11   500 non-null    float64\n",
      " 40  mfcc_var_11    500 non-null    float64\n",
      " 41  mfcc_mean_12   500 non-null    float64\n",
      " 42  mfcc_var_12    500 non-null    float64\n",
      " 43  mfcc_mean_13   500 non-null    float64\n",
      " 44  mfcc_var_13    500 non-null    float64\n",
      " 45  mfcc_mean_14   500 non-null    float64\n",
      " 46  mfcc_var_14    500 non-null    float64\n",
      " 47  mfcc_mean_15   500 non-null    float64\n",
      " 48  mfcc_var_15    500 non-null    float64\n",
      " 49  mfcc_mean_16   500 non-null    float64\n",
      " 50  mfcc_var_16    500 non-null    float64\n",
      " 51  mfcc_mean_17   500 non-null    float64\n",
      " 52  mfcc_var_17    500 non-null    float64\n",
      " 53  mfcc_mean_18   500 non-null    float64\n",
      " 54  mfcc_var_18    500 non-null    float64\n",
      " 55  mfcc_mean_19   500 non-null    float64\n",
      " 56  mfcc_var_19    500 non-null    float64\n",
      " 57  mfcc_mean_20   500 non-null    float64\n",
      " 58  mfcc_var_20    500 non-null    float64\n",
      " 59  mood           500 non-null    object \n",
      "dtypes: float64(55), int64(1), object(4)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9baff1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tempo</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>chroma_mean</th>\n",
       "      <th>chroma_var</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>centroid_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>roll_off_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_mean_16</th>\n",
       "      <th>mfcc_var_16</th>\n",
       "      <th>mfcc_mean_17</th>\n",
       "      <th>mfcc_var_17</th>\n",
       "      <th>mfcc_mean_18</th>\n",
       "      <th>mfcc_var_18</th>\n",
       "      <th>mfcc_mean_19</th>\n",
       "      <th>mfcc_var_19</th>\n",
       "      <th>mfcc_mean_20</th>\n",
       "      <th>mfcc_var_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>249.500000</td>\n",
       "      <td>120.395197</td>\n",
       "      <td>0.116869</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.343292</td>\n",
       "      <td>0.084798</td>\n",
       "      <td>1668.311026</td>\n",
       "      <td>3.214491e+05</td>\n",
       "      <td>3365.881314</td>\n",
       "      <td>1.634849e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.430237</td>\n",
       "      <td>57.411070</td>\n",
       "      <td>-3.837680</td>\n",
       "      <td>57.320411</td>\n",
       "      <td>-0.244337</td>\n",
       "      <td>59.910640</td>\n",
       "      <td>-3.588745</td>\n",
       "      <td>63.899293</td>\n",
       "      <td>-0.429178</td>\n",
       "      <td>69.647001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.481833</td>\n",
       "      <td>20.898325</td>\n",
       "      <td>0.059637</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>0.101563</td>\n",
       "      <td>0.008580</td>\n",
       "      <td>689.692712</td>\n",
       "      <td>3.074005e+05</td>\n",
       "      <td>1581.649710</td>\n",
       "      <td>1.471419e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.932478</td>\n",
       "      <td>39.696133</td>\n",
       "      <td>5.290772</td>\n",
       "      <td>38.858742</td>\n",
       "      <td>5.300261</td>\n",
       "      <td>39.766392</td>\n",
       "      <td>5.354648</td>\n",
       "      <td>42.113503</td>\n",
       "      <td>5.414775</td>\n",
       "      <td>49.896144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.999794</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.160259</td>\n",
       "      <td>0.047596</td>\n",
       "      <td>163.830532</td>\n",
       "      <td>8.299295e+03</td>\n",
       "      <td>206.985221</td>\n",
       "      <td>1.567337e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.610699</td>\n",
       "      <td>7.937813</td>\n",
       "      <td>-24.893364</td>\n",
       "      <td>13.792374</td>\n",
       "      <td>-16.672737</td>\n",
       "      <td>5.940169</td>\n",
       "      <td>-30.015142</td>\n",
       "      <td>8.014700</td>\n",
       "      <td>-18.626137</td>\n",
       "      <td>13.516327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>124.750000</td>\n",
       "      <td>106.589355</td>\n",
       "      <td>0.071237</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.270003</td>\n",
       "      <td>0.081013</td>\n",
       "      <td>1151.420533</td>\n",
       "      <td>1.250368e+05</td>\n",
       "      <td>2154.072211</td>\n",
       "      <td>5.963827e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.255613</td>\n",
       "      <td>31.845476</td>\n",
       "      <td>-7.134056</td>\n",
       "      <td>30.604404</td>\n",
       "      <td>-3.197288</td>\n",
       "      <td>32.159289</td>\n",
       "      <td>-6.238721</td>\n",
       "      <td>35.523054</td>\n",
       "      <td>-3.699433</td>\n",
       "      <td>34.763257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>249.500000</td>\n",
       "      <td>117.453835</td>\n",
       "      <td>0.107466</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.326004</td>\n",
       "      <td>0.085988</td>\n",
       "      <td>1625.869596</td>\n",
       "      <td>2.188663e+05</td>\n",
       "      <td>3279.664563</td>\n",
       "      <td>1.204243e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036742</td>\n",
       "      <td>48.418648</td>\n",
       "      <td>-4.048429</td>\n",
       "      <td>47.127392</td>\n",
       "      <td>-0.068088</td>\n",
       "      <td>50.564163</td>\n",
       "      <td>-3.444308</td>\n",
       "      <td>53.747274</td>\n",
       "      <td>-0.240833</td>\n",
       "      <td>57.556631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>374.250000</td>\n",
       "      <td>130.899208</td>\n",
       "      <td>0.156254</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.402558</td>\n",
       "      <td>0.090014</td>\n",
       "      <td>2161.708013</td>\n",
       "      <td>4.226895e+05</td>\n",
       "      <td>4549.944757</td>\n",
       "      <td>2.181722e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.722093</td>\n",
       "      <td>70.406668</td>\n",
       "      <td>-0.521758</td>\n",
       "      <td>69.277943</td>\n",
       "      <td>3.064685</td>\n",
       "      <td>73.905800</td>\n",
       "      <td>-0.808482</td>\n",
       "      <td>79.707708</td>\n",
       "      <td>2.390816</td>\n",
       "      <td>89.479397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>499.000000</td>\n",
       "      <td>198.768029</td>\n",
       "      <td>0.381500</td>\n",
       "      <td>0.039725</td>\n",
       "      <td>0.671619</td>\n",
       "      <td>0.113631</td>\n",
       "      <td>3498.680881</td>\n",
       "      <td>2.039381e+06</td>\n",
       "      <td>6959.760493</td>\n",
       "      <td>8.731942e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>18.586473</td>\n",
       "      <td>358.093842</td>\n",
       "      <td>16.780653</td>\n",
       "      <td>302.761444</td>\n",
       "      <td>23.927267</td>\n",
       "      <td>303.582184</td>\n",
       "      <td>27.736044</td>\n",
       "      <td>280.381042</td>\n",
       "      <td>23.513090</td>\n",
       "      <td>442.129852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       tempo    rms_mean     rms_var  chroma_mean  \\\n",
       "count  500.000000  500.000000  500.000000  500.000000   500.000000   \n",
       "mean   249.500000  120.395197    0.116869    0.002610     0.343292   \n",
       "std    144.481833   20.898325    0.059637    0.003381     0.101563   \n",
       "min      0.000000   33.999794    0.006621    0.000022     0.160259   \n",
       "25%    124.750000  106.589355    0.071237    0.000722     0.270003   \n",
       "50%    249.500000  117.453835    0.107466    0.001566     0.326004   \n",
       "75%    374.250000  130.899208    0.156254    0.003098     0.402558   \n",
       "max    499.000000  198.768029    0.381500    0.039725     0.671619   \n",
       "\n",
       "       chroma_var  centroid_mean  centroid_var  rolloff_mean  roll_off_var  \\\n",
       "count  500.000000     500.000000  5.000000e+02    500.000000  5.000000e+02   \n",
       "mean     0.084798    1668.311026  3.214491e+05   3365.881314  1.634849e+06   \n",
       "std      0.008580     689.692712  3.074005e+05   1581.649710  1.471419e+06   \n",
       "min      0.047596     163.830532  8.299295e+03    206.985221  1.567337e+04   \n",
       "25%      0.081013    1151.420533  1.250368e+05   2154.072211  5.963827e+05   \n",
       "50%      0.085988    1625.869596  2.188663e+05   3279.664563  1.204243e+06   \n",
       "75%      0.090014    2161.708013  4.226895e+05   4549.944757  2.181722e+06   \n",
       "max      0.113631    3498.680881  2.039381e+06   6959.760493  8.731942e+06   \n",
       "\n",
       "       ...  mfcc_mean_16  mfcc_var_16  mfcc_mean_17  mfcc_var_17  \\\n",
       "count  ...    500.000000   500.000000    500.000000   500.000000   \n",
       "mean   ...     -0.430237    57.411070     -3.837680    57.320411   \n",
       "std    ...      4.932478    39.696133      5.290772    38.858742   \n",
       "min    ...    -15.610699     7.937813    -24.893364    13.792374   \n",
       "25%    ...     -3.255613    31.845476     -7.134056    30.604404   \n",
       "50%    ...     -0.036742    48.418648     -4.048429    47.127392   \n",
       "75%    ...      2.722093    70.406668     -0.521758    69.277943   \n",
       "max    ...     18.586473   358.093842     16.780653   302.761444   \n",
       "\n",
       "       mfcc_mean_18  mfcc_var_18  mfcc_mean_19  mfcc_var_19  mfcc_mean_20  \\\n",
       "count    500.000000   500.000000    500.000000   500.000000    500.000000   \n",
       "mean      -0.244337    59.910640     -3.588745    63.899293     -0.429178   \n",
       "std        5.300261    39.766392      5.354648    42.113503      5.414775   \n",
       "min      -16.672737     5.940169    -30.015142     8.014700    -18.626137   \n",
       "25%       -3.197288    32.159289     -6.238721    35.523054     -3.699433   \n",
       "50%       -0.068088    50.564163     -3.444308    53.747274     -0.240833   \n",
       "75%        3.064685    73.905800     -0.808482    79.707708      2.390816   \n",
       "max       23.927267   303.582184     27.736044   280.381042     23.513090   \n",
       "\n",
       "       mfcc_var_20  \n",
       "count   500.000000  \n",
       "mean     69.647001  \n",
       "std      49.896144  \n",
       "min      13.516327  \n",
       "25%      34.763257  \n",
       "50%      57.556631  \n",
       "75%      89.479397  \n",
       "max     442.129852  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "425f82d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tempo</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>chroma_mean</th>\n",
       "      <th>chroma_var</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>centroid_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>roll_off_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_mean_16</th>\n",
       "      <th>mfcc_var_16</th>\n",
       "      <th>mfcc_mean_17</th>\n",
       "      <th>mfcc_var_17</th>\n",
       "      <th>mfcc_mean_18</th>\n",
       "      <th>mfcc_var_18</th>\n",
       "      <th>mfcc_mean_19</th>\n",
       "      <th>mfcc_var_19</th>\n",
       "      <th>mfcc_mean_20</th>\n",
       "      <th>mfcc_var_20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mood</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>49.5</td>\n",
       "      <td>119.791301</td>\n",
       "      <td>0.143683</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>0.411707</td>\n",
       "      <td>0.078808</td>\n",
       "      <td>1682.190407</td>\n",
       "      <td>246728.805076</td>\n",
       "      <td>3599.547643</td>\n",
       "      <td>1.383827e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.716234</td>\n",
       "      <td>29.764316</td>\n",
       "      <td>-2.571726</td>\n",
       "      <td>30.968135</td>\n",
       "      <td>1.447801</td>\n",
       "      <td>31.123624</td>\n",
       "      <td>-2.522098</td>\n",
       "      <td>32.987506</td>\n",
       "      <td>0.481684</td>\n",
       "      <td>35.660978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>149.5</td>\n",
       "      <td>117.362657</td>\n",
       "      <td>0.109265</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.388548</td>\n",
       "      <td>0.082577</td>\n",
       "      <td>1131.599525</td>\n",
       "      <td>335046.058790</td>\n",
       "      <td>2107.934238</td>\n",
       "      <td>1.483624e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.891489</td>\n",
       "      <td>48.596364</td>\n",
       "      <td>-0.211073</td>\n",
       "      <td>48.996520</td>\n",
       "      <td>1.213213</td>\n",
       "      <td>51.297225</td>\n",
       "      <td>-0.174988</td>\n",
       "      <td>54.092575</td>\n",
       "      <td>1.250011</td>\n",
       "      <td>54.720373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>249.5</td>\n",
       "      <td>119.642832</td>\n",
       "      <td>0.133122</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.370829</td>\n",
       "      <td>0.084728</td>\n",
       "      <td>2494.002767</td>\n",
       "      <td>294058.369451</td>\n",
       "      <td>5204.543552</td>\n",
       "      <td>1.297782e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320848</td>\n",
       "      <td>51.621370</td>\n",
       "      <td>-5.706828</td>\n",
       "      <td>53.341666</td>\n",
       "      <td>0.194046</td>\n",
       "      <td>54.846162</td>\n",
       "      <td>-4.663032</td>\n",
       "      <td>61.449010</td>\n",
       "      <td>0.325332</td>\n",
       "      <td>64.571930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relax</th>\n",
       "      <td>349.5</td>\n",
       "      <td>121.566391</td>\n",
       "      <td>0.098366</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.282407</td>\n",
       "      <td>0.089781</td>\n",
       "      <td>1330.465063</td>\n",
       "      <td>493934.269821</td>\n",
       "      <td>2562.747229</td>\n",
       "      <td>2.661879e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.757191</td>\n",
       "      <td>80.247970</td>\n",
       "      <td>-4.782265</td>\n",
       "      <td>79.222677</td>\n",
       "      <td>-2.434443</td>\n",
       "      <td>79.814637</td>\n",
       "      <td>-5.031492</td>\n",
       "      <td>82.774596</td>\n",
       "      <td>-2.542917</td>\n",
       "      <td>91.384084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>449.5</td>\n",
       "      <td>123.612802</td>\n",
       "      <td>0.099908</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.262969</td>\n",
       "      <td>0.088094</td>\n",
       "      <td>1703.297369</td>\n",
       "      <td>237478.189159</td>\n",
       "      <td>3354.633909</td>\n",
       "      <td>1.347131e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.680867</td>\n",
       "      <td>76.825329</td>\n",
       "      <td>-5.916506</td>\n",
       "      <td>74.073058</td>\n",
       "      <td>-1.642302</td>\n",
       "      <td>82.471553</td>\n",
       "      <td>-5.552116</td>\n",
       "      <td>88.192779</td>\n",
       "      <td>-1.659999</td>\n",
       "      <td>101.897642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       tempo  rms_mean   rms_var  chroma_mean  chroma_var  \\\n",
       "mood                                                                         \n",
       "angry        49.5  119.791301  0.143683  0.002207     0.411707    0.078808   \n",
       "fear        149.5  117.362657  0.109265  0.004573     0.388548    0.082577   \n",
       "happy       249.5  119.642832  0.133122  0.002388     0.370829    0.084728   \n",
       "relax       349.5  121.566391  0.098366  0.002285     0.282407    0.089781   \n",
       "sad         449.5  123.612802  0.099908  0.001595     0.262969    0.088094   \n",
       "\n",
       "       centroid_mean   centroid_var  rolloff_mean  roll_off_var  ...  \\\n",
       "mood                                                             ...   \n",
       "angry    1682.190407  246728.805076   3599.547643  1.383827e+06  ...   \n",
       "fear     1131.599525  335046.058790   2107.934238  1.483624e+06  ...   \n",
       "happy    2494.002767  294058.369451   5204.543552  1.297782e+06  ...   \n",
       "relax    1330.465063  493934.269821   2562.747229  2.661879e+06  ...   \n",
       "sad      1703.297369  237478.189159   3354.633909  1.347131e+06  ...   \n",
       "\n",
       "       mfcc_mean_16  mfcc_var_16  mfcc_mean_17  mfcc_var_17  mfcc_mean_18  \\\n",
       "mood                                                                        \n",
       "angry      1.716234    29.764316     -2.571726    30.968135      1.447801   \n",
       "fear       1.891489    48.596364     -0.211073    48.996520      1.213213   \n",
       "happy     -0.320848    51.621370     -5.706828    53.341666      0.194046   \n",
       "relax     -2.757191    80.247970     -4.782265    79.222677     -2.434443   \n",
       "sad       -2.680867    76.825329     -5.916506    74.073058     -1.642302   \n",
       "\n",
       "       mfcc_var_18  mfcc_mean_19  mfcc_var_19  mfcc_mean_20  mfcc_var_20  \n",
       "mood                                                                      \n",
       "angry    31.123624     -2.522098    32.987506      0.481684    35.660978  \n",
       "fear     51.297225     -0.174988    54.092575      1.250011    54.720373  \n",
       "happy    54.846162     -4.663032    61.449010      0.325332    64.571930  \n",
       "relax    79.814637     -5.031492    82.774596     -2.542917    91.384084  \n",
       "sad      82.471553     -5.552116    88.192779     -1.659999   101.897642  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('mood').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eca9703",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing\n",
    "### 2.1 Define Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99328a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'fear', 'happy', 'relax', 'sad'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = df2.drop(['mood'],axis=1)\n",
    "y2 = df2['mood']\n",
    "np.unique(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d5d1f",
   "metadata": {},
   "source": [
    "### 2.2 Encode the non-numerical features labels\n",
    "\n",
    "**Encode the labels in numerical way:**\n",
    "- Happy: 1 \n",
    "- Angry: 0 \n",
    "- Relaxed: 2 \n",
    "- Sad: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e1d89f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f32e6a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(y2)\n",
    "y2 = le.transform(y2)\n",
    "np.unique(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a79f5",
   "metadata": {},
   "source": [
    "**Then encode the non-numeric variable scale:**\n",
    "- major: 0\n",
    "- minor: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e96d6209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['major', 'minor'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2['scale'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0532f958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(X2['scale'])\n",
    "X2['scale'] = le.transform(X2['scale'])\n",
    "X2['scale'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6282266b",
   "metadata": {},
   "source": [
    "**Finally, encode the non-numeric variable key:**\n",
    "- A: 0\n",
    "- A#: 1\n",
    "- B: 2\n",
    "- C: 3\n",
    "- C#: 4\n",
    "- D: 5\n",
    "- D#: 6\n",
    "- E: 7\n",
    "- F: 8\n",
    "- F#: 9\n",
    "- G: 10\n",
    "- G#: 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42fbeede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'D', 'B', 'C#', 'E', 'D#', 'G', 'F', 'C', 'G#', 'A#', 'F#'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2['key'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d88fb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5,  2,  4,  7,  6, 10,  8,  3, 11,  1,  9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(X2['key'])\n",
    "X2['key'] = le.transform(X2['key'])\n",
    "X2['key'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c55b16",
   "metadata": {},
   "source": [
    "### 2.3 Train Test Validation Split\n",
    "Finally, split the dataset into train and test set, 80% of data are used as train set, 10% of data are used as test set and the remaining ones are used for validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4900c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, \n",
    "                                                    train_size = 0.9, \n",
    "                                                    random_state = 13, \n",
    "                                                    shuffle = True, \n",
    "                                                    stratify = y2)\n",
    "X2_train, X2_val, y2_train, y2_val = train_test_split(X2_train, y2_train, \n",
    "                                                train_size = 0.8, \n",
    "                                                random_state = 13, \n",
    "                                                shuffle = True, \n",
    "                                                stratify = y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a1c809",
   "metadata": {},
   "source": [
    "### 2.4 Feature Scaling\n",
    "As the range of the variales varies distinctly, in order to make the learning process better, the features need to be scaled into similar ranges. Here the Min-Max Scaler is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38e763e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed445136",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train_scaled = scaler.fit_transform(X2_train.drop('file',axis=1))\n",
    "X2_val_scaled = scaler.fit_transform(X2_val.drop('file',axis=1))\n",
    "X2_test_scaled = scaler.fit_transform(X2_test.drop('file',axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f2ff7",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5153ff50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define Model Builder of 3 conv1D layers and 2 fully connected layers\n",
    "# Input data and paras of layers are changable\n",
    "\n",
    "def modelBuilder3L(X_train,\n",
    "                  f1,k1,a1,\n",
    "                  f2,k2,a2,\n",
    "                  f3,k3,a3,\n",
    "                  d1,dr1,da1,r1,\n",
    "                  d2,dr2,da2,r2,\n",
    "                  num):\n",
    "    '''\n",
    "    args:\n",
    "    \n",
    "    X_train: training data\n",
    "    f1,k1,a1: num of filters, filter size and activation func of 1st conv1D layer\n",
    "    f2,k2,a2: num of filters, filter size and activation func of 2nd conv1D layer\n",
    "    f3,k3,a3: num of filters, filter size and activation func of 3rd conv1D layer\n",
    "    d1,dr1,da1, r1: num of units, dropout, activation func and regularizer para of 1st fully connected layer\n",
    "    d2,dr2,da2, r2: num of units, dropout, activation func and regularizer para of 2nd fully connected layer\n",
    "    num: integer for distinguishing different model\n",
    "    \n",
    "    return:\n",
    "    model\n",
    "    \n",
    "    '''\n",
    "    model = Sequential(name=\"Conv1D_\"+str(num))\n",
    "    m,n = X_train.shape\n",
    "    #layer 1\n",
    "    model.add(Conv1D(filters = f1, kernel_size = k1, input_shape = (n,1), padding = 'same', activation = a1, name ='Conv1D_1'))\n",
    "    model.add(BatchNormalization(name = \"BN1\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling1\"))\n",
    "    #layer 2\n",
    "    model.add(Conv1D(filters = f2, kernel_size = k2, activation = a2, padding='same', name = \"Conv1D_2\"))\n",
    "    model.add(BatchNormalization(name = \"BN2\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling2\"))\n",
    "    #layer 3\n",
    "    model.add(Conv1D(filters = f3, kernel_size = k3, activation = a3, padding='same', name = \"Conv1D_3\"))\n",
    "    model.add(BatchNormalization(name = \"BN3\"))\n",
    "    model.add(MaxPooling1D(name = \"MaxPooling3\"))\n",
    "    #Flatten output\n",
    "    model.add(Flatten(name = \"Flatten\"))\n",
    "    #Fully connected layer 4\n",
    "    model.add(Dense(d1, activation = da1, name = \"Dense_1\"))\n",
    "    #Prevent overfitting\n",
    "    model.add(Dropout(dr1, name = \"Dropout_1\"))\n",
    "    #Fully connected layer 6\n",
    "    model.add(Dense(d2, activation = da2, name = \"Dense_2\"))\n",
    "    #Prevent overfitting\n",
    "    model.add(Dropout(dr2, name = \"Dropout_2\"))\n",
    "    #Output layer\n",
    "    model.add(Dense(5, activation = 'softmax', name = \"Softmax\"))\n",
    "    #model compiling\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\n",
    "    # model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca19c2",
   "metadata": {},
   "source": [
    "### 3.2 Change dataset\n",
    "After trying out multiple ways to address the overfitting problems, the model accuracy still remain almost same and did not improve significantly. Because the number of data in this dataset is sufficient, therefore, changing of the dataset is considered. Here the dataset2 is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c538707f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 64,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.7,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.4,'relu',0.15\n",
    "num = 11\n",
    "\n",
    "model11 = modelBuilder3L(X2_train_scaled,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7948184b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.1929 - loss: 3.5967 - val_accuracy: 0.3222 - val_loss: 1.6087\n",
      "Epoch 2/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2025 - loss: 3.4118 - val_accuracy: 0.1111 - val_loss: 1.6075\n",
      "Epoch 3/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2054 - loss: 3.3734 - val_accuracy: 0.1778 - val_loss: 1.6055\n",
      "Epoch 4/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2397 - loss: 3.0263 - val_accuracy: 0.1778 - val_loss: 1.6050\n",
      "Epoch 5/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2270 - loss: 2.6483 - val_accuracy: 0.1333 - val_loss: 1.6049\n",
      "Epoch 6/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2566 - loss: 2.6969 - val_accuracy: 0.1111 - val_loss: 1.6053\n",
      "Epoch 7/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2016 - loss: 2.6310 - val_accuracy: 0.1667 - val_loss: 1.6062\n",
      "Epoch 8/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2668 - loss: 2.4260 - val_accuracy: 0.1667 - val_loss: 1.6069\n",
      "Epoch 9/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2662 - loss: 2.3728 - val_accuracy: 0.1556 - val_loss: 1.6075\n",
      "Epoch 10/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3423 - loss: 2.2715 - val_accuracy: 0.1778 - val_loss: 1.6085\n",
      "Epoch 11/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2919 - loss: 2.2103 - val_accuracy: 0.1778 - val_loss: 1.6096\n",
      "Epoch 12/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3262 - loss: 2.0054 - val_accuracy: 0.1556 - val_loss: 1.6107\n",
      "Epoch 13/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3497 - loss: 2.0465 - val_accuracy: 0.1778 - val_loss: 1.6118\n",
      "Epoch 14/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2941 - loss: 2.0376 - val_accuracy: 0.1889 - val_loss: 1.6128\n",
      "Epoch 15/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3288 - loss: 1.8505 - val_accuracy: 0.1889 - val_loss: 1.6140\n",
      "Epoch 16/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3457 - loss: 1.8879 - val_accuracy: 0.1889 - val_loss: 1.6152\n",
      "Epoch 17/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3241 - loss: 1.9834 - val_accuracy: 0.1889 - val_loss: 1.6162\n",
      "Epoch 18/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3382 - loss: 1.7592 - val_accuracy: 0.2000 - val_loss: 1.6171\n",
      "Epoch 19/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3280 - loss: 1.7575 - val_accuracy: 0.2000 - val_loss: 1.6181\n",
      "Epoch 20/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3719 - loss: 1.6470 - val_accuracy: 0.2111 - val_loss: 1.6199\n",
      "Epoch 21/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4044 - loss: 1.6561 - val_accuracy: 0.2000 - val_loss: 1.6217\n",
      "Epoch 22/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3673 - loss: 1.6545 - val_accuracy: 0.2000 - val_loss: 1.6232\n",
      "Epoch 23/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3755 - loss: 1.6392 - val_accuracy: 0.2000 - val_loss: 1.6250\n",
      "Epoch 24/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3882 - loss: 1.6570 - val_accuracy: 0.2111 - val_loss: 1.6263\n",
      "Epoch 25/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4182 - loss: 1.5028 - val_accuracy: 0.2111 - val_loss: 1.6274\n",
      "Epoch 26/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3716 - loss: 1.6237 - val_accuracy: 0.2111 - val_loss: 1.6282\n",
      "Epoch 27/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4420 - loss: 1.4296 - val_accuracy: 0.2111 - val_loss: 1.6289\n",
      "Epoch 28/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3905 - loss: 1.5281 - val_accuracy: 0.2111 - val_loss: 1.6292\n",
      "Epoch 29/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4327 - loss: 1.5444 - val_accuracy: 0.2111 - val_loss: 1.6291\n",
      "Epoch 30/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4211 - loss: 1.4844 - val_accuracy: 0.2222 - val_loss: 1.6288\n",
      "Epoch 31/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4661 - loss: 1.4053 - val_accuracy: 0.2222 - val_loss: 1.6280\n",
      "Epoch 32/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4508 - loss: 1.3868 - val_accuracy: 0.2111 - val_loss: 1.6273\n",
      "Epoch 33/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4755 - loss: 1.3318 - val_accuracy: 0.2111 - val_loss: 1.6269\n",
      "Epoch 34/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4435 - loss: 1.4360 - val_accuracy: 0.2111 - val_loss: 1.6265\n",
      "Epoch 35/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4716 - loss: 1.3956 - val_accuracy: 0.2111 - val_loss: 1.6252\n",
      "Epoch 36/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4573 - loss: 1.3199 - val_accuracy: 0.2111 - val_loss: 1.6240\n",
      "Epoch 37/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4409 - loss: 1.4403 - val_accuracy: 0.2111 - val_loss: 1.6225\n",
      "Epoch 38/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4069 - loss: 1.4375 - val_accuracy: 0.2333 - val_loss: 1.6203\n",
      "Epoch 39/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4531 - loss: 1.3989 - val_accuracy: 0.2333 - val_loss: 1.6180\n",
      "Epoch 40/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4383 - loss: 1.3097 - val_accuracy: 0.2333 - val_loss: 1.6152\n",
      "Epoch 41/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5015 - loss: 1.3729 - val_accuracy: 0.2333 - val_loss: 1.6120\n",
      "Epoch 42/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5127 - loss: 1.1911 - val_accuracy: 0.2222 - val_loss: 1.6080\n",
      "Epoch 43/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5273 - loss: 1.1851 - val_accuracy: 0.2111 - val_loss: 1.6033\n",
      "Epoch 44/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4390 - loss: 1.3520 - val_accuracy: 0.2222 - val_loss: 1.5980\n",
      "Epoch 45/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5418 - loss: 1.2390 - val_accuracy: 0.2222 - val_loss: 1.5930\n",
      "Epoch 46/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5110 - loss: 1.1745 - val_accuracy: 0.2222 - val_loss: 1.5878\n",
      "Epoch 47/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5780 - loss: 1.0911 - val_accuracy: 0.2333 - val_loss: 1.5823\n",
      "Epoch 48/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5399 - loss: 1.1920 - val_accuracy: 0.2444 - val_loss: 1.5753\n",
      "Epoch 49/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5688 - loss: 1.1832 - val_accuracy: 0.2444 - val_loss: 1.5679\n",
      "Epoch 50/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6057 - loss: 1.1006 - val_accuracy: 0.2556 - val_loss: 1.5613\n",
      "Epoch 51/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5256 - loss: 1.1424 - val_accuracy: 0.2444 - val_loss: 1.5555\n",
      "Epoch 52/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5528 - loss: 1.1832 - val_accuracy: 0.2444 - val_loss: 1.5494\n",
      "Epoch 53/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5365 - loss: 1.1347 - val_accuracy: 0.2556 - val_loss: 1.5412\n",
      "Epoch 54/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5938 - loss: 1.0251 - val_accuracy: 0.2556 - val_loss: 1.5326\n",
      "Epoch 55/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6125 - loss: 1.0078 - val_accuracy: 0.2556 - val_loss: 1.5234\n",
      "Epoch 56/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5518 - loss: 1.0990 - val_accuracy: 0.2556 - val_loss: 1.5138\n",
      "Epoch 57/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5957 - loss: 1.1136 - val_accuracy: 0.2778 - val_loss: 1.5034\n",
      "Epoch 58/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5950 - loss: 1.0425 - val_accuracy: 0.3000 - val_loss: 1.4933\n",
      "Epoch 59/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6111 - loss: 1.0571 - val_accuracy: 0.3000 - val_loss: 1.4835\n",
      "Epoch 60/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5599 - loss: 1.1210 - val_accuracy: 0.3111 - val_loss: 1.4735\n",
      "Epoch 61/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5445 - loss: 1.0900 - val_accuracy: 0.3222 - val_loss: 1.4605\n",
      "Epoch 62/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5669 - loss: 1.0278 - val_accuracy: 0.3111 - val_loss: 1.4468\n",
      "Epoch 63/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6158 - loss: 1.0237 - val_accuracy: 0.3333 - val_loss: 1.4322\n",
      "Epoch 64/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6508 - loss: 0.9567 - val_accuracy: 0.3444 - val_loss: 1.4164\n",
      "Epoch 65/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6066 - loss: 0.9600 - val_accuracy: 0.3778 - val_loss: 1.4020\n",
      "Epoch 66/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5806 - loss: 1.0314 - val_accuracy: 0.3889 - val_loss: 1.3878\n",
      "Epoch 67/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6314 - loss: 0.9649 - val_accuracy: 0.4000 - val_loss: 1.3717\n",
      "Epoch 68/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5629 - loss: 1.0588 - val_accuracy: 0.4333 - val_loss: 1.3570\n",
      "Epoch 69/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5913 - loss: 0.9973 - val_accuracy: 0.4444 - val_loss: 1.3416\n",
      "Epoch 70/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6076 - loss: 0.9668 - val_accuracy: 0.4667 - val_loss: 1.3265\n",
      "Epoch 71/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6136 - loss: 0.9373 - val_accuracy: 0.4556 - val_loss: 1.3102\n",
      "Epoch 72/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6949 - loss: 0.8954 - val_accuracy: 0.4778 - val_loss: 1.2928\n",
      "Epoch 73/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6546 - loss: 0.9703 - val_accuracy: 0.4778 - val_loss: 1.2770\n",
      "Epoch 74/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6458 - loss: 0.9535 - val_accuracy: 0.4889 - val_loss: 1.2639\n",
      "Epoch 75/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6550 - loss: 0.9328 - val_accuracy: 0.5333 - val_loss: 1.2493\n",
      "Epoch 76/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6516 - loss: 0.9061 - val_accuracy: 0.5222 - val_loss: 1.2336\n",
      "Epoch 77/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5724 - loss: 1.0147 - val_accuracy: 0.5222 - val_loss: 1.2196\n",
      "Epoch 78/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5690 - loss: 1.0279 - val_accuracy: 0.5222 - val_loss: 1.2062\n",
      "Epoch 79/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6819 - loss: 0.8341 - val_accuracy: 0.5222 - val_loss: 1.1915\n",
      "Epoch 80/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6521 - loss: 0.8956 - val_accuracy: 0.5444 - val_loss: 1.1770\n",
      "Epoch 81/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6535 - loss: 0.9202 - val_accuracy: 0.5556 - val_loss: 1.1646\n",
      "Epoch 82/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6652 - loss: 0.8663 - val_accuracy: 0.5556 - val_loss: 1.1511\n",
      "Epoch 83/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6560 - loss: 0.9086 - val_accuracy: 0.5444 - val_loss: 1.1380\n",
      "Epoch 84/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6482 - loss: 0.8485 - val_accuracy: 0.5444 - val_loss: 1.1247\n",
      "Epoch 85/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6509 - loss: 0.9001 - val_accuracy: 0.5556 - val_loss: 1.1116\n",
      "Epoch 86/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6168 - loss: 0.9118 - val_accuracy: 0.5778 - val_loss: 1.0980\n",
      "Epoch 87/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6784 - loss: 0.8677 - val_accuracy: 0.5778 - val_loss: 1.0849\n",
      "Epoch 88/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6833 - loss: 0.8706 - val_accuracy: 0.5889 - val_loss: 1.0739\n",
      "Epoch 89/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6516 - loss: 0.8460 - val_accuracy: 0.6000 - val_loss: 1.0630\n",
      "Epoch 90/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7828 - loss: 0.7324 - val_accuracy: 0.6000 - val_loss: 1.0529\n",
      "Epoch 91/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7134 - loss: 0.7572 - val_accuracy: 0.6000 - val_loss: 1.0442\n",
      "Epoch 92/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6515 - loss: 0.8687 - val_accuracy: 0.6000 - val_loss: 1.0345\n",
      "Epoch 93/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7223 - loss: 0.7302 - val_accuracy: 0.6000 - val_loss: 1.0245\n",
      "Epoch 94/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7036 - loss: 0.7981 - val_accuracy: 0.6000 - val_loss: 1.0125\n",
      "Epoch 95/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6947 - loss: 0.8305 - val_accuracy: 0.6111 - val_loss: 1.0000\n",
      "Epoch 96/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7076 - loss: 0.7392 - val_accuracy: 0.6222 - val_loss: 0.9866\n",
      "Epoch 97/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6613 - loss: 0.8404 - val_accuracy: 0.6222 - val_loss: 0.9762\n",
      "Epoch 98/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7068 - loss: 0.8510 - val_accuracy: 0.6222 - val_loss: 0.9661\n",
      "Epoch 99/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6712 - loss: 0.8353 - val_accuracy: 0.6222 - val_loss: 0.9579\n",
      "Epoch 100/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6950 - loss: 0.7471 - val_accuracy: 0.6222 - val_loss: 0.9520\n",
      "Epoch 101/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7055 - loss: 0.8135 - val_accuracy: 0.6111 - val_loss: 0.9468\n",
      "Epoch 102/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7245 - loss: 0.7693 - val_accuracy: 0.6000 - val_loss: 0.9404\n",
      "Epoch 103/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6808 - loss: 0.7771 - val_accuracy: 0.6111 - val_loss: 0.9355\n",
      "Epoch 104/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7341 - loss: 0.7409 - val_accuracy: 0.6333 - val_loss: 0.9283\n",
      "Epoch 105/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7158 - loss: 0.7453 - val_accuracy: 0.6444 - val_loss: 0.9224\n",
      "Epoch 106/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6831 - loss: 0.7717 - val_accuracy: 0.6556 - val_loss: 0.9169\n",
      "Epoch 107/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7568 - loss: 0.6733 - val_accuracy: 0.6444 - val_loss: 0.9116\n",
      "Epoch 108/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7203 - loss: 0.7604 - val_accuracy: 0.6444 - val_loss: 0.9106\n",
      "Epoch 109/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7581 - loss: 0.7394 - val_accuracy: 0.6444 - val_loss: 0.9105\n",
      "Epoch 110/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7444 - loss: 0.6925 - val_accuracy: 0.6444 - val_loss: 0.9099\n",
      "Epoch 111/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7199 - loss: 0.7230 - val_accuracy: 0.6444 - val_loss: 0.9073\n",
      "Epoch 112/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7726 - loss: 0.6491 - val_accuracy: 0.6444 - val_loss: 0.9040\n",
      "Epoch 113/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7354 - loss: 0.7492 - val_accuracy: 0.6444 - val_loss: 0.9020\n",
      "Epoch 114/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6957 - loss: 0.7654 - val_accuracy: 0.6444 - val_loss: 0.8996\n",
      "Epoch 115/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7347 - loss: 0.7160 - val_accuracy: 0.6444 - val_loss: 0.8977\n",
      "Epoch 116/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7290 - loss: 0.6856 - val_accuracy: 0.6444 - val_loss: 0.8922\n",
      "Epoch 117/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7797 - loss: 0.6791 - val_accuracy: 0.6444 - val_loss: 0.8884\n",
      "Epoch 118/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7290 - loss: 0.6802 - val_accuracy: 0.6444 - val_loss: 0.8888\n",
      "Epoch 119/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7514 - loss: 0.6833 - val_accuracy: 0.6444 - val_loss: 0.8877\n",
      "Epoch 120/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7624 - loss: 0.6667 - val_accuracy: 0.6444 - val_loss: 0.8843\n",
      "Epoch 121/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7354 - loss: 0.6907 - val_accuracy: 0.6667 - val_loss: 0.8817\n",
      "Epoch 122/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8207 - loss: 0.5415 - val_accuracy: 0.6778 - val_loss: 0.8764\n",
      "Epoch 123/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7589 - loss: 0.6279 - val_accuracy: 0.6778 - val_loss: 0.8711\n",
      "Epoch 124/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8129 - loss: 0.5771 - val_accuracy: 0.6667 - val_loss: 0.8716\n",
      "Epoch 125/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7838 - loss: 0.6521 - val_accuracy: 0.6556 - val_loss: 0.8743\n",
      "Epoch 126/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7855 - loss: 0.5550 - val_accuracy: 0.6444 - val_loss: 0.8793\n",
      "Epoch 127/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7867 - loss: 0.6361 - val_accuracy: 0.6222 - val_loss: 0.8831\n",
      "Epoch 128/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7605 - loss: 0.6188 - val_accuracy: 0.6333 - val_loss: 0.8872\n",
      "Epoch 129/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7830 - loss: 0.6102 - val_accuracy: 0.6333 - val_loss: 0.8913\n",
      "Epoch 130/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7842 - loss: 0.6634 - val_accuracy: 0.6333 - val_loss: 0.8915\n",
      "Epoch 131/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8008 - loss: 0.6097 - val_accuracy: 0.6222 - val_loss: 0.8899\n",
      "Epoch 132/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7547 - loss: 0.7083 - val_accuracy: 0.6444 - val_loss: 0.8849\n",
      "Epoch 133/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7729 - loss: 0.6275 - val_accuracy: 0.6444 - val_loss: 0.8827\n",
      "Epoch 134/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7760 - loss: 0.5954 - val_accuracy: 0.6556 - val_loss: 0.8773\n",
      "Epoch 135/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7857 - loss: 0.6111 - val_accuracy: 0.6667 - val_loss: 0.8750\n",
      "Epoch 136/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7743 - loss: 0.5841 - val_accuracy: 0.6778 - val_loss: 0.8721\n",
      "Epoch 137/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8011 - loss: 0.5576 - val_accuracy: 0.6778 - val_loss: 0.8675\n",
      "Epoch 138/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7877 - loss: 0.5494 - val_accuracy: 0.6667 - val_loss: 0.8650\n",
      "Epoch 139/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7978 - loss: 0.5766 - val_accuracy: 0.6667 - val_loss: 0.8645\n",
      "Epoch 140/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7990 - loss: 0.5550 - val_accuracy: 0.6556 - val_loss: 0.8685\n",
      "Epoch 141/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8051 - loss: 0.5339 - val_accuracy: 0.6556 - val_loss: 0.8687\n",
      "Epoch 142/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7835 - loss: 0.5652 - val_accuracy: 0.6667 - val_loss: 0.8666\n",
      "Epoch 143/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7936 - loss: 0.5678 - val_accuracy: 0.6778 - val_loss: 0.8638\n",
      "Epoch 144/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8051 - loss: 0.5168 - val_accuracy: 0.6778 - val_loss: 0.8653\n",
      "Epoch 145/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8024 - loss: 0.5631 - val_accuracy: 0.6889 - val_loss: 0.8668\n",
      "Epoch 146/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7976 - loss: 0.5483 - val_accuracy: 0.6889 - val_loss: 0.8644\n",
      "Epoch 147/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7757 - loss: 0.5683 - val_accuracy: 0.6778 - val_loss: 0.8691\n",
      "Epoch 148/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7978 - loss: 0.5304 - val_accuracy: 0.6778 - val_loss: 0.8667\n",
      "Epoch 149/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8201 - loss: 0.5552 - val_accuracy: 0.6778 - val_loss: 0.8649\n",
      "Epoch 150/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8032 - loss: 0.5643 - val_accuracy: 0.6778 - val_loss: 0.8649\n",
      "Epoch 151/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8189 - loss: 0.4878 - val_accuracy: 0.6667 - val_loss: 0.8646\n",
      "Epoch 152/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8374 - loss: 0.5223 - val_accuracy: 0.6667 - val_loss: 0.8611\n",
      "Epoch 153/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8340 - loss: 0.4322 - val_accuracy: 0.6778 - val_loss: 0.8569\n",
      "Epoch 154/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8295 - loss: 0.4924 - val_accuracy: 0.6889 - val_loss: 0.8543\n",
      "Epoch 155/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8365 - loss: 0.4808 - val_accuracy: 0.6889 - val_loss: 0.8519\n",
      "Epoch 156/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7992 - loss: 0.4908 - val_accuracy: 0.6778 - val_loss: 0.8528\n",
      "Epoch 157/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8272 - loss: 0.4906 - val_accuracy: 0.6778 - val_loss: 0.8551\n",
      "Epoch 158/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8229 - loss: 0.4678 - val_accuracy: 0.6778 - val_loss: 0.8615\n",
      "Epoch 159/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8798 - loss: 0.3919 - val_accuracy: 0.6778 - val_loss: 0.8631\n",
      "Epoch 160/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8049 - loss: 0.5712 - val_accuracy: 0.6778 - val_loss: 0.8673\n",
      "Epoch 161/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8309 - loss: 0.4901 - val_accuracy: 0.6889 - val_loss: 0.8640\n",
      "Epoch 162/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8111 - loss: 0.5076 - val_accuracy: 0.7000 - val_loss: 0.8547\n",
      "Epoch 163/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7844 - loss: 0.5266 - val_accuracy: 0.7000 - val_loss: 0.8461\n",
      "Epoch 164/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8226 - loss: 0.4762 - val_accuracy: 0.7000 - val_loss: 0.8412\n",
      "Epoch 165/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8588 - loss: 0.4074 - val_accuracy: 0.7000 - val_loss: 0.8427\n",
      "Epoch 166/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8370 - loss: 0.5221 - val_accuracy: 0.7000 - val_loss: 0.8468\n",
      "Epoch 167/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8767 - loss: 0.3646 - val_accuracy: 0.7000 - val_loss: 0.8416\n",
      "Epoch 168/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8132 - loss: 0.5516 - val_accuracy: 0.7111 - val_loss: 0.8377\n",
      "Epoch 169/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8535 - loss: 0.4238 - val_accuracy: 0.7111 - val_loss: 0.8361\n",
      "Epoch 170/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8019 - loss: 0.4875 - val_accuracy: 0.7111 - val_loss: 0.8383\n",
      "Epoch 171/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8457 - loss: 0.4459 - val_accuracy: 0.7111 - val_loss: 0.8405\n",
      "Epoch 172/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8664 - loss: 0.4071 - val_accuracy: 0.7000 - val_loss: 0.8455\n",
      "Epoch 173/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8681 - loss: 0.4086 - val_accuracy: 0.7111 - val_loss: 0.8433\n",
      "Epoch 174/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8507 - loss: 0.4077 - val_accuracy: 0.7111 - val_loss: 0.8384\n",
      "Epoch 175/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8570 - loss: 0.3990 - val_accuracy: 0.7000 - val_loss: 0.8356\n",
      "Epoch 176/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8619 - loss: 0.3789 - val_accuracy: 0.6889 - val_loss: 0.8333\n",
      "Epoch 177/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8300 - loss: 0.4036 - val_accuracy: 0.6778 - val_loss: 0.8364\n",
      "Epoch 178/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8632 - loss: 0.4088 - val_accuracy: 0.6889 - val_loss: 0.8388\n",
      "Epoch 179/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8716 - loss: 0.3948 - val_accuracy: 0.6889 - val_loss: 0.8370\n",
      "Epoch 180/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8822 - loss: 0.3644 - val_accuracy: 0.6889 - val_loss: 0.8397\n",
      "Epoch 181/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8703 - loss: 0.3652 - val_accuracy: 0.6889 - val_loss: 0.8470\n",
      "Epoch 182/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8557 - loss: 0.3676 - val_accuracy: 0.6889 - val_loss: 0.8482\n",
      "Epoch 183/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8606 - loss: 0.3738 - val_accuracy: 0.6889 - val_loss: 0.8563\n",
      "Epoch 184/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8378 - loss: 0.4499 - val_accuracy: 0.6889 - val_loss: 0.8553\n",
      "Epoch 185/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8345 - loss: 0.3868 - val_accuracy: 0.7000 - val_loss: 0.8545\n",
      "Epoch 186/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8899 - loss: 0.3598 - val_accuracy: 0.7000 - val_loss: 0.8554\n",
      "Epoch 187/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8494 - loss: 0.4020 - val_accuracy: 0.7000 - val_loss: 0.8600\n",
      "Epoch 188/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8796 - loss: 0.3847 - val_accuracy: 0.7000 - val_loss: 0.8594\n",
      "Epoch 189/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8472 - loss: 0.3832 - val_accuracy: 0.7111 - val_loss: 0.8620\n",
      "Epoch 190/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8486 - loss: 0.3986 - val_accuracy: 0.7111 - val_loss: 0.8616\n",
      "Epoch 191/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8627 - loss: 0.3644 - val_accuracy: 0.7111 - val_loss: 0.8647\n",
      "Epoch 192/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8928 - loss: 0.3242 - val_accuracy: 0.7000 - val_loss: 0.8696\n",
      "Epoch 193/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8818 - loss: 0.3743 - val_accuracy: 0.7000 - val_loss: 0.8707\n",
      "Epoch 194/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8695 - loss: 0.3548 - val_accuracy: 0.7000 - val_loss: 0.8784\n",
      "Epoch 195/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8704 - loss: 0.3534 - val_accuracy: 0.7000 - val_loss: 0.8890\n",
      "Epoch 196/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8317 - loss: 0.4470 - val_accuracy: 0.7000 - val_loss: 0.8921\n",
      "Epoch 197/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8823 - loss: 0.3400 - val_accuracy: 0.6889 - val_loss: 0.8878\n",
      "Epoch 198/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8796 - loss: 0.3805 - val_accuracy: 0.6889 - val_loss: 0.8777\n",
      "Epoch 199/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8748 - loss: 0.3332 - val_accuracy: 0.7000 - val_loss: 0.8631\n",
      "Epoch 200/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8804 - loss: 0.3812 - val_accuracy: 0.7111 - val_loss: 0.8554\n",
      "Epoch 201/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8969 - loss: 0.3279 - val_accuracy: 0.7111 - val_loss: 0.8458\n",
      "Epoch 202/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8699 - loss: 0.2908 - val_accuracy: 0.7111 - val_loss: 0.8328\n",
      "Epoch 203/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9251 - loss: 0.2680 - val_accuracy: 0.7222 - val_loss: 0.8261\n",
      "Epoch 204/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8645 - loss: 0.3472 - val_accuracy: 0.7222 - val_loss: 0.8293\n",
      "Epoch 205/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9052 - loss: 0.2693 - val_accuracy: 0.7222 - val_loss: 0.8375\n",
      "Epoch 206/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9000 - loss: 0.3211 - val_accuracy: 0.7222 - val_loss: 0.8440\n",
      "Epoch 207/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8665 - loss: 0.3932 - val_accuracy: 0.7222 - val_loss: 0.8476\n",
      "Epoch 208/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9108 - loss: 0.3311 - val_accuracy: 0.7000 - val_loss: 0.8528\n",
      "Epoch 209/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8788 - loss: 0.3061 - val_accuracy: 0.7111 - val_loss: 0.8501\n",
      "Epoch 210/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8688 - loss: 0.4023 - val_accuracy: 0.7000 - val_loss: 0.8468\n",
      "Epoch 211/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8887 - loss: 0.3332 - val_accuracy: 0.7000 - val_loss: 0.8431\n",
      "Epoch 212/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8815 - loss: 0.3345 - val_accuracy: 0.7000 - val_loss: 0.8452\n",
      "Epoch 213/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9265 - loss: 0.2553 - val_accuracy: 0.7000 - val_loss: 0.8507\n",
      "Epoch 214/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8550 - loss: 0.3841 - val_accuracy: 0.7000 - val_loss: 0.8632\n",
      "Epoch 215/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8989 - loss: 0.2830 - val_accuracy: 0.7000 - val_loss: 0.8707\n",
      "Epoch 216/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9183 - loss: 0.2664 - val_accuracy: 0.7000 - val_loss: 0.8674\n",
      "Epoch 217/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9237 - loss: 0.2927 - val_accuracy: 0.7000 - val_loss: 0.8703\n",
      "Epoch 218/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9127 - loss: 0.2791 - val_accuracy: 0.7000 - val_loss: 0.8731\n",
      "Epoch 219/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9212 - loss: 0.2449 - val_accuracy: 0.7000 - val_loss: 0.8763\n",
      "Epoch 220/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9102 - loss: 0.2588 - val_accuracy: 0.6889 - val_loss: 0.8778\n",
      "Epoch 221/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8868 - loss: 0.3313 - val_accuracy: 0.6889 - val_loss: 0.8776\n",
      "Epoch 222/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8892 - loss: 0.2938 - val_accuracy: 0.7000 - val_loss: 0.8748\n",
      "Epoch 223/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9261 - loss: 0.2786 - val_accuracy: 0.7000 - val_loss: 0.8775\n",
      "Epoch 224/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9306 - loss: 0.2206 - val_accuracy: 0.7000 - val_loss: 0.8806\n",
      "Epoch 225/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9070 - loss: 0.2776 - val_accuracy: 0.7000 - val_loss: 0.8797\n",
      "Epoch 226/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8933 - loss: 0.2921 - val_accuracy: 0.7000 - val_loss: 0.8751\n",
      "Epoch 227/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8936 - loss: 0.3126 - val_accuracy: 0.7111 - val_loss: 0.8693\n",
      "Epoch 228/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9438 - loss: 0.2254 - val_accuracy: 0.7111 - val_loss: 0.8696\n",
      "Epoch 229/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9078 - loss: 0.2694 - val_accuracy: 0.7111 - val_loss: 0.8732\n",
      "Epoch 230/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9177 - loss: 0.2505 - val_accuracy: 0.7111 - val_loss: 0.8850\n",
      "Epoch 231/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9218 - loss: 0.2242 - val_accuracy: 0.7000 - val_loss: 0.8923\n",
      "Epoch 232/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9043 - loss: 0.2892 - val_accuracy: 0.7000 - val_loss: 0.8964\n",
      "Epoch 233/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8989 - loss: 0.2484 - val_accuracy: 0.7000 - val_loss: 0.8968\n",
      "Epoch 234/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9022 - loss: 0.2626 - val_accuracy: 0.7000 - val_loss: 0.8969\n",
      "Epoch 235/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9232 - loss: 0.2235 - val_accuracy: 0.7111 - val_loss: 0.8909\n",
      "Epoch 236/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9109 - loss: 0.2406 - val_accuracy: 0.7111 - val_loss: 0.8962\n",
      "Epoch 237/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9139 - loss: 0.2792 - val_accuracy: 0.7111 - val_loss: 0.9064\n",
      "Epoch 238/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9322 - loss: 0.2152 - val_accuracy: 0.7000 - val_loss: 0.9093\n",
      "Epoch 239/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9492 - loss: 0.1893 - val_accuracy: 0.7000 - val_loss: 0.9099\n",
      "Epoch 240/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9426 - loss: 0.1814 - val_accuracy: 0.7000 - val_loss: 0.9061\n",
      "Epoch 241/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8923 - loss: 0.2918 - val_accuracy: 0.7000 - val_loss: 0.9089\n",
      "Epoch 242/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9254 - loss: 0.2510 - val_accuracy: 0.7000 - val_loss: 0.9103\n",
      "Epoch 243/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9014 - loss: 0.2670 - val_accuracy: 0.7000 - val_loss: 0.9116\n",
      "Epoch 244/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9116 - loss: 0.2637 - val_accuracy: 0.7000 - val_loss: 0.8994\n",
      "Epoch 245/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9115 - loss: 0.2352 - val_accuracy: 0.7111 - val_loss: 0.8925\n",
      "Epoch 246/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9334 - loss: 0.1796 - val_accuracy: 0.7111 - val_loss: 0.8861\n",
      "Epoch 247/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9307 - loss: 0.2219 - val_accuracy: 0.7000 - val_loss: 0.8836\n",
      "Epoch 248/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9053 - loss: 0.2452 - val_accuracy: 0.7111 - val_loss: 0.8926\n",
      "Epoch 249/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9335 - loss: 0.2175 - val_accuracy: 0.7000 - val_loss: 0.9073\n",
      "Epoch 250/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9297 - loss: 0.2185 - val_accuracy: 0.7000 - val_loss: 0.9205\n",
      "Epoch 251/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9073 - loss: 0.2582 - val_accuracy: 0.7000 - val_loss: 0.9311\n",
      "Epoch 252/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9362 - loss: 0.2178 - val_accuracy: 0.7000 - val_loss: 0.9342\n",
      "Epoch 253/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9351 - loss: 0.1949 - val_accuracy: 0.7000 - val_loss: 0.9386\n",
      "Epoch 254/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9483 - loss: 0.1764 - val_accuracy: 0.7000 - val_loss: 0.9435\n",
      "Epoch 255/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8680 - loss: 0.3007 - val_accuracy: 0.6889 - val_loss: 0.9433\n",
      "Epoch 256/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9237 - loss: 0.2115 - val_accuracy: 0.6889 - val_loss: 0.9453\n",
      "Epoch 257/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9073 - loss: 0.2266 - val_accuracy: 0.7000 - val_loss: 0.9435\n",
      "Epoch 258/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9231 - loss: 0.2400 - val_accuracy: 0.7111 - val_loss: 0.9442\n",
      "Epoch 259/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9282 - loss: 0.2094 - val_accuracy: 0.7111 - val_loss: 0.9485\n",
      "Epoch 260/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.2267 - val_accuracy: 0.7111 - val_loss: 0.9546\n",
      "Epoch 261/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9341 - loss: 0.2008 - val_accuracy: 0.7111 - val_loss: 0.9565\n",
      "Epoch 262/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9051 - loss: 0.2528 - val_accuracy: 0.7111 - val_loss: 0.9524\n",
      "Epoch 263/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9456 - loss: 0.1870 - val_accuracy: 0.7111 - val_loss: 0.9435\n",
      "Epoch 264/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9417 - loss: 0.1949 - val_accuracy: 0.7222 - val_loss: 0.9414\n",
      "Epoch 265/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9034 - loss: 0.2557 - val_accuracy: 0.7111 - val_loss: 0.9378\n",
      "Epoch 266/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9378 - loss: 0.2112 - val_accuracy: 0.7111 - val_loss: 0.9419\n",
      "Epoch 267/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9384 - loss: 0.1981 - val_accuracy: 0.7111 - val_loss: 0.9449\n",
      "Epoch 268/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9228 - loss: 0.2185 - val_accuracy: 0.7111 - val_loss: 0.9505\n",
      "Epoch 269/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9434 - loss: 0.1683 - val_accuracy: 0.7000 - val_loss: 0.9591\n",
      "Epoch 270/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9245 - loss: 0.2160 - val_accuracy: 0.7111 - val_loss: 0.9731\n",
      "Epoch 271/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9320 - loss: 0.1944 - val_accuracy: 0.7222 - val_loss: 0.9787\n",
      "Epoch 272/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9573 - loss: 0.1458 - val_accuracy: 0.7111 - val_loss: 0.9790\n",
      "Epoch 273/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9288 - loss: 0.2306 - val_accuracy: 0.7111 - val_loss: 0.9832\n",
      "Epoch 274/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9633 - loss: 0.1602 - val_accuracy: 0.7111 - val_loss: 0.9622\n",
      "Epoch 275/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9371 - loss: 0.1771 - val_accuracy: 0.7222 - val_loss: 0.9383\n",
      "Epoch 276/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9372 - loss: 0.1866 - val_accuracy: 0.7111 - val_loss: 0.9261\n",
      "Epoch 277/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9450 - loss: 0.1857 - val_accuracy: 0.7111 - val_loss: 0.9180\n",
      "Epoch 278/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9472 - loss: 0.1839 - val_accuracy: 0.7111 - val_loss: 0.9142\n",
      "Epoch 279/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9490 - loss: 0.1895 - val_accuracy: 0.7222 - val_loss: 0.9316\n",
      "Epoch 280/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9612 - loss: 0.1399 - val_accuracy: 0.7222 - val_loss: 0.9430\n",
      "Epoch 281/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9576 - loss: 0.1370 - val_accuracy: 0.7111 - val_loss: 0.9547\n",
      "Epoch 282/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9463 - loss: 0.1477 - val_accuracy: 0.7111 - val_loss: 0.9606\n",
      "Epoch 283/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9493 - loss: 0.1970 - val_accuracy: 0.7222 - val_loss: 0.9709\n",
      "Epoch 284/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9394 - loss: 0.1719 - val_accuracy: 0.7222 - val_loss: 0.9786\n",
      "Epoch 285/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9442 - loss: 0.1498 - val_accuracy: 0.7222 - val_loss: 0.9877\n",
      "Epoch 286/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9672 - loss: 0.1295 - val_accuracy: 0.7222 - val_loss: 0.9880\n",
      "Epoch 287/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9434 - loss: 0.1642 - val_accuracy: 0.7222 - val_loss: 0.9625\n",
      "Epoch 288/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9399 - loss: 0.1478 - val_accuracy: 0.7222 - val_loss: 0.9600\n",
      "Epoch 289/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9433 - loss: 0.1646 - val_accuracy: 0.7222 - val_loss: 0.9755\n",
      "Epoch 290/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9274 - loss: 0.1977 - val_accuracy: 0.7222 - val_loss: 0.9890\n",
      "Epoch 291/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9338 - loss: 0.1923 - val_accuracy: 0.7222 - val_loss: 0.9990\n",
      "Epoch 292/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9742 - loss: 0.1498 - val_accuracy: 0.7222 - val_loss: 0.9886\n",
      "Epoch 293/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9421 - loss: 0.1885 - val_accuracy: 0.7222 - val_loss: 0.9714\n",
      "Epoch 294/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9734 - loss: 0.1154 - val_accuracy: 0.7222 - val_loss: 0.9703\n",
      "Epoch 295/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9660 - loss: 0.1526 - val_accuracy: 0.7222 - val_loss: 0.9701\n",
      "Epoch 296/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9532 - loss: 0.1454 - val_accuracy: 0.7222 - val_loss: 0.9838\n",
      "Epoch 297/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9443 - loss: 0.1434 - val_accuracy: 0.7222 - val_loss: 1.0037\n",
      "Epoch 298/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9512 - loss: 0.1544 - val_accuracy: 0.7222 - val_loss: 1.0078\n",
      "Epoch 299/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9387 - loss: 0.1950 - val_accuracy: 0.7111 - val_loss: 1.0032\n",
      "Epoch 300/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9616 - loss: 0.1494 - val_accuracy: 0.7111 - val_loss: 0.9927\n",
      "Epoch 301/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9618 - loss: 0.1349 - val_accuracy: 0.7222 - val_loss: 0.9844\n",
      "Epoch 302/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9415 - loss: 0.1562 - val_accuracy: 0.7222 - val_loss: 0.9807\n",
      "Epoch 303/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9787 - loss: 0.1114 - val_accuracy: 0.7111 - val_loss: 0.9866\n",
      "Epoch 304/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9350 - loss: 0.1594 - val_accuracy: 0.7111 - val_loss: 1.0086\n",
      "Epoch 305/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9447 - loss: 0.1994 - val_accuracy: 0.7111 - val_loss: 1.0266\n",
      "Epoch 306/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9394 - loss: 0.1713 - val_accuracy: 0.7111 - val_loss: 1.0313\n",
      "Epoch 307/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9367 - loss: 0.1467 - val_accuracy: 0.7111 - val_loss: 1.0221\n",
      "Epoch 308/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9381 - loss: 0.1378 - val_accuracy: 0.7000 - val_loss: 1.0215\n",
      "Epoch 309/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9517 - loss: 0.1426 - val_accuracy: 0.7222 - val_loss: 0.9989\n",
      "Epoch 310/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9699 - loss: 0.1223 - val_accuracy: 0.7222 - val_loss: 0.9789\n",
      "Epoch 311/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9682 - loss: 0.0976 - val_accuracy: 0.7111 - val_loss: 0.9913\n",
      "Epoch 312/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9614 - loss: 0.1361 - val_accuracy: 0.7111 - val_loss: 1.0078\n",
      "Epoch 313/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9596 - loss: 0.1333 - val_accuracy: 0.7000 - val_loss: 1.0164\n",
      "Epoch 314/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9631 - loss: 0.1380 - val_accuracy: 0.7000 - val_loss: 1.0145\n",
      "Epoch 315/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9605 - loss: 0.1499 - val_accuracy: 0.7111 - val_loss: 1.0154\n",
      "Epoch 316/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9630 - loss: 0.1018 - val_accuracy: 0.7111 - val_loss: 1.0197\n",
      "Epoch 317/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9577 - loss: 0.1373 - val_accuracy: 0.7111 - val_loss: 1.0258\n",
      "Epoch 318/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9534 - loss: 0.1244 - val_accuracy: 0.7222 - val_loss: 1.0352\n",
      "Epoch 319/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9535 - loss: 0.1232 - val_accuracy: 0.7222 - val_loss: 1.0332\n",
      "Epoch 320/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9393 - loss: 0.1527 - val_accuracy: 0.7222 - val_loss: 1.0219\n",
      "Epoch 321/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9582 - loss: 0.1296 - val_accuracy: 0.7222 - val_loss: 1.0094\n",
      "Epoch 322/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9465 - loss: 0.1496 - val_accuracy: 0.7222 - val_loss: 0.9985\n",
      "Epoch 323/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9596 - loss: 0.1310 - val_accuracy: 0.7333 - val_loss: 1.0012\n",
      "Epoch 324/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9462 - loss: 0.1302 - val_accuracy: 0.7222 - val_loss: 1.0123\n",
      "Epoch 325/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9470 - loss: 0.1180 - val_accuracy: 0.7222 - val_loss: 1.0181\n",
      "Epoch 326/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9520 - loss: 0.1555 - val_accuracy: 0.7111 - val_loss: 1.0287\n",
      "Epoch 327/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9599 - loss: 0.1283 - val_accuracy: 0.7111 - val_loss: 1.0433\n",
      "Epoch 328/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9477 - loss: 0.1318 - val_accuracy: 0.7222 - val_loss: 1.0469\n",
      "Epoch 329/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9587 - loss: 0.1286 - val_accuracy: 0.7222 - val_loss: 1.0560\n",
      "Epoch 330/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9690 - loss: 0.1055 - val_accuracy: 0.7222 - val_loss: 1.0692\n",
      "Epoch 331/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9654 - loss: 0.1168 - val_accuracy: 0.7333 - val_loss: 1.0617\n",
      "Epoch 332/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9718 - loss: 0.0967 - val_accuracy: 0.7333 - val_loss: 1.0478\n",
      "Epoch 333/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9640 - loss: 0.1101 - val_accuracy: 0.7333 - val_loss: 1.0447\n",
      "Epoch 334/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9678 - loss: 0.1142 - val_accuracy: 0.7333 - val_loss: 1.0496\n",
      "Epoch 335/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9332 - loss: 0.1550 - val_accuracy: 0.7222 - val_loss: 1.0422\n",
      "Epoch 336/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9702 - loss: 0.0979 - val_accuracy: 0.7444 - val_loss: 1.0276\n",
      "Epoch 337/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9496 - loss: 0.1217 - val_accuracy: 0.7333 - val_loss: 1.0078\n",
      "Epoch 338/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1087 - val_accuracy: 0.7222 - val_loss: 1.0071\n",
      "Epoch 339/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9497 - loss: 0.1498 - val_accuracy: 0.7333 - val_loss: 1.0095\n",
      "Epoch 340/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9600 - loss: 0.1156 - val_accuracy: 0.7111 - val_loss: 1.0156\n",
      "Epoch 341/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9822 - loss: 0.0862 - val_accuracy: 0.7111 - val_loss: 1.0235\n",
      "Epoch 342/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9592 - loss: 0.1445 - val_accuracy: 0.7000 - val_loss: 1.0301\n",
      "Epoch 343/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9759 - loss: 0.1131 - val_accuracy: 0.7111 - val_loss: 1.0352\n",
      "Epoch 344/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9731 - loss: 0.1074 - val_accuracy: 0.7111 - val_loss: 1.0433\n",
      "Epoch 345/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9662 - loss: 0.0963 - val_accuracy: 0.7000 - val_loss: 1.0405\n",
      "Epoch 346/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: 0.1080 - val_accuracy: 0.7000 - val_loss: 1.0406\n",
      "Epoch 347/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9760 - loss: 0.0889 - val_accuracy: 0.7000 - val_loss: 1.0401\n",
      "Epoch 348/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9792 - loss: 0.0828 - val_accuracy: 0.7000 - val_loss: 1.0493\n",
      "Epoch 349/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9602 - loss: 0.1125 - val_accuracy: 0.7111 - val_loss: 1.0407\n",
      "Epoch 350/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9784 - loss: 0.0882 - val_accuracy: 0.7333 - val_loss: 1.0274\n",
      "Epoch 351/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9420 - loss: 0.1392 - val_accuracy: 0.7333 - val_loss: 0.9938\n",
      "Epoch 352/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9637 - loss: 0.1160 - val_accuracy: 0.7333 - val_loss: 0.9936\n",
      "Epoch 353/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9600 - loss: 0.0996 - val_accuracy: 0.7333 - val_loss: 0.9993\n",
      "Epoch 354/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9612 - loss: 0.1146 - val_accuracy: 0.7333 - val_loss: 1.0146\n",
      "Epoch 355/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9596 - loss: 0.1231 - val_accuracy: 0.7333 - val_loss: 1.0317\n",
      "Epoch 356/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0716 - val_accuracy: 0.7333 - val_loss: 1.0424\n",
      "Epoch 357/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9807 - loss: 0.0938 - val_accuracy: 0.7222 - val_loss: 1.0529\n",
      "Epoch 358/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9840 - loss: 0.0880 - val_accuracy: 0.7222 - val_loss: 1.0605\n",
      "Epoch 359/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9769 - loss: 0.0861 - val_accuracy: 0.7333 - val_loss: 1.0677\n",
      "Epoch 360/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9633 - loss: 0.0984 - val_accuracy: 0.7333 - val_loss: 1.0673\n",
      "Epoch 361/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9692 - loss: 0.0765 - val_accuracy: 0.7222 - val_loss: 1.0588\n",
      "Epoch 362/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9550 - loss: 0.1051 - val_accuracy: 0.7222 - val_loss: 1.0593\n",
      "Epoch 363/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9628 - loss: 0.1471 - val_accuracy: 0.7333 - val_loss: 1.0635\n",
      "Epoch 364/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9752 - loss: 0.0921 - val_accuracy: 0.7444 - val_loss: 1.0684\n",
      "Epoch 365/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9862 - loss: 0.0580 - val_accuracy: 0.7333 - val_loss: 1.0703\n",
      "Epoch 366/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9487 - loss: 0.1237 - val_accuracy: 0.7444 - val_loss: 1.0545\n",
      "Epoch 367/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9783 - loss: 0.0964 - val_accuracy: 0.7333 - val_loss: 1.0466\n",
      "Epoch 368/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9634 - loss: 0.0927 - val_accuracy: 0.7222 - val_loss: 1.0575\n",
      "Epoch 369/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9711 - loss: 0.0882 - val_accuracy: 0.7222 - val_loss: 1.0618\n",
      "Epoch 370/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9724 - loss: 0.0921 - val_accuracy: 0.7333 - val_loss: 1.0514\n",
      "Epoch 371/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9577 - loss: 0.1114 - val_accuracy: 0.7222 - val_loss: 1.0611\n",
      "Epoch 372/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9794 - loss: 0.0834 - val_accuracy: 0.7333 - val_loss: 1.0512\n",
      "Epoch 373/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9793 - loss: 0.0663 - val_accuracy: 0.7333 - val_loss: 1.0409\n",
      "Epoch 374/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0826 - val_accuracy: 0.7333 - val_loss: 1.0470\n",
      "Epoch 375/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9846 - loss: 0.0649 - val_accuracy: 0.7222 - val_loss: 1.0659\n",
      "Epoch 376/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9791 - loss: 0.0718 - val_accuracy: 0.7111 - val_loss: 1.0877\n",
      "Epoch 377/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9567 - loss: 0.1037 - val_accuracy: 0.7111 - val_loss: 1.1029\n",
      "Epoch 378/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9823 - loss: 0.0850 - val_accuracy: 0.7111 - val_loss: 1.0783\n",
      "Epoch 379/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9874 - loss: 0.0688 - val_accuracy: 0.7222 - val_loss: 1.0562\n",
      "Epoch 380/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9787 - loss: 0.0901 - val_accuracy: 0.7222 - val_loss: 1.0496\n",
      "Epoch 381/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.0806 - val_accuracy: 0.7222 - val_loss: 1.0594\n",
      "Epoch 382/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9884 - loss: 0.0682 - val_accuracy: 0.7111 - val_loss: 1.0753\n",
      "Epoch 383/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9738 - loss: 0.1087 - val_accuracy: 0.7111 - val_loss: 1.0995\n",
      "Epoch 384/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9838 - loss: 0.0697 - val_accuracy: 0.7111 - val_loss: 1.1013\n",
      "Epoch 385/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9675 - loss: 0.0867 - val_accuracy: 0.7222 - val_loss: 1.1003\n",
      "Epoch 386/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9582 - loss: 0.1155 - val_accuracy: 0.7333 - val_loss: 1.1163\n",
      "Epoch 387/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9788 - loss: 0.0645 - val_accuracy: 0.7333 - val_loss: 1.1301\n",
      "Epoch 388/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9581 - loss: 0.1187 - val_accuracy: 0.7333 - val_loss: 1.1402\n",
      "Epoch 389/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9804 - loss: 0.0826 - val_accuracy: 0.7222 - val_loss: 1.1633\n",
      "Epoch 390/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9657 - loss: 0.0989 - val_accuracy: 0.7222 - val_loss: 1.1717\n",
      "Epoch 391/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9538 - loss: 0.1238 - val_accuracy: 0.7333 - val_loss: 1.1694\n",
      "Epoch 392/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9736 - loss: 0.0843 - val_accuracy: 0.7333 - val_loss: 1.1641\n",
      "Epoch 393/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9708 - loss: 0.0864 - val_accuracy: 0.7333 - val_loss: 1.1613\n",
      "Epoch 394/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9739 - loss: 0.0708 - val_accuracy: 0.7333 - val_loss: 1.1591\n",
      "Epoch 395/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9748 - loss: 0.0702 - val_accuracy: 0.7333 - val_loss: 1.1714\n",
      "Epoch 396/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9746 - loss: 0.0918 - val_accuracy: 0.7222 - val_loss: 1.1852\n",
      "Epoch 397/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9716 - loss: 0.0893 - val_accuracy: 0.7222 - val_loss: 1.1870\n",
      "Epoch 398/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9789 - loss: 0.0882 - val_accuracy: 0.7222 - val_loss: 1.1880\n",
      "Epoch 399/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9756 - loss: 0.0694 - val_accuracy: 0.7222 - val_loss: 1.1810\n",
      "Epoch 400/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0504 - val_accuracy: 0.7222 - val_loss: 1.1687\n",
      "Epoch 401/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9639 - loss: 0.0775 - val_accuracy: 0.7222 - val_loss: 1.1536\n",
      "Epoch 402/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9668 - loss: 0.0884 - val_accuracy: 0.7222 - val_loss: 1.1446\n",
      "Epoch 403/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9762 - loss: 0.0791 - val_accuracy: 0.7222 - val_loss: 1.1409\n",
      "Epoch 404/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.0667 - val_accuracy: 0.7333 - val_loss: 1.1294\n",
      "Epoch 405/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9646 - loss: 0.1009 - val_accuracy: 0.7222 - val_loss: 1.1230\n",
      "Epoch 406/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9710 - loss: 0.0735 - val_accuracy: 0.7333 - val_loss: 1.1101\n",
      "Epoch 407/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9720 - loss: 0.0710 - val_accuracy: 0.7333 - val_loss: 1.1118\n",
      "Epoch 408/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9731 - loss: 0.0876 - val_accuracy: 0.7222 - val_loss: 1.1165\n",
      "Epoch 409/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9623 - loss: 0.1028 - val_accuracy: 0.7222 - val_loss: 1.1051\n",
      "Epoch 410/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9807 - loss: 0.0775 - val_accuracy: 0.7222 - val_loss: 1.0860\n",
      "Epoch 411/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9812 - loss: 0.0666 - val_accuracy: 0.7333 - val_loss: 1.0710\n",
      "Epoch 412/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9661 - loss: 0.0904 - val_accuracy: 0.7444 - val_loss: 1.0692\n",
      "Epoch 413/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9794 - loss: 0.0622 - val_accuracy: 0.7444 - val_loss: 1.0785\n",
      "Epoch 414/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9751 - loss: 0.0696 - val_accuracy: 0.7444 - val_loss: 1.0946\n",
      "Epoch 415/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9595 - loss: 0.0858 - val_accuracy: 0.7222 - val_loss: 1.1123\n",
      "Epoch 416/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9764 - loss: 0.0797 - val_accuracy: 0.7222 - val_loss: 1.1248\n",
      "Epoch 417/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9665 - loss: 0.0723 - val_accuracy: 0.7222 - val_loss: 1.1293\n",
      "Epoch 418/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0762 - val_accuracy: 0.7222 - val_loss: 1.1240\n",
      "Epoch 419/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9715 - loss: 0.0686 - val_accuracy: 0.7333 - val_loss: 1.1090\n",
      "Epoch 420/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9654 - loss: 0.1032 - val_accuracy: 0.7333 - val_loss: 1.0913\n",
      "Epoch 421/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9860 - loss: 0.0562 - val_accuracy: 0.7556 - val_loss: 1.0848\n",
      "Epoch 422/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9748 - loss: 0.0761 - val_accuracy: 0.7556 - val_loss: 1.0899\n",
      "Epoch 423/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0557 - val_accuracy: 0.7556 - val_loss: 1.0848\n",
      "Epoch 424/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9753 - loss: 0.0606 - val_accuracy: 0.7556 - val_loss: 1.0707\n",
      "Epoch 425/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9822 - loss: 0.0607 - val_accuracy: 0.7444 - val_loss: 1.0664\n",
      "Epoch 426/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.0540 - val_accuracy: 0.7333 - val_loss: 1.0751\n",
      "Epoch 427/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9578 - loss: 0.1059 - val_accuracy: 0.7333 - val_loss: 1.0971\n",
      "Epoch 428/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9933 - loss: 0.0375 - val_accuracy: 0.7333 - val_loss: 1.1156\n",
      "Epoch 429/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9838 - loss: 0.0652 - val_accuracy: 0.7333 - val_loss: 1.1194\n",
      "Epoch 430/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9881 - loss: 0.0532 - val_accuracy: 0.7222 - val_loss: 1.1269\n",
      "Epoch 431/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.0560 - val_accuracy: 0.7222 - val_loss: 1.1373\n",
      "Epoch 432/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9835 - loss: 0.0575 - val_accuracy: 0.7222 - val_loss: 1.1483\n",
      "Epoch 433/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9701 - loss: 0.0806 - val_accuracy: 0.7333 - val_loss: 1.1580\n",
      "Epoch 434/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9795 - loss: 0.0596 - val_accuracy: 0.7333 - val_loss: 1.1508\n",
      "Epoch 435/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0575 - val_accuracy: 0.7333 - val_loss: 1.1354\n",
      "Epoch 436/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9795 - loss: 0.0640 - val_accuracy: 0.7333 - val_loss: 1.1361\n",
      "Epoch 437/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9727 - loss: 0.0777 - val_accuracy: 0.7444 - val_loss: 1.1361\n",
      "Epoch 438/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9691 - loss: 0.0994 - val_accuracy: 0.7444 - val_loss: 1.1576\n",
      "Epoch 439/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9877 - loss: 0.0428 - val_accuracy: 0.7222 - val_loss: 1.1807\n",
      "Epoch 440/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9845 - loss: 0.0625 - val_accuracy: 0.7222 - val_loss: 1.1977\n",
      "Epoch 441/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0402 - val_accuracy: 0.7333 - val_loss: 1.2104\n",
      "Epoch 442/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9703 - loss: 0.0833 - val_accuracy: 0.7333 - val_loss: 1.2136\n",
      "Epoch 443/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9724 - loss: 0.0883 - val_accuracy: 0.7222 - val_loss: 1.2017\n",
      "Epoch 444/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9705 - loss: 0.0689 - val_accuracy: 0.7333 - val_loss: 1.2036\n",
      "Epoch 445/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9851 - loss: 0.0544 - val_accuracy: 0.7222 - val_loss: 1.1923\n",
      "Epoch 446/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9799 - loss: 0.0526 - val_accuracy: 0.7222 - val_loss: 1.1746\n",
      "Epoch 447/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9703 - loss: 0.1170 - val_accuracy: 0.7333 - val_loss: 1.1809\n",
      "Epoch 448/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9929 - loss: 0.0450 - val_accuracy: 0.7333 - val_loss: 1.1790\n",
      "Epoch 449/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9851 - loss: 0.0496 - val_accuracy: 0.7333 - val_loss: 1.1812\n",
      "Epoch 450/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9680 - loss: 0.0854 - val_accuracy: 0.7333 - val_loss: 1.2015\n",
      "Epoch 451/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9655 - loss: 0.0707 - val_accuracy: 0.7333 - val_loss: 1.2169\n",
      "Epoch 452/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9693 - loss: 0.0801 - val_accuracy: 0.7333 - val_loss: 1.2243\n",
      "Epoch 453/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9821 - loss: 0.0631 - val_accuracy: 0.7222 - val_loss: 1.2319\n",
      "Epoch 454/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9825 - loss: 0.0708 - val_accuracy: 0.7222 - val_loss: 1.2280\n",
      "Epoch 455/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9847 - loss: 0.0680 - val_accuracy: 0.7222 - val_loss: 1.2214\n",
      "Epoch 456/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9716 - loss: 0.0736 - val_accuracy: 0.7333 - val_loss: 1.2226\n",
      "Epoch 457/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9714 - loss: 0.0750 - val_accuracy: 0.7333 - val_loss: 1.2308\n",
      "Epoch 458/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9835 - loss: 0.0514 - val_accuracy: 0.7222 - val_loss: 1.2212\n",
      "Epoch 459/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9768 - loss: 0.0707 - val_accuracy: 0.7222 - val_loss: 1.2089\n",
      "Epoch 460/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9705 - loss: 0.0672 - val_accuracy: 0.7333 - val_loss: 1.2039\n",
      "Epoch 461/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9768 - loss: 0.0712 - val_accuracy: 0.7222 - val_loss: 1.2126\n",
      "Epoch 462/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9923 - loss: 0.0510 - val_accuracy: 0.7111 - val_loss: 1.2404\n",
      "Epoch 463/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9739 - loss: 0.0866 - val_accuracy: 0.7222 - val_loss: 1.2607\n",
      "Epoch 464/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9905 - loss: 0.0516 - val_accuracy: 0.7222 - val_loss: 1.2939\n",
      "Epoch 465/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9800 - loss: 0.0505 - val_accuracy: 0.7222 - val_loss: 1.3013\n",
      "Epoch 466/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9805 - loss: 0.0611 - val_accuracy: 0.7222 - val_loss: 1.2964\n",
      "Epoch 467/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9779 - loss: 0.0639 - val_accuracy: 0.7222 - val_loss: 1.2823\n",
      "Epoch 468/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9851 - loss: 0.0605 - val_accuracy: 0.7222 - val_loss: 1.2581\n",
      "Epoch 469/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9858 - loss: 0.0607 - val_accuracy: 0.7333 - val_loss: 1.2402\n",
      "Epoch 470/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9744 - loss: 0.0695 - val_accuracy: 0.7333 - val_loss: 1.2256\n",
      "Epoch 471/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9854 - loss: 0.0451 - val_accuracy: 0.7444 - val_loss: 1.2121\n",
      "Epoch 472/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9774 - loss: 0.0555 - val_accuracy: 0.7444 - val_loss: 1.2146\n",
      "Epoch 473/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0278 - val_accuracy: 0.7333 - val_loss: 1.2249\n",
      "Epoch 474/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9887 - loss: 0.0525 - val_accuracy: 0.7333 - val_loss: 1.2411\n",
      "Epoch 475/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9820 - loss: 0.0698 - val_accuracy: 0.7222 - val_loss: 1.2610\n",
      "Epoch 476/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9704 - loss: 0.0682 - val_accuracy: 0.7222 - val_loss: 1.2706\n",
      "Epoch 477/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9890 - loss: 0.0575 - val_accuracy: 0.7222 - val_loss: 1.2880\n",
      "Epoch 478/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9928 - loss: 0.0540 - val_accuracy: 0.7222 - val_loss: 1.2949\n",
      "Epoch 479/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9907 - loss: 0.0396 - val_accuracy: 0.7222 - val_loss: 1.3093\n",
      "Epoch 480/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9717 - loss: 0.0790 - val_accuracy: 0.7222 - val_loss: 1.3137\n",
      "Epoch 481/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9908 - loss: 0.0476 - val_accuracy: 0.7222 - val_loss: 1.3073\n",
      "Epoch 482/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9823 - loss: 0.0739 - val_accuracy: 0.7222 - val_loss: 1.2895\n",
      "Epoch 483/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9890 - loss: 0.0423 - val_accuracy: 0.7333 - val_loss: 1.2553\n",
      "Epoch 484/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9902 - loss: 0.0470 - val_accuracy: 0.7333 - val_loss: 1.2415\n",
      "Epoch 485/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9970 - loss: 0.0358 - val_accuracy: 0.7333 - val_loss: 1.2364\n",
      "Epoch 486/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9962 - loss: 0.0416 - val_accuracy: 0.7333 - val_loss: 1.2340\n",
      "Epoch 487/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9792 - loss: 0.0757 - val_accuracy: 0.7444 - val_loss: 1.2444\n",
      "Epoch 488/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9811 - loss: 0.0513 - val_accuracy: 0.7444 - val_loss: 1.2615\n",
      "Epoch 489/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9791 - loss: 0.0587 - val_accuracy: 0.7444 - val_loss: 1.2731\n",
      "Epoch 490/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9785 - loss: 0.0635 - val_accuracy: 0.7444 - val_loss: 1.2816\n",
      "Epoch 491/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9838 - loss: 0.0474 - val_accuracy: 0.7444 - val_loss: 1.2914\n",
      "Epoch 492/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9860 - loss: 0.0560 - val_accuracy: 0.7556 - val_loss: 1.2925\n",
      "Epoch 493/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.0509 - val_accuracy: 0.7556 - val_loss: 1.3182\n",
      "Epoch 494/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0374 - val_accuracy: 0.7556 - val_loss: 1.3258\n",
      "Epoch 495/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.0339 - val_accuracy: 0.7778 - val_loss: 1.3328\n",
      "Epoch 496/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.0676 - val_accuracy: 0.7556 - val_loss: 1.3320\n",
      "Epoch 497/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9914 - loss: 0.0259 - val_accuracy: 0.7556 - val_loss: 1.3368\n",
      "Epoch 498/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9901 - loss: 0.0428 - val_accuracy: 0.7333 - val_loss: 1.3422\n",
      "Epoch 499/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9826 - loss: 0.0676 - val_accuracy: 0.7333 - val_loss: 1.3237\n",
      "Epoch 500/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9885 - loss: 0.0533 - val_accuracy: 0.7333 - val_loss: 1.2979\n",
      "Epoch 501/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9860 - loss: 0.0585 - val_accuracy: 0.7444 - val_loss: 1.3088\n",
      "Epoch 502/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0396 - val_accuracy: 0.7444 - val_loss: 1.3088\n",
      "Epoch 503/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9830 - loss: 0.0511 - val_accuracy: 0.7556 - val_loss: 1.3255\n",
      "Epoch 504/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.0544 - val_accuracy: 0.7556 - val_loss: 1.3439\n",
      "Epoch 505/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9925 - loss: 0.0426 - val_accuracy: 0.7444 - val_loss: 1.3578\n",
      "Epoch 506/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9894 - loss: 0.0515 - val_accuracy: 0.7444 - val_loss: 1.3692\n",
      "Epoch 507/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0332 - val_accuracy: 0.7333 - val_loss: 1.3734\n",
      "Epoch 508/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9775 - loss: 0.0665 - val_accuracy: 0.7556 - val_loss: 1.3586\n",
      "Epoch 509/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.0423 - val_accuracy: 0.7444 - val_loss: 1.3695\n",
      "Epoch 510/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9823 - loss: 0.0518 - val_accuracy: 0.7444 - val_loss: 1.3642\n",
      "Epoch 511/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.0465 - val_accuracy: 0.7444 - val_loss: 1.3530\n",
      "Epoch 512/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9867 - loss: 0.0542 - val_accuracy: 0.7556 - val_loss: 1.3196\n",
      "Epoch 513/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9964 - loss: 0.0216 - val_accuracy: 0.7667 - val_loss: 1.2933\n",
      "Epoch 514/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9927 - loss: 0.0293 - val_accuracy: 0.7778 - val_loss: 1.2818\n",
      "Epoch 515/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9870 - loss: 0.0378 - val_accuracy: 0.7778 - val_loss: 1.2890\n",
      "Epoch 516/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9847 - loss: 0.0549 - val_accuracy: 0.7778 - val_loss: 1.2885\n",
      "Epoch 517/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9731 - loss: 0.0835 - val_accuracy: 0.7778 - val_loss: 1.2835\n",
      "Epoch 518/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9763 - loss: 0.0671 - val_accuracy: 0.7667 - val_loss: 1.3076\n",
      "Epoch 519/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9908 - loss: 0.0271 - val_accuracy: 0.7556 - val_loss: 1.3354\n",
      "Epoch 520/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.0379 - val_accuracy: 0.7444 - val_loss: 1.3505\n",
      "Epoch 521/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9816 - loss: 0.0509 - val_accuracy: 0.7444 - val_loss: 1.3308\n",
      "Epoch 522/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9954 - loss: 0.0204 - val_accuracy: 0.7556 - val_loss: 1.3032\n",
      "Epoch 523/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9762 - loss: 0.0531 - val_accuracy: 0.7667 - val_loss: 1.2890\n",
      "Epoch 524/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9933 - loss: 0.0221 - val_accuracy: 0.7667 - val_loss: 1.2708\n",
      "Epoch 525/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9820 - loss: 0.0571 - val_accuracy: 0.7667 - val_loss: 1.2522\n",
      "Epoch 526/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0249 - val_accuracy: 0.7667 - val_loss: 1.2403\n",
      "Epoch 527/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0236 - val_accuracy: 0.7667 - val_loss: 1.2363\n",
      "Epoch 528/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9885 - loss: 0.0431 - val_accuracy: 0.7667 - val_loss: 1.2494\n",
      "Epoch 529/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9842 - loss: 0.0515 - val_accuracy: 0.7556 - val_loss: 1.2532\n",
      "Epoch 530/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9883 - loss: 0.0357 - val_accuracy: 0.7556 - val_loss: 1.2563\n",
      "Epoch 531/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9819 - loss: 0.0518 - val_accuracy: 0.7556 - val_loss: 1.2555\n",
      "Epoch 532/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.0369 - val_accuracy: 0.7667 - val_loss: 1.2560\n",
      "Epoch 533/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9876 - loss: 0.0411 - val_accuracy: 0.7667 - val_loss: 1.2501\n",
      "Epoch 534/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9862 - loss: 0.0542 - val_accuracy: 0.7556 - val_loss: 1.2751\n",
      "Epoch 535/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9860 - loss: 0.0564 - val_accuracy: 0.7333 - val_loss: 1.3020\n",
      "Epoch 536/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9939 - loss: 0.0314 - val_accuracy: 0.7333 - val_loss: 1.3094\n",
      "Epoch 537/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9904 - loss: 0.0537 - val_accuracy: 0.7222 - val_loss: 1.3123\n",
      "Epoch 538/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0376 - val_accuracy: 0.7333 - val_loss: 1.3016\n",
      "Epoch 539/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0424 - val_accuracy: 0.7444 - val_loss: 1.2758\n",
      "Epoch 540/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9970 - loss: 0.0296 - val_accuracy: 0.7556 - val_loss: 1.2691\n",
      "Epoch 541/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9830 - loss: 0.0642 - val_accuracy: 0.7667 - val_loss: 1.2677\n",
      "Epoch 542/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0259 - val_accuracy: 0.7667 - val_loss: 1.2813\n",
      "Epoch 543/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9884 - loss: 0.0360 - val_accuracy: 0.7667 - val_loss: 1.2948\n",
      "Epoch 544/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9864 - loss: 0.0411 - val_accuracy: 0.7667 - val_loss: 1.3017\n",
      "Epoch 545/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9835 - loss: 0.0325 - val_accuracy: 0.7667 - val_loss: 1.2875\n",
      "Epoch 546/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9831 - loss: 0.0625 - val_accuracy: 0.7778 - val_loss: 1.2673\n",
      "Epoch 547/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.0470 - val_accuracy: 0.7778 - val_loss: 1.2504\n",
      "Epoch 548/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0343 - val_accuracy: 0.7667 - val_loss: 1.2319\n",
      "Epoch 549/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9918 - loss: 0.0303 - val_accuracy: 0.7667 - val_loss: 1.2221\n",
      "Epoch 550/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0231 - val_accuracy: 0.7667 - val_loss: 1.2237\n",
      "Epoch 551/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0282 - val_accuracy: 0.7667 - val_loss: 1.2302\n",
      "Epoch 552/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9877 - loss: 0.0382 - val_accuracy: 0.7667 - val_loss: 1.2492\n",
      "Epoch 553/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9905 - loss: 0.0308 - val_accuracy: 0.7667 - val_loss: 1.2553\n",
      "Epoch 554/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9821 - loss: 0.0715 - val_accuracy: 0.7667 - val_loss: 1.2686\n",
      "Epoch 555/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.0414 - val_accuracy: 0.7667 - val_loss: 1.2840\n",
      "Epoch 556/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9796 - loss: 0.0476 - val_accuracy: 0.7667 - val_loss: 1.2848\n",
      "Epoch 557/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9905 - loss: 0.0360 - val_accuracy: 0.7667 - val_loss: 1.2803\n",
      "Epoch 558/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0292 - val_accuracy: 0.7667 - val_loss: 1.2820\n",
      "Epoch 559/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0304 - val_accuracy: 0.7778 - val_loss: 1.2772\n",
      "Epoch 560/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9827 - loss: 0.0569 - val_accuracy: 0.7778 - val_loss: 1.2835\n",
      "Epoch 561/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.0350 - val_accuracy: 0.7667 - val_loss: 1.2844\n",
      "Epoch 562/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0363 - val_accuracy: 0.7667 - val_loss: 1.3023\n",
      "Epoch 563/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.0511 - val_accuracy: 0.7667 - val_loss: 1.2882\n",
      "Epoch 564/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.0369 - val_accuracy: 0.7667 - val_loss: 1.2608\n",
      "Epoch 565/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.0491 - val_accuracy: 0.7667 - val_loss: 1.2540\n",
      "Epoch 566/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9867 - loss: 0.0539 - val_accuracy: 0.7667 - val_loss: 1.2678\n",
      "Epoch 567/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9687 - loss: 0.0727 - val_accuracy: 0.7667 - val_loss: 1.2907\n",
      "Epoch 568/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0230 - val_accuracy: 0.7667 - val_loss: 1.3276\n",
      "Epoch 569/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0235 - val_accuracy: 0.7667 - val_loss: 1.3506\n",
      "Epoch 570/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9852 - loss: 0.0473 - val_accuracy: 0.7556 - val_loss: 1.3756\n",
      "Epoch 571/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 0.7667 - val_loss: 1.3733\n",
      "Epoch 572/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9904 - loss: 0.0323 - val_accuracy: 0.7778 - val_loss: 1.3744\n",
      "Epoch 573/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9916 - loss: 0.0316 - val_accuracy: 0.7778 - val_loss: 1.3951\n",
      "Epoch 574/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0231 - val_accuracy: 0.7778 - val_loss: 1.4061\n",
      "Epoch 575/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.0373 - val_accuracy: 0.7667 - val_loss: 1.4039\n",
      "Epoch 576/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9938 - loss: 0.0375 - val_accuracy: 0.7556 - val_loss: 1.4007\n",
      "Epoch 577/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9980 - loss: 0.0215 - val_accuracy: 0.7556 - val_loss: 1.3985\n",
      "Epoch 578/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0310 - val_accuracy: 0.7444 - val_loss: 1.4143\n",
      "Epoch 579/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9939 - loss: 0.0354 - val_accuracy: 0.7556 - val_loss: 1.4180\n",
      "Epoch 580/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0358 - val_accuracy: 0.7444 - val_loss: 1.4184\n",
      "Epoch 581/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9948 - loss: 0.0208 - val_accuracy: 0.7556 - val_loss: 1.4119\n",
      "Epoch 582/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9764 - loss: 0.0482 - val_accuracy: 0.7444 - val_loss: 1.4208\n",
      "Epoch 583/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 0.0266 - val_accuracy: 0.7444 - val_loss: 1.4347\n",
      "Epoch 584/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9864 - loss: 0.0258 - val_accuracy: 0.7444 - val_loss: 1.4444\n",
      "Epoch 585/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9838 - loss: 0.0316 - val_accuracy: 0.7444 - val_loss: 1.4653\n",
      "Epoch 586/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9849 - loss: 0.0406 - val_accuracy: 0.7556 - val_loss: 1.4933\n",
      "Epoch 587/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0280 - val_accuracy: 0.7556 - val_loss: 1.5132\n",
      "Epoch 588/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9934 - loss: 0.0214 - val_accuracy: 0.7333 - val_loss: 1.5134\n",
      "Epoch 589/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0297 - val_accuracy: 0.7333 - val_loss: 1.5038\n",
      "Epoch 590/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9897 - loss: 0.0470 - val_accuracy: 0.7444 - val_loss: 1.4914\n",
      "Epoch 591/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9849 - loss: 0.0304 - val_accuracy: 0.7444 - val_loss: 1.4933\n",
      "Epoch 592/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9839 - loss: 0.0276 - val_accuracy: 0.7444 - val_loss: 1.4988\n",
      "Epoch 593/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9854 - loss: 0.0429 - val_accuracy: 0.7444 - val_loss: 1.4924\n",
      "Epoch 594/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0321 - val_accuracy: 0.7556 - val_loss: 1.4872\n",
      "Epoch 595/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9980 - loss: 0.0194 - val_accuracy: 0.7556 - val_loss: 1.4971\n",
      "Epoch 596/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0312 - val_accuracy: 0.7667 - val_loss: 1.5154\n",
      "Epoch 597/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0254 - val_accuracy: 0.7667 - val_loss: 1.5308\n",
      "Epoch 598/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9939 - loss: 0.0315 - val_accuracy: 0.7667 - val_loss: 1.5191\n",
      "Epoch 599/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0164 - val_accuracy: 0.7444 - val_loss: 1.5158\n",
      "Epoch 600/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9820 - loss: 0.0528 - val_accuracy: 0.7333 - val_loss: 1.5332\n",
      "Epoch 601/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9865 - loss: 0.0378 - val_accuracy: 0.7222 - val_loss: 1.5288\n",
      "Epoch 602/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0310 - val_accuracy: 0.7333 - val_loss: 1.5081\n",
      "Epoch 603/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9887 - loss: 0.0427 - val_accuracy: 0.7333 - val_loss: 1.4855\n",
      "Epoch 604/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.0329 - val_accuracy: 0.7444 - val_loss: 1.4626\n",
      "Epoch 605/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9810 - loss: 0.0371 - val_accuracy: 0.7444 - val_loss: 1.4551\n",
      "Epoch 606/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9944 - loss: 0.0210 - val_accuracy: 0.7444 - val_loss: 1.4515\n",
      "Epoch 607/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0321 - val_accuracy: 0.7444 - val_loss: 1.4347\n",
      "Epoch 608/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9808 - loss: 0.0636 - val_accuracy: 0.7556 - val_loss: 1.4261\n",
      "Epoch 609/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0187 - val_accuracy: 0.7556 - val_loss: 1.4256\n",
      "Epoch 610/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9982 - loss: 0.0143 - val_accuracy: 0.7556 - val_loss: 1.4273\n",
      "Epoch 611/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0201 - val_accuracy: 0.7556 - val_loss: 1.4267\n",
      "Epoch 612/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9838 - loss: 0.0495 - val_accuracy: 0.7556 - val_loss: 1.4323\n",
      "Epoch 613/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9885 - loss: 0.0449 - val_accuracy: 0.7556 - val_loss: 1.4198\n",
      "Epoch 614/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0190 - val_accuracy: 0.7556 - val_loss: 1.4163\n",
      "Epoch 615/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0404 - val_accuracy: 0.7556 - val_loss: 1.4118\n",
      "Epoch 616/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0194 - val_accuracy: 0.7556 - val_loss: 1.4025\n",
      "Epoch 617/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9824 - loss: 0.0404 - val_accuracy: 0.7556 - val_loss: 1.4009\n",
      "Epoch 618/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9943 - loss: 0.0212 - val_accuracy: 0.7556 - val_loss: 1.4038\n",
      "Epoch 619/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0169 - val_accuracy: 0.7556 - val_loss: 1.4069\n",
      "Epoch 620/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0251 - val_accuracy: 0.7556 - val_loss: 1.4212\n",
      "Epoch 621/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 0.0199 - val_accuracy: 0.7556 - val_loss: 1.4285\n",
      "Epoch 622/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.0340 - val_accuracy: 0.7556 - val_loss: 1.4073\n",
      "Epoch 623/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9877 - loss: 0.0368 - val_accuracy: 0.7556 - val_loss: 1.3956\n",
      "Epoch 624/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9848 - loss: 0.0319 - val_accuracy: 0.7667 - val_loss: 1.4131\n",
      "Epoch 625/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0164 - val_accuracy: 0.7667 - val_loss: 1.4575\n",
      "Epoch 626/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0349 - val_accuracy: 0.7667 - val_loss: 1.4711\n",
      "Epoch 627/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0313 - val_accuracy: 0.7667 - val_loss: 1.4678\n",
      "Epoch 628/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9967 - loss: 0.0225 - val_accuracy: 0.7667 - val_loss: 1.4576\n",
      "Epoch 629/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9867 - loss: 0.0441 - val_accuracy: 0.7667 - val_loss: 1.4372\n",
      "Epoch 630/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0107 - val_accuracy: 0.7667 - val_loss: 1.4198\n",
      "Epoch 631/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.0222 - val_accuracy: 0.7667 - val_loss: 1.4139\n",
      "Epoch 632/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0206 - val_accuracy: 0.7667 - val_loss: 1.4065\n",
      "Epoch 633/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0269 - val_accuracy: 0.7667 - val_loss: 1.4086\n",
      "Epoch 634/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0248 - val_accuracy: 0.7667 - val_loss: 1.4183\n",
      "Epoch 635/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0242 - val_accuracy: 0.7667 - val_loss: 1.4245\n",
      "Epoch 636/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0216 - val_accuracy: 0.7667 - val_loss: 1.4361\n",
      "Epoch 637/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9887 - loss: 0.0262 - val_accuracy: 0.7667 - val_loss: 1.4300\n",
      "Epoch 638/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9905 - loss: 0.0246 - val_accuracy: 0.7667 - val_loss: 1.4209\n",
      "Epoch 639/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0178 - val_accuracy: 0.7667 - val_loss: 1.4238\n",
      "Epoch 640/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9879 - loss: 0.0275 - val_accuracy: 0.7667 - val_loss: 1.4300\n",
      "Epoch 641/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0155 - val_accuracy: 0.7667 - val_loss: 1.4319\n",
      "Epoch 642/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9792 - loss: 0.0422 - val_accuracy: 0.7667 - val_loss: 1.4242\n",
      "Epoch 643/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0203 - val_accuracy: 0.7667 - val_loss: 1.3967\n",
      "Epoch 644/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9923 - loss: 0.0405 - val_accuracy: 0.7667 - val_loss: 1.3866\n",
      "Epoch 645/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9849 - loss: 0.0364 - val_accuracy: 0.7778 - val_loss: 1.3665\n",
      "Epoch 646/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9962 - loss: 0.0146 - val_accuracy: 0.7778 - val_loss: 1.3669\n",
      "Epoch 647/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0210 - val_accuracy: 0.7778 - val_loss: 1.3805\n",
      "Epoch 648/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0104 - val_accuracy: 0.7778 - val_loss: 1.3913\n",
      "Epoch 649/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0134 - val_accuracy: 0.7778 - val_loss: 1.4096\n",
      "Epoch 650/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0126 - val_accuracy: 0.7778 - val_loss: 1.4240\n",
      "Epoch 651/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0161 - val_accuracy: 0.7778 - val_loss: 1.4349\n",
      "Epoch 652/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9841 - loss: 0.0308 - val_accuracy: 0.7667 - val_loss: 1.4402\n",
      "Epoch 653/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9794 - loss: 0.0406 - val_accuracy: 0.7667 - val_loss: 1.4268\n",
      "Epoch 654/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.0179 - val_accuracy: 0.7667 - val_loss: 1.4189\n",
      "Epoch 655/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0213 - val_accuracy: 0.7556 - val_loss: 1.4305\n",
      "Epoch 656/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9870 - loss: 0.0258 - val_accuracy: 0.7556 - val_loss: 1.4359\n",
      "Epoch 657/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0275 - val_accuracy: 0.7667 - val_loss: 1.4523\n",
      "Epoch 658/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9846 - loss: 0.0313 - val_accuracy: 0.7444 - val_loss: 1.4769\n",
      "Epoch 659/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0259 - val_accuracy: 0.7333 - val_loss: 1.4819\n",
      "Epoch 660/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0206 - val_accuracy: 0.7556 - val_loss: 1.4719\n",
      "Epoch 661/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.7556 - val_loss: 1.4608\n",
      "Epoch 662/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9962 - loss: 0.0183 - val_accuracy: 0.7556 - val_loss: 1.4471\n",
      "Epoch 663/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9926 - loss: 0.0159 - val_accuracy: 0.7667 - val_loss: 1.4323\n",
      "Epoch 664/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9857 - loss: 0.0354 - val_accuracy: 0.7778 - val_loss: 1.4060\n",
      "Epoch 665/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9955 - loss: 0.0198 - val_accuracy: 0.7778 - val_loss: 1.3894\n",
      "Epoch 666/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0425 - val_accuracy: 0.7778 - val_loss: 1.3817\n",
      "Epoch 667/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9957 - loss: 0.0126 - val_accuracy: 0.7778 - val_loss: 1.3796\n",
      "Epoch 668/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9963 - loss: 0.0144 - val_accuracy: 0.7667 - val_loss: 1.3975\n",
      "Epoch 669/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9923 - loss: 0.0252 - val_accuracy: 0.7667 - val_loss: 1.4036\n",
      "Epoch 670/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9941 - loss: 0.0193 - val_accuracy: 0.7667 - val_loss: 1.4319\n",
      "Epoch 671/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9878 - loss: 0.0385 - val_accuracy: 0.7667 - val_loss: 1.4436\n",
      "Epoch 672/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 0.7667 - val_loss: 1.4557\n",
      "Epoch 673/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9970 - loss: 0.0101 - val_accuracy: 0.7667 - val_loss: 1.4636\n",
      "Epoch 674/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0079 - val_accuracy: 0.7667 - val_loss: 1.4620\n",
      "Epoch 675/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9957 - loss: 0.0138 - val_accuracy: 0.7667 - val_loss: 1.4609\n",
      "Epoch 676/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0208 - val_accuracy: 0.7667 - val_loss: 1.4690\n",
      "Epoch 677/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0176 - val_accuracy: 0.7556 - val_loss: 1.4755\n",
      "Epoch 678/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0205 - val_accuracy: 0.7556 - val_loss: 1.4864\n",
      "Epoch 679/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9945 - loss: 0.0205 - val_accuracy: 0.7556 - val_loss: 1.4977\n",
      "Epoch 680/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9861 - loss: 0.0350 - val_accuracy: 0.7667 - val_loss: 1.4846\n",
      "Epoch 681/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0106 - val_accuracy: 0.7667 - val_loss: 1.4719\n",
      "Epoch 682/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.0246 - val_accuracy: 0.7667 - val_loss: 1.4581\n",
      "Epoch 683/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.7667 - val_loss: 1.4473\n",
      "Epoch 684/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0141 - val_accuracy: 0.7667 - val_loss: 1.4435\n",
      "Epoch 685/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9849 - loss: 0.0454 - val_accuracy: 0.7667 - val_loss: 1.4364\n",
      "Epoch 686/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0153 - val_accuracy: 0.7667 - val_loss: 1.4349\n",
      "Epoch 687/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0156 - val_accuracy: 0.7667 - val_loss: 1.4421\n",
      "Epoch 688/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9864 - loss: 0.0332 - val_accuracy: 0.7667 - val_loss: 1.4608\n",
      "Epoch 689/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0185 - val_accuracy: 0.7667 - val_loss: 1.4581\n",
      "Epoch 690/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9949 - loss: 0.0145 - val_accuracy: 0.7667 - val_loss: 1.4535\n",
      "Epoch 691/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9905 - loss: 0.0245 - val_accuracy: 0.7667 - val_loss: 1.4455\n",
      "Epoch 692/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9975 - loss: 0.0152 - val_accuracy: 0.7667 - val_loss: 1.4365\n",
      "Epoch 693/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.0223 - val_accuracy: 0.7667 - val_loss: 1.4327\n",
      "Epoch 694/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9900 - loss: 0.0258 - val_accuracy: 0.7667 - val_loss: 1.4195\n",
      "Epoch 695/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0144 - val_accuracy: 0.7667 - val_loss: 1.4008\n",
      "Epoch 696/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0191 - val_accuracy: 0.7778 - val_loss: 1.3749\n",
      "Epoch 697/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9974 - loss: 0.0162 - val_accuracy: 0.7889 - val_loss: 1.3452\n",
      "Epoch 698/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9843 - loss: 0.0369 - val_accuracy: 0.7778 - val_loss: 1.3227\n",
      "Epoch 699/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9887 - loss: 0.0340 - val_accuracy: 0.7889 - val_loss: 1.3247\n",
      "Epoch 700/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9939 - loss: 0.0274 - val_accuracy: 0.7889 - val_loss: 1.3401\n",
      "Epoch 701/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.7889 - val_loss: 1.3471\n",
      "Epoch 702/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9959 - loss: 0.0138 - val_accuracy: 0.7889 - val_loss: 1.3430\n",
      "Epoch 703/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9901 - loss: 0.0326 - val_accuracy: 0.7889 - val_loss: 1.3496\n",
      "Epoch 704/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9893 - loss: 0.0221 - val_accuracy: 0.7889 - val_loss: 1.3646\n",
      "Epoch 705/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9821 - loss: 0.0255 - val_accuracy: 0.7889 - val_loss: 1.4057\n",
      "Epoch 706/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9955 - loss: 0.0147 - val_accuracy: 0.7778 - val_loss: 1.4370\n",
      "Epoch 707/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0161 - val_accuracy: 0.7778 - val_loss: 1.4402\n",
      "Epoch 708/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9788 - loss: 0.0405 - val_accuracy: 0.7778 - val_loss: 1.4553\n",
      "Epoch 709/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9913 - loss: 0.0198 - val_accuracy: 0.7667 - val_loss: 1.4664\n",
      "Epoch 710/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9941 - loss: 0.0271 - val_accuracy: 0.7667 - val_loss: 1.4750\n",
      "Epoch 711/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9836 - loss: 0.0342 - val_accuracy: 0.7667 - val_loss: 1.4898\n",
      "Epoch 712/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.0220 - val_accuracy: 0.7667 - val_loss: 1.5131\n",
      "Epoch 713/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.7667 - val_loss: 1.5273\n",
      "Epoch 714/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0114 - val_accuracy: 0.7667 - val_loss: 1.5191\n",
      "Epoch 715/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0108 - val_accuracy: 0.7667 - val_loss: 1.4993\n",
      "Epoch 716/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9821 - loss: 0.0263 - val_accuracy: 0.7667 - val_loss: 1.5101\n",
      "Epoch 717/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9898 - loss: 0.0218 - val_accuracy: 0.7667 - val_loss: 1.5224\n",
      "Epoch 718/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.7667 - val_loss: 1.5400\n",
      "Epoch 719/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9860 - loss: 0.0376 - val_accuracy: 0.7778 - val_loss: 1.5171\n",
      "Epoch 720/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9931 - loss: 0.0262 - val_accuracy: 0.7667 - val_loss: 1.4903\n",
      "Epoch 721/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9823 - loss: 0.0509 - val_accuracy: 0.7778 - val_loss: 1.5263\n",
      "Epoch 722/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9992 - loss: 0.0097 - val_accuracy: 0.7667 - val_loss: 1.5400\n",
      "Epoch 723/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9702 - loss: 0.0601 - val_accuracy: 0.7667 - val_loss: 1.5162\n",
      "Epoch 724/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9975 - loss: 0.0088 - val_accuracy: 0.7667 - val_loss: 1.4980\n",
      "Epoch 725/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9895 - loss: 0.0293 - val_accuracy: 0.7667 - val_loss: 1.4802\n",
      "Epoch 726/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0094 - val_accuracy: 0.7556 - val_loss: 1.4658\n",
      "Epoch 727/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0172 - val_accuracy: 0.7667 - val_loss: 1.4345\n",
      "Epoch 728/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9956 - loss: 0.0167 - val_accuracy: 0.7778 - val_loss: 1.4252\n",
      "Epoch 729/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9895 - loss: 0.0268 - val_accuracy: 0.7778 - val_loss: 1.4316\n",
      "Epoch 730/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0128 - val_accuracy: 0.7778 - val_loss: 1.4452\n",
      "Epoch 731/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9926 - loss: 0.0266 - val_accuracy: 0.7778 - val_loss: 1.4616\n",
      "Epoch 732/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0074 - val_accuracy: 0.7778 - val_loss: 1.4751\n",
      "Epoch 733/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9794 - loss: 0.0610 - val_accuracy: 0.7778 - val_loss: 1.4872\n",
      "Epoch 734/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9853 - loss: 0.0421 - val_accuracy: 0.7778 - val_loss: 1.4968\n",
      "Epoch 735/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9908 - loss: 0.0359 - val_accuracy: 0.7778 - val_loss: 1.4442\n",
      "Epoch 736/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9929 - loss: 0.0208 - val_accuracy: 0.7889 - val_loss: 1.3494\n",
      "Epoch 737/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9839 - loss: 0.0382 - val_accuracy: 0.7889 - val_loss: 1.3556\n",
      "Epoch 738/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.0218 - val_accuracy: 0.7889 - val_loss: 1.3861\n",
      "Epoch 739/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9957 - loss: 0.0168 - val_accuracy: 0.7778 - val_loss: 1.4157\n",
      "Epoch 740/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9963 - loss: 0.0108 - val_accuracy: 0.7889 - val_loss: 1.4252\n",
      "Epoch 741/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0156 - val_accuracy: 0.7889 - val_loss: 1.4145\n",
      "Epoch 742/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9963 - loss: 0.0157 - val_accuracy: 0.7889 - val_loss: 1.4023\n",
      "Epoch 743/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0142 - val_accuracy: 0.7889 - val_loss: 1.4000\n",
      "Epoch 744/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9963 - loss: 0.0156 - val_accuracy: 0.7889 - val_loss: 1.4054\n",
      "Epoch 745/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0155 - val_accuracy: 0.7778 - val_loss: 1.4154\n",
      "Epoch 746/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.0227 - val_accuracy: 0.7778 - val_loss: 1.4505\n",
      "Epoch 747/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.0316 - val_accuracy: 0.7778 - val_loss: 1.4852\n",
      "Epoch 748/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9861 - loss: 0.0467 - val_accuracy: 0.7778 - val_loss: 1.4845\n",
      "Epoch 749/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0188 - val_accuracy: 0.7778 - val_loss: 1.4822\n",
      "Epoch 750/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9926 - loss: 0.0118 - val_accuracy: 0.7667 - val_loss: 1.4788\n",
      "Epoch 751/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9945 - loss: 0.0168 - val_accuracy: 0.7667 - val_loss: 1.4729\n",
      "Epoch 752/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0112 - val_accuracy: 0.7667 - val_loss: 1.4724\n",
      "Epoch 753/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9970 - loss: 0.0118 - val_accuracy: 0.7778 - val_loss: 1.4813\n",
      "Epoch 754/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9929 - loss: 0.0153 - val_accuracy: 0.7667 - val_loss: 1.4984\n",
      "Epoch 755/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9905 - loss: 0.0179 - val_accuracy: 0.7667 - val_loss: 1.5144\n",
      "Epoch 756/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0135 - val_accuracy: 0.7667 - val_loss: 1.5126\n",
      "Epoch 757/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0122 - val_accuracy: 0.7778 - val_loss: 1.4996\n",
      "Epoch 758/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9943 - loss: 0.0343 - val_accuracy: 0.7778 - val_loss: 1.4886\n",
      "Epoch 759/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0157 - val_accuracy: 0.7778 - val_loss: 1.4658\n",
      "Epoch 760/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.7778 - val_loss: 1.4468\n",
      "Epoch 761/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9944 - loss: 0.0227 - val_accuracy: 0.7778 - val_loss: 1.4345\n",
      "Epoch 762/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0080 - val_accuracy: 0.7778 - val_loss: 1.4357\n",
      "Epoch 763/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0148 - val_accuracy: 0.7778 - val_loss: 1.4475\n",
      "Epoch 764/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9867 - loss: 0.0411 - val_accuracy: 0.7778 - val_loss: 1.4553\n",
      "Epoch 765/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.7778 - val_loss: 1.4600\n",
      "Epoch 766/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.7667 - val_loss: 1.4660\n",
      "Epoch 767/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0233 - val_accuracy: 0.7778 - val_loss: 1.4762\n",
      "Epoch 768/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0093 - val_accuracy: 0.7778 - val_loss: 1.4792\n",
      "Epoch 769/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0175 - val_accuracy: 0.7778 - val_loss: 1.4660\n",
      "Epoch 770/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9933 - loss: 0.0192 - val_accuracy: 0.7778 - val_loss: 1.4670\n",
      "Epoch 771/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0178 - val_accuracy: 0.7667 - val_loss: 1.4754\n",
      "Epoch 772/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0108 - val_accuracy: 0.7667 - val_loss: 1.4938\n",
      "Epoch 773/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9938 - loss: 0.0212 - val_accuracy: 0.7778 - val_loss: 1.5143\n",
      "Epoch 774/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9939 - loss: 0.0218 - val_accuracy: 0.7778 - val_loss: 1.5355\n",
      "Epoch 775/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0170 - val_accuracy: 0.7778 - val_loss: 1.5620\n",
      "Epoch 776/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9946 - loss: 0.0212 - val_accuracy: 0.7778 - val_loss: 1.5928\n",
      "Epoch 777/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0256 - val_accuracy: 0.7778 - val_loss: 1.6025\n",
      "Epoch 778/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.7556 - val_loss: 1.6435\n",
      "Epoch 779/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.7556 - val_loss: 1.6615\n",
      "Epoch 780/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9884 - loss: 0.0179 - val_accuracy: 0.7556 - val_loss: 1.6686\n",
      "Epoch 781/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0153 - val_accuracy: 0.7556 - val_loss: 1.6718\n",
      "Epoch 782/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9955 - loss: 0.0131 - val_accuracy: 0.7556 - val_loss: 1.6695\n",
      "Epoch 783/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0163 - val_accuracy: 0.7556 - val_loss: 1.6756\n",
      "Epoch 784/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.0363 - val_accuracy: 0.7556 - val_loss: 1.6793\n",
      "Epoch 785/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0269 - val_accuracy: 0.7556 - val_loss: 1.6806\n",
      "Epoch 786/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.7556 - val_loss: 1.6460\n",
      "Epoch 787/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9824 - loss: 0.0726 - val_accuracy: 0.7667 - val_loss: 1.5976\n",
      "Epoch 788/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0121 - val_accuracy: 0.7667 - val_loss: 1.6056\n",
      "Epoch 789/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0182 - val_accuracy: 0.7667 - val_loss: 1.6161\n",
      "Epoch 790/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0089 - val_accuracy: 0.7667 - val_loss: 1.6438\n",
      "Epoch 791/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9967 - loss: 0.0116 - val_accuracy: 0.7444 - val_loss: 1.6861\n",
      "Epoch 792/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0178 - val_accuracy: 0.7556 - val_loss: 1.7126\n",
      "Epoch 793/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0153 - val_accuracy: 0.7556 - val_loss: 1.7049\n",
      "Epoch 794/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9915 - loss: 0.0245 - val_accuracy: 0.7556 - val_loss: 1.6924\n",
      "Epoch 795/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.0156 - val_accuracy: 0.7667 - val_loss: 1.6678\n",
      "Epoch 796/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.7667 - val_loss: 1.6327\n",
      "Epoch 797/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0153 - val_accuracy: 0.7667 - val_loss: 1.6202\n",
      "Epoch 798/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9963 - loss: 0.0106 - val_accuracy: 0.7667 - val_loss: 1.6093\n",
      "Epoch 799/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.7667 - val_loss: 1.6156\n",
      "Epoch 800/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.7667 - val_loss: 1.6251\n",
      "Epoch 801/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0213 - val_accuracy: 0.7667 - val_loss: 1.6163\n",
      "Epoch 802/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9963 - loss: 0.0111 - val_accuracy: 0.7667 - val_loss: 1.6087\n",
      "Epoch 803/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9892 - loss: 0.0178 - val_accuracy: 0.7778 - val_loss: 1.5887\n",
      "Epoch 804/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0151 - val_accuracy: 0.7778 - val_loss: 1.5845\n",
      "Epoch 805/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9937 - loss: 0.0132 - val_accuracy: 0.7778 - val_loss: 1.5729\n",
      "Epoch 806/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9879 - loss: 0.0157 - val_accuracy: 0.7778 - val_loss: 1.5822\n",
      "Epoch 807/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.7556 - val_loss: 1.5811\n",
      "Epoch 808/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0227 - val_accuracy: 0.7556 - val_loss: 1.5888\n",
      "Epoch 809/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0257 - val_accuracy: 0.7556 - val_loss: 1.5761\n",
      "Epoch 810/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9951 - loss: 0.0157 - val_accuracy: 0.7556 - val_loss: 1.5824\n",
      "Epoch 811/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0162 - val_accuracy: 0.7444 - val_loss: 1.5902\n",
      "Epoch 812/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.7444 - val_loss: 1.5930\n",
      "Epoch 813/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0146 - val_accuracy: 0.7444 - val_loss: 1.6015\n",
      "Epoch 814/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.7444 - val_loss: 1.6143\n",
      "Epoch 815/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0287 - val_accuracy: 0.7333 - val_loss: 1.6820\n",
      "Epoch 816/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9962 - loss: 0.0105 - val_accuracy: 0.7222 - val_loss: 1.7250\n",
      "Epoch 817/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.0230 - val_accuracy: 0.7444 - val_loss: 1.7208\n",
      "Epoch 818/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.7444 - val_loss: 1.6976\n",
      "Epoch 819/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0106 - val_accuracy: 0.7667 - val_loss: 1.6729\n",
      "Epoch 820/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9921 - loss: 0.0150 - val_accuracy: 0.7667 - val_loss: 1.6344\n",
      "Epoch 821/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0150 - val_accuracy: 0.7667 - val_loss: 1.6071\n",
      "Epoch 822/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9909 - loss: 0.0310 - val_accuracy: 0.7556 - val_loss: 1.5947\n",
      "Epoch 823/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.0268 - val_accuracy: 0.7556 - val_loss: 1.6054\n",
      "Epoch 824/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0161 - val_accuracy: 0.7667 - val_loss: 1.6190\n",
      "Epoch 825/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.7667 - val_loss: 1.6275\n",
      "Epoch 826/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0177 - val_accuracy: 0.7667 - val_loss: 1.6381\n",
      "Epoch 827/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 0.7667 - val_loss: 1.6324\n",
      "Epoch 828/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.0332 - val_accuracy: 0.7667 - val_loss: 1.6267\n",
      "Epoch 829/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.7667 - val_loss: 1.6285\n",
      "Epoch 830/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9963 - loss: 0.0132 - val_accuracy: 0.7556 - val_loss: 1.6537\n",
      "Epoch 831/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9892 - loss: 0.0245 - val_accuracy: 0.7556 - val_loss: 1.6837\n",
      "Epoch 832/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.7444 - val_loss: 1.7023\n",
      "Epoch 833/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9933 - loss: 0.0216 - val_accuracy: 0.7444 - val_loss: 1.7198\n",
      "Epoch 834/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0112 - val_accuracy: 0.7444 - val_loss: 1.7120\n",
      "Epoch 835/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0298 - val_accuracy: 0.7556 - val_loss: 1.6835\n",
      "Epoch 836/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0091 - val_accuracy: 0.7556 - val_loss: 1.6753\n",
      "Epoch 837/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9921 - loss: 0.0182 - val_accuracy: 0.7556 - val_loss: 1.6589\n",
      "Epoch 838/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0121 - val_accuracy: 0.7444 - val_loss: 1.6237\n",
      "Epoch 839/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9860 - loss: 0.0261 - val_accuracy: 0.7556 - val_loss: 1.6277\n",
      "Epoch 840/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.7667 - val_loss: 1.6375\n",
      "Epoch 841/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9938 - loss: 0.0275 - val_accuracy: 0.7667 - val_loss: 1.6506\n",
      "Epoch 842/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9945 - loss: 0.0209 - val_accuracy: 0.7667 - val_loss: 1.6382\n",
      "Epoch 843/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0106 - val_accuracy: 0.7667 - val_loss: 1.6310\n",
      "Epoch 844/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9802 - loss: 0.0433 - val_accuracy: 0.7667 - val_loss: 1.6499\n",
      "Epoch 845/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.0243 - val_accuracy: 0.7667 - val_loss: 1.6676\n",
      "Epoch 846/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0079 - val_accuracy: 0.7556 - val_loss: 1.6790\n",
      "Epoch 847/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0100 - val_accuracy: 0.7444 - val_loss: 1.6875\n",
      "Epoch 848/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0105 - val_accuracy: 0.7667 - val_loss: 1.6935\n",
      "Epoch 849/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0085 - val_accuracy: 0.7667 - val_loss: 1.6975\n",
      "Epoch 850/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0208 - val_accuracy: 0.7667 - val_loss: 1.6847\n",
      "Epoch 851/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9957 - loss: 0.0145 - val_accuracy: 0.7667 - val_loss: 1.6861\n",
      "Epoch 852/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.7667 - val_loss: 1.6864\n",
      "Epoch 853/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.7667 - val_loss: 1.6899\n",
      "Epoch 854/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7667 - val_loss: 1.6957\n",
      "Epoch 855/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.7667 - val_loss: 1.6969\n",
      "Epoch 856/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0256 - val_accuracy: 0.7667 - val_loss: 1.6939\n",
      "Epoch 857/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.7667 - val_loss: 1.6903\n",
      "Epoch 858/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.0213 - val_accuracy: 0.7667 - val_loss: 1.6825\n",
      "Epoch 859/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0174 - val_accuracy: 0.7667 - val_loss: 1.6297\n",
      "Epoch 860/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.7667 - val_loss: 1.6061\n",
      "Epoch 861/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9929 - loss: 0.0163 - val_accuracy: 0.7667 - val_loss: 1.6006\n",
      "Epoch 862/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0142 - val_accuracy: 0.7667 - val_loss: 1.6005\n",
      "Epoch 863/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0136 - val_accuracy: 0.7667 - val_loss: 1.6055\n",
      "Epoch 864/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0141 - val_accuracy: 0.7556 - val_loss: 1.5773\n",
      "Epoch 865/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9905 - loss: 0.0251 - val_accuracy: 0.7667 - val_loss: 1.5419\n",
      "Epoch 866/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0154 - val_accuracy: 0.7556 - val_loss: 1.5305\n",
      "Epoch 867/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 0.7556 - val_loss: 1.5327\n",
      "Epoch 868/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9872 - loss: 0.0353 - val_accuracy: 0.7556 - val_loss: 1.5386\n",
      "Epoch 869/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0076 - val_accuracy: 0.7444 - val_loss: 1.5389\n",
      "Epoch 870/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9963 - loss: 0.0101 - val_accuracy: 0.7444 - val_loss: 1.5426\n",
      "Epoch 871/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0130 - val_accuracy: 0.7556 - val_loss: 1.5548\n",
      "Epoch 872/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.0179 - val_accuracy: 0.7444 - val_loss: 1.5640\n",
      "Epoch 873/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0190 - val_accuracy: 0.7556 - val_loss: 1.5730\n",
      "Epoch 874/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9941 - loss: 0.0153 - val_accuracy: 0.7556 - val_loss: 1.5828\n",
      "Epoch 875/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9882 - loss: 0.0221 - val_accuracy: 0.7556 - val_loss: 1.5907\n",
      "Epoch 876/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9955 - loss: 0.0155 - val_accuracy: 0.7667 - val_loss: 1.5746\n",
      "Epoch 877/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9962 - loss: 0.0142 - val_accuracy: 0.7667 - val_loss: 1.5579\n",
      "Epoch 878/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0310 - val_accuracy: 0.7667 - val_loss: 1.5880\n",
      "Epoch 879/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0246 - val_accuracy: 0.7667 - val_loss: 1.6167\n",
      "Epoch 880/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9992 - loss: 0.0074 - val_accuracy: 0.7667 - val_loss: 1.6144\n",
      "Epoch 881/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.7667 - val_loss: 1.5827\n",
      "Epoch 882/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0101 - val_accuracy: 0.7889 - val_loss: 1.5701\n",
      "Epoch 883/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0065 - val_accuracy: 0.7889 - val_loss: 1.5642\n",
      "Epoch 884/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0080 - val_accuracy: 0.7889 - val_loss: 1.5661\n",
      "Epoch 885/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0323 - val_accuracy: 0.7889 - val_loss: 1.5721\n",
      "Epoch 886/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0116 - val_accuracy: 0.7889 - val_loss: 1.6339\n",
      "Epoch 887/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0130 - val_accuracy: 0.7889 - val_loss: 1.6859\n",
      "Epoch 888/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9911 - loss: 0.0232 - val_accuracy: 0.7667 - val_loss: 1.6800\n",
      "Epoch 889/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0071 - val_accuracy: 0.7667 - val_loss: 1.6689\n",
      "Epoch 890/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.7556 - val_loss: 1.6619\n",
      "Epoch 891/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9970 - loss: 0.0068 - val_accuracy: 0.7556 - val_loss: 1.6577\n",
      "Epoch 892/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9885 - loss: 0.0194 - val_accuracy: 0.7556 - val_loss: 1.6745\n",
      "Epoch 893/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0201 - val_accuracy: 0.7556 - val_loss: 1.6789\n",
      "Epoch 894/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9945 - loss: 0.0110 - val_accuracy: 0.7667 - val_loss: 1.6550\n",
      "Epoch 895/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0156 - val_accuracy: 0.7556 - val_loss: 1.6165\n",
      "Epoch 896/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9924 - loss: 0.0136 - val_accuracy: 0.7556 - val_loss: 1.6013\n",
      "Epoch 897/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0089 - val_accuracy: 0.7556 - val_loss: 1.5984\n",
      "Epoch 898/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0111 - val_accuracy: 0.7556 - val_loss: 1.6022\n",
      "Epoch 899/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9874 - loss: 0.0344 - val_accuracy: 0.7556 - val_loss: 1.6120\n",
      "Epoch 900/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9975 - loss: 0.0112 - val_accuracy: 0.7667 - val_loss: 1.6297\n",
      "Epoch 901/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0101 - val_accuracy: 0.7667 - val_loss: 1.6471\n",
      "Epoch 902/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.7667 - val_loss: 1.6578\n",
      "Epoch 903/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0062 - val_accuracy: 0.7667 - val_loss: 1.6582\n",
      "Epoch 904/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.7667 - val_loss: 1.6653\n",
      "Epoch 905/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0153 - val_accuracy: 0.7556 - val_loss: 1.6799\n",
      "Epoch 906/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7556 - val_loss: 1.7003\n",
      "Epoch 907/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0118 - val_accuracy: 0.7556 - val_loss: 1.7272\n",
      "Epoch 908/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0089 - val_accuracy: 0.7556 - val_loss: 1.7560\n",
      "Epoch 909/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9962 - loss: 0.0072 - val_accuracy: 0.7667 - val_loss: 1.7688\n",
      "Epoch 910/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9905 - loss: 0.0219 - val_accuracy: 0.7667 - val_loss: 1.7926\n",
      "Epoch 911/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0085 - val_accuracy: 0.7667 - val_loss: 1.8121\n",
      "Epoch 912/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9911 - loss: 0.0206 - val_accuracy: 0.7667 - val_loss: 1.8023\n",
      "Epoch 913/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0147 - val_accuracy: 0.7667 - val_loss: 1.7853\n",
      "Epoch 914/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0067 - val_accuracy: 0.7556 - val_loss: 1.7868\n",
      "Epoch 915/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.7556 - val_loss: 1.7895\n",
      "Epoch 916/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.7556 - val_loss: 1.7915\n",
      "Epoch 917/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.7556 - val_loss: 1.8102\n",
      "Epoch 918/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9982 - loss: 0.0126 - val_accuracy: 0.7556 - val_loss: 1.7843\n",
      "Epoch 919/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0121 - val_accuracy: 0.7556 - val_loss: 1.7634\n",
      "Epoch 920/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0101 - val_accuracy: 0.7556 - val_loss: 1.7691\n",
      "Epoch 921/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0201 - val_accuracy: 0.7556 - val_loss: 1.7469\n",
      "Epoch 922/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.7556 - val_loss: 1.7359\n",
      "Epoch 923/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0059 - val_accuracy: 0.7556 - val_loss: 1.7379\n",
      "Epoch 924/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0139 - val_accuracy: 0.7556 - val_loss: 1.7513\n",
      "Epoch 925/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0128 - val_accuracy: 0.7556 - val_loss: 1.7629\n",
      "Epoch 926/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9963 - loss: 0.0116 - val_accuracy: 0.7556 - val_loss: 1.7822\n",
      "Epoch 927/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.7556 - val_loss: 1.7922\n",
      "Epoch 928/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0120 - val_accuracy: 0.7556 - val_loss: 1.8094\n",
      "Epoch 929/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7667 - val_loss: 1.8161\n",
      "Epoch 930/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.7667 - val_loss: 1.8338\n",
      "Epoch 931/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.7667 - val_loss: 1.8502\n",
      "Epoch 932/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.7667 - val_loss: 1.8673\n",
      "Epoch 933/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9865 - loss: 0.0252 - val_accuracy: 0.7667 - val_loss: 1.8895\n",
      "Epoch 934/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.7667 - val_loss: 1.8997\n",
      "Epoch 935/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.7667 - val_loss: 1.9086\n",
      "Epoch 936/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0094 - val_accuracy: 0.7667 - val_loss: 1.9211\n",
      "Epoch 937/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9988 - loss: 0.0091 - val_accuracy: 0.7556 - val_loss: 1.9486\n",
      "Epoch 938/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.7556 - val_loss: 1.9816\n",
      "Epoch 939/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9916 - loss: 0.0195 - val_accuracy: 0.7556 - val_loss: 2.0267\n",
      "Epoch 940/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.7444 - val_loss: 2.0403\n",
      "Epoch 941/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7556 - val_loss: 2.0281\n",
      "Epoch 942/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.7556 - val_loss: 2.0152\n",
      "Epoch 943/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9937 - loss: 0.0198 - val_accuracy: 0.7556 - val_loss: 1.9929\n",
      "Epoch 944/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0160 - val_accuracy: 0.7667 - val_loss: 1.9565\n",
      "Epoch 945/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0073 - val_accuracy: 0.7667 - val_loss: 1.9068\n",
      "Epoch 946/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9929 - loss: 0.0224 - val_accuracy: 0.7667 - val_loss: 1.9077\n",
      "Epoch 947/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0093 - val_accuracy: 0.7667 - val_loss: 1.9393\n",
      "Epoch 948/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.7667 - val_loss: 1.9563\n",
      "Epoch 949/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0255 - val_accuracy: 0.7556 - val_loss: 1.9661\n",
      "Epoch 950/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9982 - loss: 0.0076 - val_accuracy: 0.7556 - val_loss: 1.9606\n",
      "Epoch 951/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.7556 - val_loss: 1.9412\n",
      "Epoch 952/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0142 - val_accuracy: 0.7667 - val_loss: 1.9497\n",
      "Epoch 953/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0153 - val_accuracy: 0.7667 - val_loss: 1.9261\n",
      "Epoch 954/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0088 - val_accuracy: 0.7667 - val_loss: 1.8771\n",
      "Epoch 955/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0135 - val_accuracy: 0.7556 - val_loss: 1.8327\n",
      "Epoch 956/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0174 - val_accuracy: 0.7556 - val_loss: 1.8088\n",
      "Epoch 957/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0156 - val_accuracy: 0.7667 - val_loss: 1.8044\n",
      "Epoch 958/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0153 - val_accuracy: 0.7667 - val_loss: 1.8083\n",
      "Epoch 959/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.7667 - val_loss: 1.8112\n",
      "Epoch 960/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9982 - loss: 0.0100 - val_accuracy: 0.7667 - val_loss: 1.8360\n",
      "Epoch 961/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0127 - val_accuracy: 0.7778 - val_loss: 1.8184\n",
      "Epoch 962/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0124 - val_accuracy: 0.7889 - val_loss: 1.7962\n",
      "Epoch 963/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0170 - val_accuracy: 0.7667 - val_loss: 1.7846\n",
      "Epoch 964/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0124 - val_accuracy: 0.7556 - val_loss: 1.7939\n",
      "Epoch 965/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7667 - val_loss: 1.8088\n",
      "Epoch 966/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0079 - val_accuracy: 0.7667 - val_loss: 1.8218\n",
      "Epoch 967/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0192 - val_accuracy: 0.7667 - val_loss: 1.8430\n",
      "Epoch 968/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9950 - loss: 0.0138 - val_accuracy: 0.7556 - val_loss: 1.8676\n",
      "Epoch 969/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0051 - val_accuracy: 0.7556 - val_loss: 1.8813\n",
      "Epoch 970/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9962 - loss: 0.0107 - val_accuracy: 0.7556 - val_loss: 1.8700\n",
      "Epoch 971/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.7556 - val_loss: 1.8577\n",
      "Epoch 972/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0079 - val_accuracy: 0.7778 - val_loss: 1.8375\n",
      "Epoch 973/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0124 - val_accuracy: 0.7778 - val_loss: 1.8199\n",
      "Epoch 974/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.7667 - val_loss: 1.8025\n",
      "Epoch 975/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9916 - loss: 0.0242 - val_accuracy: 0.7667 - val_loss: 1.8144\n",
      "Epoch 976/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9967 - loss: 0.0068 - val_accuracy: 0.7667 - val_loss: 1.8206\n",
      "Epoch 977/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.0133 - val_accuracy: 0.7667 - val_loss: 1.7855\n",
      "Epoch 978/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9868 - loss: 0.0287 - val_accuracy: 0.7778 - val_loss: 1.8165\n",
      "Epoch 979/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0069 - val_accuracy: 0.7778 - val_loss: 1.8193\n",
      "Epoch 980/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.7667 - val_loss: 1.8187\n",
      "Epoch 981/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.7667 - val_loss: 1.8352\n",
      "Epoch 982/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.7667 - val_loss: 1.8409\n",
      "Epoch 983/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.7667 - val_loss: 1.8350\n",
      "Epoch 984/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.7667 - val_loss: 1.8495\n",
      "Epoch 985/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0054 - val_accuracy: 0.7556 - val_loss: 1.8751\n",
      "Epoch 986/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0201 - val_accuracy: 0.7556 - val_loss: 1.8995\n",
      "Epoch 987/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.7556 - val_loss: 1.9129\n",
      "Epoch 988/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0105 - val_accuracy: 0.7667 - val_loss: 1.9046\n",
      "Epoch 989/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0095 - val_accuracy: 0.7667 - val_loss: 1.8787\n",
      "Epoch 990/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0131 - val_accuracy: 0.7556 - val_loss: 1.8650\n",
      "Epoch 991/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0066 - val_accuracy: 0.7667 - val_loss: 1.8772\n",
      "Epoch 992/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.0144 - val_accuracy: 0.7667 - val_loss: 1.8822\n",
      "Epoch 993/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.7667 - val_loss: 1.8684\n",
      "Epoch 994/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.7667 - val_loss: 1.8659\n",
      "Epoch 995/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7667 - val_loss: 1.8675\n",
      "Epoch 996/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9982 - loss: 0.0050 - val_accuracy: 0.7667 - val_loss: 1.8766\n",
      "Epoch 997/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0098 - val_accuracy: 0.7667 - val_loss: 1.8793\n",
      "Epoch 998/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0079 - val_accuracy: 0.7556 - val_loss: 1.8967\n",
      "Epoch 999/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0121 - val_accuracy: 0.7444 - val_loss: 1.9849\n",
      "Epoch 1000/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.7444 - val_loss: 2.0402\n",
      "Epoch 1001/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0167 - val_accuracy: 0.7333 - val_loss: 2.0522\n",
      "Epoch 1002/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0108 - val_accuracy: 0.7444 - val_loss: 2.0777\n",
      "Epoch 1003/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.7333 - val_loss: 2.1057\n",
      "Epoch 1004/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.7333 - val_loss: 2.1403\n",
      "Epoch 1005/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9945 - loss: 0.0185 - val_accuracy: 0.7222 - val_loss: 2.1309\n",
      "Epoch 1006/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0086 - val_accuracy: 0.7333 - val_loss: 2.1123\n",
      "Epoch 1007/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7333 - val_loss: 2.0884\n",
      "Epoch 1008/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9945 - loss: 0.0158 - val_accuracy: 0.7333 - val_loss: 2.0466\n",
      "Epoch 1009/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9930 - loss: 0.0165 - val_accuracy: 0.7444 - val_loss: 2.0034\n",
      "Epoch 1010/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0084 - val_accuracy: 0.7556 - val_loss: 1.9169\n",
      "Epoch 1011/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.7667 - val_loss: 1.8510\n",
      "Epoch 1012/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0067 - val_accuracy: 0.7778 - val_loss: 1.8083\n",
      "Epoch 1013/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9882 - loss: 0.0187 - val_accuracy: 0.7667 - val_loss: 1.7705\n",
      "Epoch 1014/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.7667 - val_loss: 1.7515\n",
      "Epoch 1015/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9963 - loss: 0.0093 - val_accuracy: 0.7667 - val_loss: 1.7283\n",
      "Epoch 1016/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0116 - val_accuracy: 0.7778 - val_loss: 1.7180\n",
      "Epoch 1017/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.7778 - val_loss: 1.7208\n",
      "Epoch 1018/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0049 - val_accuracy: 0.7778 - val_loss: 1.7217\n",
      "Epoch 1019/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9941 - loss: 0.0112 - val_accuracy: 0.7778 - val_loss: 1.7140\n",
      "Epoch 1020/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7667 - val_loss: 1.7125\n",
      "Epoch 1021/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.7556 - val_loss: 1.7234\n",
      "Epoch 1022/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9870 - loss: 0.0291 - val_accuracy: 0.7556 - val_loss: 1.7527\n",
      "Epoch 1023/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.7556 - val_loss: 1.7629\n",
      "Epoch 1024/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0074 - val_accuracy: 0.7556 - val_loss: 1.7644\n",
      "Epoch 1025/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9963 - loss: 0.0158 - val_accuracy: 0.7556 - val_loss: 1.7320\n",
      "Epoch 1026/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0308 - val_accuracy: 0.7556 - val_loss: 1.6858\n",
      "Epoch 1027/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0024 - val_accuracy: 0.7556 - val_loss: 1.6705\n",
      "Epoch 1028/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.7556 - val_loss: 1.6707\n",
      "Epoch 1029/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7556 - val_loss: 1.6805\n",
      "Epoch 1030/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9945 - loss: 0.0168 - val_accuracy: 0.7556 - val_loss: 1.6899\n",
      "Epoch 1031/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9921 - loss: 0.0125 - val_accuracy: 0.7667 - val_loss: 1.6953\n",
      "Epoch 1032/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7667 - val_loss: 1.7101\n",
      "Epoch 1033/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9967 - loss: 0.0106 - val_accuracy: 0.7778 - val_loss: 1.7332\n",
      "Epoch 1034/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7667 - val_loss: 1.7622\n",
      "Epoch 1035/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9970 - loss: 0.0099 - val_accuracy: 0.7667 - val_loss: 1.7885\n",
      "Epoch 1036/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.7556 - val_loss: 1.8267\n",
      "Epoch 1037/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9970 - loss: 0.0076 - val_accuracy: 0.7556 - val_loss: 1.8497\n",
      "Epoch 1038/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9952 - loss: 0.0100 - val_accuracy: 0.7667 - val_loss: 1.8497\n",
      "Epoch 1039/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0095 - val_accuracy: 0.7667 - val_loss: 1.8507\n",
      "Epoch 1040/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.7778 - val_loss: 1.8470\n",
      "Epoch 1041/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9944 - loss: 0.0135 - val_accuracy: 0.7778 - val_loss: 1.8570\n",
      "Epoch 1042/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0050 - val_accuracy: 0.7889 - val_loss: 1.8767\n",
      "Epoch 1043/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0041 - val_accuracy: 0.7889 - val_loss: 1.9001\n",
      "Epoch 1044/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9945 - loss: 0.0146 - val_accuracy: 0.7778 - val_loss: 1.8976\n",
      "Epoch 1045/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0077 - val_accuracy: 0.7667 - val_loss: 1.8890\n",
      "Epoch 1046/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.7667 - val_loss: 1.8875\n",
      "Epoch 1047/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9970 - loss: 0.0058 - val_accuracy: 0.7667 - val_loss: 1.9727\n",
      "Epoch 1048/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7556 - val_loss: 2.1063\n",
      "Epoch 1049/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0045 - val_accuracy: 0.7556 - val_loss: 2.1446\n",
      "Epoch 1050/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0113 - val_accuracy: 0.7556 - val_loss: 2.1669\n",
      "Epoch 1051/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.7444 - val_loss: 2.1609\n",
      "Epoch 1052/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.7444 - val_loss: 2.1425\n",
      "Epoch 1053/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.7444 - val_loss: 2.1291\n",
      "Epoch 1054/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9933 - loss: 0.0139 - val_accuracy: 0.7444 - val_loss: 2.1091\n",
      "Epoch 1055/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.7444 - val_loss: 2.0788\n",
      "Epoch 1056/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0037 - val_accuracy: 0.7556 - val_loss: 2.0277\n",
      "Epoch 1057/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.7333 - val_loss: 1.9311\n",
      "Epoch 1058/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0118 - val_accuracy: 0.7444 - val_loss: 1.8988\n",
      "Epoch 1059/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0106 - val_accuracy: 0.7556 - val_loss: 1.8741\n",
      "Epoch 1060/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9905 - loss: 0.0245 - val_accuracy: 0.7556 - val_loss: 1.8225\n",
      "Epoch 1061/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0064 - val_accuracy: 0.7778 - val_loss: 1.7990\n",
      "Epoch 1062/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.7778 - val_loss: 1.7740\n",
      "Epoch 1063/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0063 - val_accuracy: 0.7778 - val_loss: 1.7341\n",
      "Epoch 1064/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.7556 - val_loss: 1.7101\n",
      "Epoch 1065/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0117 - val_accuracy: 0.7556 - val_loss: 1.7160\n",
      "Epoch 1066/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9975 - loss: 0.0096 - val_accuracy: 0.7667 - val_loss: 1.7635\n",
      "Epoch 1067/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.7556 - val_loss: 1.8091\n",
      "Epoch 1068/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9933 - loss: 0.0137 - val_accuracy: 0.7556 - val_loss: 1.8802\n",
      "Epoch 1069/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0139 - val_accuracy: 0.7444 - val_loss: 1.9134\n",
      "Epoch 1070/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0032 - val_accuracy: 0.7333 - val_loss: 1.9333\n",
      "Epoch 1071/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9975 - loss: 0.0147 - val_accuracy: 0.7333 - val_loss: 1.9910\n",
      "Epoch 1072/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7222 - val_loss: 2.0361\n",
      "Epoch 1073/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7222 - val_loss: 2.0493\n",
      "Epoch 1074/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9992 - loss: 0.0065 - val_accuracy: 0.7222 - val_loss: 2.0304\n",
      "Epoch 1075/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9963 - loss: 0.0135 - val_accuracy: 0.7333 - val_loss: 2.0056\n",
      "Epoch 1076/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9929 - loss: 0.0177 - val_accuracy: 0.7333 - val_loss: 1.9816\n",
      "Epoch 1077/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9982 - loss: 0.0082 - val_accuracy: 0.7333 - val_loss: 1.9614\n",
      "Epoch 1078/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.7333 - val_loss: 1.9330\n",
      "Epoch 1079/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.7444 - val_loss: 1.9060\n",
      "Epoch 1080/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.7556 - val_loss: 1.8999\n",
      "Epoch 1081/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9878 - loss: 0.0260 - val_accuracy: 0.7556 - val_loss: 1.9029\n",
      "Epoch 1082/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.0046 - val_accuracy: 0.7556 - val_loss: 1.9322\n",
      "Epoch 1083/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0046 - val_accuracy: 0.7556 - val_loss: 1.9473\n",
      "Epoch 1084/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7556 - val_loss: 1.9384\n",
      "Epoch 1085/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9980 - loss: 0.0039 - val_accuracy: 0.7556 - val_loss: 1.9125\n",
      "Epoch 1086/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0035 - val_accuracy: 0.7556 - val_loss: 1.8524\n",
      "Epoch 1087/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.7667 - val_loss: 1.8032\n",
      "Epoch 1088/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.7667 - val_loss: 1.7531\n",
      "Epoch 1089/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.7667 - val_loss: 1.7274\n",
      "Epoch 1090/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.1405e-04 - val_accuracy: 0.7667 - val_loss: 1.7119\n",
      "Epoch 1091/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.7556 - val_loss: 1.7082\n",
      "Epoch 1092/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9916 - loss: 0.0120 - val_accuracy: 0.7556 - val_loss: 1.7172\n",
      "Epoch 1093/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.7667 - val_loss: 1.7397\n",
      "Epoch 1094/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.0138 - val_accuracy: 0.7778 - val_loss: 1.7297\n",
      "Epoch 1095/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0092 - val_accuracy: 0.8000 - val_loss: 1.7304\n",
      "Epoch 1096/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.7778 - val_loss: 1.7285\n",
      "Epoch 1097/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7667 - val_loss: 1.7271\n",
      "Epoch 1098/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7667 - val_loss: 1.7305\n",
      "Epoch 1099/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.7667 - val_loss: 1.7288\n",
      "Epoch 1100/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7667 - val_loss: 1.7321\n",
      "Epoch 1101/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.7667 - val_loss: 1.7490\n",
      "Epoch 1102/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.7556 - val_loss: 1.7729\n",
      "Epoch 1103/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0074 - val_accuracy: 0.7444 - val_loss: 1.7770\n",
      "Epoch 1104/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7444 - val_loss: 1.7762\n",
      "Epoch 1105/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0105 - val_accuracy: 0.7444 - val_loss: 1.7768\n",
      "Epoch 1106/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7444 - val_loss: 1.7784\n",
      "Epoch 1107/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0111 - val_accuracy: 0.7444 - val_loss: 1.7586\n",
      "Epoch 1108/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9963 - loss: 0.0045 - val_accuracy: 0.7556 - val_loss: 1.7458\n",
      "Epoch 1109/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0189 - val_accuracy: 0.7667 - val_loss: 1.7636\n",
      "Epoch 1110/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7667 - val_loss: 1.7967\n",
      "Epoch 1111/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9951 - loss: 0.0148 - val_accuracy: 0.7667 - val_loss: 1.8216\n",
      "Epoch 1112/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7667 - val_loss: 1.8577\n",
      "Epoch 1113/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7667 - val_loss: 1.8761\n",
      "Epoch 1114/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7778 - val_loss: 1.8850\n",
      "Epoch 1115/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0088 - val_accuracy: 0.7667 - val_loss: 1.8649\n",
      "Epoch 1116/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.7667 - val_loss: 1.8522\n",
      "Epoch 1117/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.7667 - val_loss: 1.8373\n",
      "Epoch 1118/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.7667 - val_loss: 1.8312\n",
      "Epoch 1119/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.7667 - val_loss: 1.8311\n",
      "Epoch 1120/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9980 - loss: 0.0079 - val_accuracy: 0.7778 - val_loss: 1.8396\n",
      "Epoch 1121/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9916 - loss: 0.0136 - val_accuracy: 0.7778 - val_loss: 1.8569\n",
      "Epoch 1122/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.1157e-04 - val_accuracy: 0.7667 - val_loss: 1.8669\n",
      "Epoch 1123/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0066 - val_accuracy: 0.7667 - val_loss: 1.8891\n",
      "Epoch 1124/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9964 - loss: 0.0074 - val_accuracy: 0.7667 - val_loss: 1.8710\n",
      "Epoch 1125/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0039 - val_accuracy: 0.7778 - val_loss: 1.8356\n",
      "Epoch 1126/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.7778 - val_loss: 1.8173\n",
      "Epoch 1127/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.7778 - val_loss: 1.8031\n",
      "Epoch 1128/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7667 - val_loss: 1.8006\n",
      "Epoch 1129/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9963 - loss: 0.0070 - val_accuracy: 0.7667 - val_loss: 1.8023\n",
      "Epoch 1130/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.7556 - val_loss: 1.8145\n",
      "Epoch 1131/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7556 - val_loss: 1.8245\n",
      "Epoch 1132/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7556 - val_loss: 1.8303\n",
      "Epoch 1133/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0065 - val_accuracy: 0.7556 - val_loss: 1.8116\n",
      "Epoch 1134/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0093 - val_accuracy: 0.7556 - val_loss: 1.8409\n",
      "Epoch 1135/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0046 - val_accuracy: 0.7556 - val_loss: 1.8946\n",
      "Epoch 1136/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.7556 - val_loss: 1.9091\n",
      "Epoch 1137/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0107 - val_accuracy: 0.7556 - val_loss: 1.9409\n",
      "Epoch 1138/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.7444 - val_loss: 1.9889\n",
      "Epoch 1139/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7556 - val_loss: 2.0094\n",
      "Epoch 1140/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0111 - val_accuracy: 0.7556 - val_loss: 2.0413\n",
      "Epoch 1141/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0022 - val_accuracy: 0.7556 - val_loss: 2.0630\n",
      "Epoch 1142/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7667 - val_loss: 2.0801\n",
      "Epoch 1143/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7667 - val_loss: 2.0958\n",
      "Epoch 1144/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7667 - val_loss: 2.0851\n",
      "Epoch 1145/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.7667 - val_loss: 2.0859\n",
      "Epoch 1146/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.5763e-04 - val_accuracy: 0.7556 - val_loss: 2.0851\n",
      "Epoch 1147/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.7556 - val_loss: 2.0706\n",
      "Epoch 1148/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7667 - val_loss: 2.0459\n",
      "Epoch 1149/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7667 - val_loss: 2.0258\n",
      "Epoch 1150/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.7667 - val_loss: 2.0224\n",
      "Epoch 1151/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.7667 - val_loss: 2.0236\n",
      "Epoch 1152/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.7667 - val_loss: 1.9826\n",
      "Epoch 1153/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0047 - val_accuracy: 0.7667 - val_loss: 1.9606\n",
      "Epoch 1154/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9963 - loss: 0.0061 - val_accuracy: 0.7556 - val_loss: 1.9655\n",
      "Epoch 1155/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.7556 - val_loss: 1.9775\n",
      "Epoch 1156/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.7667 - val_loss: 1.9772\n",
      "Epoch 1157/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0137 - val_accuracy: 0.7667 - val_loss: 1.9582\n",
      "Epoch 1158/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0160 - val_accuracy: 0.7778 - val_loss: 1.9377\n",
      "Epoch 1159/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.7778 - val_loss: 1.9211\n",
      "Epoch 1160/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.7889 - val_loss: 1.9168\n",
      "Epoch 1161/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0060 - val_accuracy: 0.7778 - val_loss: 1.9443\n",
      "Epoch 1162/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0085 - val_accuracy: 0.7667 - val_loss: 2.0213\n",
      "Epoch 1163/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0046 - val_accuracy: 0.7667 - val_loss: 2.0639\n",
      "Epoch 1164/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.7667 - val_loss: 2.0776\n",
      "Epoch 1165/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7667 - val_loss: 2.0835\n",
      "Epoch 1166/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.7667 - val_loss: 2.0904\n",
      "Epoch 1167/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.7667 - val_loss: 2.1086\n",
      "Epoch 1168/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.7667 - val_loss: 2.1150\n",
      "Epoch 1169/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.7667 - val_loss: 2.1167\n",
      "Epoch 1170/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9954 - loss: 0.0144 - val_accuracy: 0.7667 - val_loss: 2.1041\n",
      "Epoch 1171/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.0222 - val_accuracy: 0.7556 - val_loss: 2.0188\n",
      "Epoch 1172/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7667 - val_loss: 1.9761\n",
      "Epoch 1173/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0026 - val_accuracy: 0.7667 - val_loss: 1.9645\n",
      "Epoch 1174/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.7667 - val_loss: 1.9548\n",
      "Epoch 1175/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.7667 - val_loss: 1.9438\n",
      "Epoch 1176/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0180 - val_accuracy: 0.7667 - val_loss: 1.9214\n",
      "Epoch 1177/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7667 - val_loss: 1.9093\n",
      "Epoch 1178/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7667 - val_loss: 1.9052\n",
      "Epoch 1179/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.7778 - val_loss: 1.9129\n",
      "Epoch 1180/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9923 - loss: 0.0101 - val_accuracy: 0.7778 - val_loss: 1.9738\n",
      "Epoch 1181/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9929 - loss: 0.0158 - val_accuracy: 0.7556 - val_loss: 2.1300\n",
      "Epoch 1182/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9905 - loss: 0.0143 - val_accuracy: 0.7556 - val_loss: 2.2400\n",
      "Epoch 1183/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 0.0158 - val_accuracy: 0.7556 - val_loss: 2.2699\n",
      "Epoch 1184/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.0166 - val_accuracy: 0.7444 - val_loss: 2.2904\n",
      "Epoch 1185/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7333 - val_loss: 2.2981\n",
      "Epoch 1186/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0075 - val_accuracy: 0.7333 - val_loss: 2.2780\n",
      "Epoch 1187/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0045 - val_accuracy: 0.7333 - val_loss: 2.2525\n",
      "Epoch 1188/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7333 - val_loss: 2.2170\n",
      "Epoch 1189/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7333 - val_loss: 2.1899\n",
      "Epoch 1190/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9923 - loss: 0.0122 - val_accuracy: 0.7556 - val_loss: 2.1634\n",
      "Epoch 1191/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0063 - val_accuracy: 0.7556 - val_loss: 2.1695\n",
      "Epoch 1192/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.7556 - val_loss: 2.2146\n",
      "Epoch 1193/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.7444 - val_loss: 2.2242\n",
      "Epoch 1194/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0122 - val_accuracy: 0.7444 - val_loss: 2.2529\n",
      "Epoch 1195/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9916 - loss: 0.0140 - val_accuracy: 0.7556 - val_loss: 2.2202\n",
      "Epoch 1196/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0084 - val_accuracy: 0.7556 - val_loss: 2.1981\n",
      "Epoch 1197/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.7667 - val_loss: 2.1799\n",
      "Epoch 1198/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.7667 - val_loss: 2.1715\n",
      "Epoch 1199/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.7556 - val_loss: 2.1726\n",
      "Epoch 1200/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0048 - val_accuracy: 0.7556 - val_loss: 2.1603\n",
      "Epoch 1201/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9941 - loss: 0.0141 - val_accuracy: 0.7667 - val_loss: 2.1311\n",
      "Epoch 1202/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9963 - loss: 0.0131 - val_accuracy: 0.7667 - val_loss: 2.1242\n",
      "Epoch 1203/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7667 - val_loss: 2.1316\n",
      "Epoch 1204/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0055 - val_accuracy: 0.7778 - val_loss: 2.1278\n",
      "Epoch 1205/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0074 - val_accuracy: 0.7889 - val_loss: 2.1268\n",
      "Epoch 1206/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.7889 - val_loss: 2.1274\n",
      "Epoch 1207/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0084 - val_accuracy: 0.7889 - val_loss: 2.1320\n",
      "Epoch 1208/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9963 - loss: 0.0113 - val_accuracy: 0.7889 - val_loss: 2.1420\n",
      "Epoch 1209/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9982 - loss: 0.0097 - val_accuracy: 0.7667 - val_loss: 2.1663\n",
      "Epoch 1210/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.7556 - val_loss: 2.1789\n",
      "Epoch 1211/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.7556 - val_loss: 2.1740\n",
      "Epoch 1212/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9941 - loss: 0.0080 - val_accuracy: 0.7667 - val_loss: 2.1255\n",
      "Epoch 1213/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0067 - val_accuracy: 0.7556 - val_loss: 2.0716\n",
      "Epoch 1214/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7556 - val_loss: 2.0467\n",
      "Epoch 1215/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7556 - val_loss: 2.0514\n",
      "Epoch 1216/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7444 - val_loss: 2.0612\n",
      "Epoch 1217/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.7444 - val_loss: 2.0715\n",
      "Epoch 1218/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.7444 - val_loss: 2.0741\n",
      "Epoch 1219/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7556 - val_loss: 2.0725\n",
      "Epoch 1220/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7667 - val_loss: 2.0733\n",
      "Epoch 1221/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.7556 - val_loss: 2.0997\n",
      "Epoch 1222/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9982 - loss: 0.0085 - val_accuracy: 0.7667 - val_loss: 2.1560\n",
      "Epoch 1223/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.7444 - val_loss: 2.1985\n",
      "Epoch 1224/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.7556 - val_loss: 2.2173\n",
      "Epoch 1225/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9970 - loss: 0.0084 - val_accuracy: 0.7556 - val_loss: 2.2453\n",
      "Epoch 1226/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7444 - val_loss: 2.2685\n",
      "Epoch 1227/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.7444 - val_loss: 2.2747\n",
      "Epoch 1228/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.7160e-04 - val_accuracy: 0.7444 - val_loss: 2.2852\n",
      "Epoch 1229/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.7778 - val_loss: 2.2961\n",
      "Epoch 1230/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9963 - loss: 0.0145 - val_accuracy: 0.7778 - val_loss: 2.2788\n",
      "Epoch 1231/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 8.5615e-04 - val_accuracy: 0.7667 - val_loss: 2.2335\n",
      "Epoch 1232/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.7667 - val_loss: 2.1847\n",
      "Epoch 1233/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9963 - loss: 0.0123 - val_accuracy: 0.7556 - val_loss: 2.1535\n",
      "Epoch 1234/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.7889 - val_loss: 2.1384\n",
      "Epoch 1235/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0172 - val_accuracy: 0.8000 - val_loss: 2.1093\n",
      "Epoch 1236/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0060 - val_accuracy: 0.7778 - val_loss: 2.0959\n",
      "Epoch 1237/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7778 - val_loss: 2.0863\n",
      "Epoch 1238/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7667 - val_loss: 2.0764\n",
      "Epoch 1239/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9951 - loss: 0.0091 - val_accuracy: 0.7778 - val_loss: 2.0637\n",
      "Epoch 1240/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0021 - val_accuracy: 0.7889 - val_loss: 2.0396\n",
      "Epoch 1241/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0048 - val_accuracy: 0.7889 - val_loss: 2.0257\n",
      "Epoch 1242/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.7889 - val_loss: 2.0247\n",
      "Epoch 1243/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7889 - val_loss: 2.0238\n",
      "Epoch 1244/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.0201 - val_accuracy: 0.7889 - val_loss: 2.0164\n",
      "Epoch 1245/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7889 - val_loss: 2.0162\n",
      "Epoch 1246/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.0093 - val_accuracy: 0.7889 - val_loss: 2.0082\n",
      "Epoch 1247/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7889 - val_loss: 2.0022\n",
      "Epoch 1248/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.7889 - val_loss: 2.0066\n",
      "Epoch 1249/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 7.3791e-04 - val_accuracy: 0.7889 - val_loss: 2.0166\n",
      "Epoch 1250/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.7889 - val_loss: 2.0304\n",
      "Epoch 1251/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.7889 - val_loss: 2.0371\n",
      "Epoch 1252/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7778 - val_loss: 2.0421\n",
      "Epoch 1253/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0046 - val_accuracy: 0.7778 - val_loss: 2.0576\n",
      "Epoch 1254/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9962 - loss: 0.0111 - val_accuracy: 0.7667 - val_loss: 2.0898\n",
      "Epoch 1255/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0066 - val_accuracy: 0.7778 - val_loss: 2.1135\n",
      "Epoch 1256/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7778 - val_loss: 2.1151\n",
      "Epoch 1257/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7889 - val_loss: 2.0868\n",
      "Epoch 1258/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7889 - val_loss: 2.0555\n",
      "Epoch 1259/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9982 - loss: 0.0099 - val_accuracy: 0.7778 - val_loss: 2.0282\n",
      "Epoch 1260/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0097 - val_accuracy: 0.7889 - val_loss: 2.0236\n",
      "Epoch 1261/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9963 - loss: 0.0077 - val_accuracy: 0.7778 - val_loss: 1.9672\n",
      "Epoch 1262/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0091 - val_accuracy: 0.7778 - val_loss: 1.9327\n",
      "Epoch 1263/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.7778 - val_loss: 1.9121\n",
      "Epoch 1264/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7778 - val_loss: 1.9037\n",
      "Epoch 1265/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.7778 - val_loss: 1.9013\n",
      "Epoch 1266/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7778 - val_loss: 1.9144\n",
      "Epoch 1267/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7778 - val_loss: 1.9275\n",
      "Epoch 1268/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7778 - val_loss: 1.9504\n",
      "Epoch 1269/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 8.0815e-04 - val_accuracy: 0.7778 - val_loss: 1.9702\n",
      "Epoch 1270/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.7778 - val_loss: 1.9898\n",
      "Epoch 1271/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7667 - val_loss: 2.0068\n",
      "Epoch 1272/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0088 - val_accuracy: 0.7778 - val_loss: 1.9866\n",
      "Epoch 1273/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9963 - loss: 0.0135 - val_accuracy: 0.7778 - val_loss: 1.9749\n",
      "Epoch 1274/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9941 - loss: 0.0099 - val_accuracy: 0.7778 - val_loss: 1.9830\n",
      "Epoch 1275/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7778 - val_loss: 1.9836\n",
      "Epoch 1276/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.7778 - val_loss: 1.9850\n",
      "Epoch 1277/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.7778 - val_loss: 1.9784\n",
      "Epoch 1278/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0093 - val_accuracy: 0.7778 - val_loss: 1.9771\n",
      "Epoch 1279/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7778 - val_loss: 1.9607\n",
      "Epoch 1280/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0089 - val_accuracy: 0.7778 - val_loss: 1.9758\n",
      "Epoch 1281/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7778 - val_loss: 2.0060\n",
      "Epoch 1282/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9970 - loss: 0.0083 - val_accuracy: 0.7778 - val_loss: 2.0152\n",
      "Epoch 1283/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9846 - loss: 0.0280 - val_accuracy: 0.8000 - val_loss: 2.0182\n",
      "Epoch 1284/1500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8000 - val_loss: 2.0312\n",
      "Epoch 1285/1500\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.8524e-04"
     ]
    }
   ],
   "source": [
    "history11 = model11.fit(X2_train_scaled, y2_train, \n",
    "                        validation_data=(X2_val_scaled, y2_val), \n",
    "                        batch_size=64, \n",
    "                        epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae83b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [10/1500], Train Loss: 1.5778, Train Accuracy: 0.3528, Val Loss: 1.6043, Val Accuracy: 0.3222\n",
      "Epoch [20/1500], Train Loss: 1.5449, Train Accuracy: 0.4056, Val Loss: 1.5519, Val Accuracy: 0.6222\n",
      "Epoch [30/1500], Train Loss: 1.4859, Train Accuracy: 0.5139, Val Loss: 1.4688, Val Accuracy: 0.6111\n",
      "Epoch [40/1500], Train Loss: 1.4449, Train Accuracy: 0.5056, Val Loss: 1.4031, Val Accuracy: 0.6333\n",
      "Epoch [50/1500], Train Loss: 1.3864, Train Accuracy: 0.5972, Val Loss: 1.3409, Val Accuracy: 0.7000\n",
      "Epoch [60/1500], Train Loss: 1.3345, Train Accuracy: 0.6222, Val Loss: 1.2790, Val Accuracy: 0.7333\n",
      "Epoch [70/1500], Train Loss: 1.2843, Train Accuracy: 0.6694, Val Loss: 1.2289, Val Accuracy: 0.7556\n",
      "Epoch [80/1500], Train Loss: 1.2231, Train Accuracy: 0.7444, Val Loss: 1.1805, Val Accuracy: 0.8111\n",
      "Epoch [90/1500], Train Loss: 1.1872, Train Accuracy: 0.8028, Val Loss: 1.1406, Val Accuracy: 0.8556\n",
      "Epoch [100/1500], Train Loss: 1.1424, Train Accuracy: 0.8333, Val Loss: 1.1049, Val Accuracy: 0.8778\n",
      "Epoch [110/1500], Train Loss: 1.0765, Train Accuracy: 0.8944, Val Loss: 1.0757, Val Accuracy: 0.8889\n",
      "Epoch [120/1500], Train Loss: 1.0723, Train Accuracy: 0.9000, Val Loss: 1.0579, Val Accuracy: 0.8889\n",
      "Epoch [130/1500], Train Loss: 1.0441, Train Accuracy: 0.9167, Val Loss: 1.0451, Val Accuracy: 0.8889\n",
      "Epoch [140/1500], Train Loss: 1.0201, Train Accuracy: 0.9333, Val Loss: 1.0378, Val Accuracy: 0.8889\n",
      "Epoch [150/1500], Train Loss: 1.0102, Train Accuracy: 0.9417, Val Loss: 1.0349, Val Accuracy: 0.8778\n",
      "Epoch [160/1500], Train Loss: 0.9803, Train Accuracy: 0.9722, Val Loss: 1.0287, Val Accuracy: 0.8778\n",
      "Epoch [170/1500], Train Loss: 0.9756, Train Accuracy: 0.9639, Val Loss: 1.0255, Val Accuracy: 0.8778\n",
      "Epoch [180/1500], Train Loss: 0.9584, Train Accuracy: 0.9694, Val Loss: 1.0248, Val Accuracy: 0.8778\n",
      "Epoch [190/1500], Train Loss: 0.9657, Train Accuracy: 0.9667, Val Loss: 1.0225, Val Accuracy: 0.8778\n",
      "Epoch [200/1500], Train Loss: 0.9527, Train Accuracy: 0.9778, Val Loss: 1.0225, Val Accuracy: 0.8889\n",
      "Epoch [210/1500], Train Loss: 0.9608, Train Accuracy: 0.9583, Val Loss: 1.0186, Val Accuracy: 0.8889\n",
      "Epoch [220/1500], Train Loss: 0.9447, Train Accuracy: 0.9750, Val Loss: 1.0156, Val Accuracy: 0.8889\n",
      "Epoch [230/1500], Train Loss: 0.9427, Train Accuracy: 0.9778, Val Loss: 1.0177, Val Accuracy: 0.8889\n",
      "Epoch [240/1500], Train Loss: 0.9372, Train Accuracy: 0.9833, Val Loss: 1.0158, Val Accuracy: 0.8889\n",
      "Epoch [250/1500], Train Loss: 0.9383, Train Accuracy: 0.9806, Val Loss: 1.0146, Val Accuracy: 0.8889\n",
      "Epoch [260/1500], Train Loss: 0.9468, Train Accuracy: 0.9750, Val Loss: 1.0146, Val Accuracy: 0.8889\n",
      "Epoch [270/1500], Train Loss: 0.9373, Train Accuracy: 0.9833, Val Loss: 1.0128, Val Accuracy: 0.8889\n",
      "Epoch [280/1500], Train Loss: 0.9307, Train Accuracy: 0.9917, Val Loss: 1.0111, Val Accuracy: 0.8889\n",
      "Epoch [290/1500], Train Loss: 0.9379, Train Accuracy: 0.9778, Val Loss: 1.0142, Val Accuracy: 0.9000\n",
      "Epoch [300/1500], Train Loss: 0.9309, Train Accuracy: 0.9861, Val Loss: 1.0117, Val Accuracy: 0.9000\n",
      "Epoch [310/1500], Train Loss: 0.9276, Train Accuracy: 0.9917, Val Loss: 1.0132, Val Accuracy: 0.8889\n",
      "Epoch [320/1500], Train Loss: 0.9302, Train Accuracy: 0.9833, Val Loss: 1.0158, Val Accuracy: 0.8889\n",
      "Epoch [330/1500], Train Loss: 0.9323, Train Accuracy: 0.9861, Val Loss: 1.0176, Val Accuracy: 0.8778\n",
      "Epoch [340/1500], Train Loss: 0.9251, Train Accuracy: 0.9917, Val Loss: 1.0145, Val Accuracy: 0.8889\n",
      "Epoch [350/1500], Train Loss: 0.9263, Train Accuracy: 0.9889, Val Loss: 1.0146, Val Accuracy: 0.8889\n",
      "Epoch [360/1500], Train Loss: 0.9234, Train Accuracy: 0.9917, Val Loss: 1.0113, Val Accuracy: 0.8889\n",
      "Epoch [370/1500], Train Loss: 0.9193, Train Accuracy: 0.9917, Val Loss: 1.0117, Val Accuracy: 0.9000\n",
      "Epoch [380/1500], Train Loss: 0.9217, Train Accuracy: 0.9944, Val Loss: 1.0140, Val Accuracy: 0.8889\n",
      "Epoch [390/1500], Train Loss: 0.9194, Train Accuracy: 0.9917, Val Loss: 1.0241, Val Accuracy: 0.8778\n",
      "Epoch [400/1500], Train Loss: 0.9194, Train Accuracy: 0.9944, Val Loss: 1.0136, Val Accuracy: 0.8889\n",
      "Epoch [410/1500], Train Loss: 0.9204, Train Accuracy: 0.9944, Val Loss: 1.0157, Val Accuracy: 0.8889\n",
      "Epoch [420/1500], Train Loss: 0.9169, Train Accuracy: 0.9944, Val Loss: 1.0122, Val Accuracy: 0.9000\n",
      "Epoch [430/1500], Train Loss: 0.9186, Train Accuracy: 0.9972, Val Loss: 1.0063, Val Accuracy: 0.9000\n",
      "Epoch [440/1500], Train Loss: 0.9177, Train Accuracy: 0.9972, Val Loss: 1.0166, Val Accuracy: 0.8889\n",
      "Epoch [450/1500], Train Loss: 0.9123, Train Accuracy: 0.9972, Val Loss: 1.0061, Val Accuracy: 0.9111\n",
      "Epoch [460/1500], Train Loss: 0.9158, Train Accuracy: 0.9889, Val Loss: 1.0026, Val Accuracy: 0.9000\n",
      "Epoch [470/1500], Train Loss: 0.9134, Train Accuracy: 0.9972, Val Loss: 1.0162, Val Accuracy: 0.9000\n",
      "Epoch [480/1500], Train Loss: 0.9102, Train Accuracy: 1.0000, Val Loss: 1.0067, Val Accuracy: 0.9000\n",
      "Epoch [490/1500], Train Loss: 0.9172, Train Accuracy: 0.9944, Val Loss: 1.0081, Val Accuracy: 0.9000\n",
      "Epoch [500/1500], Train Loss: 0.9109, Train Accuracy: 0.9972, Val Loss: 1.0024, Val Accuracy: 0.9000\n",
      "Epoch [510/1500], Train Loss: 0.9107, Train Accuracy: 1.0000, Val Loss: 1.0065, Val Accuracy: 0.9000\n",
      "Epoch [520/1500], Train Loss: 0.9100, Train Accuracy: 0.9972, Val Loss: 1.0068, Val Accuracy: 0.9000\n",
      "Epoch [530/1500], Train Loss: 0.9084, Train Accuracy: 1.0000, Val Loss: 1.0064, Val Accuracy: 0.9000\n",
      "Epoch [540/1500], Train Loss: 0.9086, Train Accuracy: 1.0000, Val Loss: 1.0097, Val Accuracy: 0.8889\n",
      "Epoch [550/1500], Train Loss: 0.9117, Train Accuracy: 0.9972, Val Loss: 1.0127, Val Accuracy: 0.9000\n",
      "Epoch [560/1500], Train Loss: 0.9100, Train Accuracy: 0.9972, Val Loss: 1.0099, Val Accuracy: 0.9000\n",
      "Epoch [570/1500], Train Loss: 0.9122, Train Accuracy: 0.9944, Val Loss: 1.0051, Val Accuracy: 0.9000\n",
      "Epoch [580/1500], Train Loss: 0.9118, Train Accuracy: 0.9972, Val Loss: 1.0125, Val Accuracy: 0.8889\n",
      "Epoch [590/1500], Train Loss: 0.9076, Train Accuracy: 1.0000, Val Loss: 1.0071, Val Accuracy: 0.9000\n",
      "Epoch [600/1500], Train Loss: 0.9125, Train Accuracy: 0.9944, Val Loss: 1.0084, Val Accuracy: 0.9000\n",
      "Epoch [610/1500], Train Loss: 0.9097, Train Accuracy: 0.9972, Val Loss: 1.0127, Val Accuracy: 0.8889\n",
      "Epoch [620/1500], Train Loss: 0.9079, Train Accuracy: 1.0000, Val Loss: 1.0060, Val Accuracy: 0.9000\n",
      "Epoch [630/1500], Train Loss: 0.9123, Train Accuracy: 0.9944, Val Loss: 1.0013, Val Accuracy: 0.9000\n",
      "Epoch [640/1500], Train Loss: 0.9077, Train Accuracy: 1.0000, Val Loss: 1.0049, Val Accuracy: 0.8889\n",
      "Epoch [650/1500], Train Loss: 0.9088, Train Accuracy: 0.9972, Val Loss: 1.0025, Val Accuracy: 0.9000\n",
      "Epoch [660/1500], Train Loss: 0.9103, Train Accuracy: 1.0000, Val Loss: 1.0004, Val Accuracy: 0.9000\n",
      "Epoch [670/1500], Train Loss: 0.9093, Train Accuracy: 1.0000, Val Loss: 1.0106, Val Accuracy: 0.8889\n",
      "Epoch [680/1500], Train Loss: 0.9116, Train Accuracy: 0.9972, Val Loss: 1.0112, Val Accuracy: 0.8889\n",
      "Epoch [690/1500], Train Loss: 0.9104, Train Accuracy: 0.9972, Val Loss: 1.0096, Val Accuracy: 0.8889\n",
      "Epoch [700/1500], Train Loss: 0.9095, Train Accuracy: 0.9972, Val Loss: 1.0122, Val Accuracy: 0.8889\n",
      "Epoch [710/1500], Train Loss: 0.9096, Train Accuracy: 1.0000, Val Loss: 1.0072, Val Accuracy: 0.8889\n",
      "Epoch [720/1500], Train Loss: 0.9096, Train Accuracy: 0.9972, Val Loss: 1.0131, Val Accuracy: 0.8889\n",
      "Epoch [730/1500], Train Loss: 0.9099, Train Accuracy: 0.9972, Val Loss: 1.0112, Val Accuracy: 0.8889\n",
      "Epoch [740/1500], Train Loss: 0.9079, Train Accuracy: 0.9972, Val Loss: 1.0105, Val Accuracy: 0.8889\n",
      "Epoch [750/1500], Train Loss: 0.9095, Train Accuracy: 1.0000, Val Loss: 1.0067, Val Accuracy: 0.9000\n",
      "Epoch [760/1500], Train Loss: 0.9077, Train Accuracy: 1.0000, Val Loss: 1.0069, Val Accuracy: 0.9000\n",
      "Epoch [770/1500], Train Loss: 0.9069, Train Accuracy: 1.0000, Val Loss: 1.0076, Val Accuracy: 0.8889\n",
      "Epoch [780/1500], Train Loss: 0.9095, Train Accuracy: 1.0000, Val Loss: 1.0031, Val Accuracy: 0.9111\n",
      "Epoch [790/1500], Train Loss: 0.9085, Train Accuracy: 1.0000, Val Loss: 1.0132, Val Accuracy: 0.8889\n",
      "Epoch [800/1500], Train Loss: 0.9068, Train Accuracy: 1.0000, Val Loss: 1.0113, Val Accuracy: 0.9000\n",
      "Epoch [810/1500], Train Loss: 0.9125, Train Accuracy: 0.9917, Val Loss: 1.0187, Val Accuracy: 0.8889\n",
      "Epoch [820/1500], Train Loss: 0.9081, Train Accuracy: 0.9972, Val Loss: 1.0042, Val Accuracy: 0.9000\n",
      "Epoch [830/1500], Train Loss: 0.9060, Train Accuracy: 1.0000, Val Loss: 1.0081, Val Accuracy: 0.9000\n",
      "Epoch [840/1500], Train Loss: 0.9083, Train Accuracy: 1.0000, Val Loss: 1.0126, Val Accuracy: 0.8889\n",
      "Epoch [850/1500], Train Loss: 0.9127, Train Accuracy: 0.9917, Val Loss: 1.0079, Val Accuracy: 0.8889\n",
      "Epoch [860/1500], Train Loss: 0.9063, Train Accuracy: 1.0000, Val Loss: 1.0111, Val Accuracy: 0.8889\n",
      "Epoch [870/1500], Train Loss: 0.9106, Train Accuracy: 0.9944, Val Loss: 1.0060, Val Accuracy: 0.8889\n",
      "Epoch [880/1500], Train Loss: 0.9093, Train Accuracy: 0.9972, Val Loss: 1.0074, Val Accuracy: 0.8889\n",
      "Epoch [890/1500], Train Loss: 0.9074, Train Accuracy: 1.0000, Val Loss: 0.9954, Val Accuracy: 0.9111\n",
      "Epoch [900/1500], Train Loss: 0.9081, Train Accuracy: 0.9972, Val Loss: 1.0162, Val Accuracy: 0.8778\n",
      "Epoch [910/1500], Train Loss: 0.9080, Train Accuracy: 1.0000, Val Loss: 1.0125, Val Accuracy: 0.8889\n",
      "Epoch [920/1500], Train Loss: 0.9094, Train Accuracy: 1.0000, Val Loss: 1.0085, Val Accuracy: 0.8889\n",
      "Epoch [930/1500], Train Loss: 0.9101, Train Accuracy: 0.9972, Val Loss: 1.0022, Val Accuracy: 0.9111\n",
      "Epoch [940/1500], Train Loss: 0.9060, Train Accuracy: 1.0000, Val Loss: 1.0151, Val Accuracy: 0.8889\n",
      "Epoch [950/1500], Train Loss: 0.9074, Train Accuracy: 0.9972, Val Loss: 1.0172, Val Accuracy: 0.8889\n",
      "Epoch [960/1500], Train Loss: 0.9108, Train Accuracy: 0.9944, Val Loss: 1.0191, Val Accuracy: 0.8778\n",
      "Epoch [970/1500], Train Loss: 0.9061, Train Accuracy: 1.0000, Val Loss: 1.0139, Val Accuracy: 0.8889\n",
      "Epoch [980/1500], Train Loss: 0.9086, Train Accuracy: 0.9972, Val Loss: 1.0110, Val Accuracy: 0.8889\n",
      "Epoch [990/1500], Train Loss: 0.9079, Train Accuracy: 0.9972, Val Loss: 1.0049, Val Accuracy: 0.9000\n",
      "Epoch [1000/1500], Train Loss: 0.9063, Train Accuracy: 1.0000, Val Loss: 1.0136, Val Accuracy: 0.8889\n",
      "Epoch [1010/1500], Train Loss: 0.9061, Train Accuracy: 1.0000, Val Loss: 1.0078, Val Accuracy: 0.9000\n",
      "Epoch [1020/1500], Train Loss: 0.9071, Train Accuracy: 0.9972, Val Loss: 0.9977, Val Accuracy: 0.9111\n",
      "Epoch [1030/1500], Train Loss: 0.9077, Train Accuracy: 0.9972, Val Loss: 0.9954, Val Accuracy: 0.9111\n",
      "Epoch [1040/1500], Train Loss: 0.9084, Train Accuracy: 0.9972, Val Loss: 0.9964, Val Accuracy: 0.9111\n",
      "Epoch [1050/1500], Train Loss: 0.9119, Train Accuracy: 0.9944, Val Loss: 1.0062, Val Accuracy: 0.8889\n",
      "Epoch [1060/1500], Train Loss: 0.9084, Train Accuracy: 1.0000, Val Loss: 0.9895, Val Accuracy: 0.9222\n",
      "Epoch [1070/1500], Train Loss: 0.9099, Train Accuracy: 0.9972, Val Loss: 1.0226, Val Accuracy: 0.8889\n",
      "Epoch [1080/1500], Train Loss: 0.9072, Train Accuracy: 0.9972, Val Loss: 0.9924, Val Accuracy: 0.9111\n",
      "Epoch [1090/1500], Train Loss: 0.9070, Train Accuracy: 1.0000, Val Loss: 1.0150, Val Accuracy: 0.8889\n",
      "Epoch [1100/1500], Train Loss: 0.9073, Train Accuracy: 0.9972, Val Loss: 1.0327, Val Accuracy: 0.8667\n",
      "Epoch [1110/1500], Train Loss: 0.9072, Train Accuracy: 1.0000, Val Loss: 1.0204, Val Accuracy: 0.8778\n",
      "Epoch [1120/1500], Train Loss: 0.9066, Train Accuracy: 1.0000, Val Loss: 1.0257, Val Accuracy: 0.8667\n",
      "Epoch [1130/1500], Train Loss: 0.9070, Train Accuracy: 1.0000, Val Loss: 1.0085, Val Accuracy: 0.8889\n",
      "Epoch [1140/1500], Train Loss: 0.9065, Train Accuracy: 1.0000, Val Loss: 1.0109, Val Accuracy: 0.8889\n",
      "Epoch [1150/1500], Train Loss: 0.9086, Train Accuracy: 0.9972, Val Loss: 1.0064, Val Accuracy: 0.8889\n",
      "Epoch [1160/1500], Train Loss: 0.9051, Train Accuracy: 1.0000, Val Loss: 1.0081, Val Accuracy: 0.8889\n",
      "Epoch [1170/1500], Train Loss: 0.9086, Train Accuracy: 0.9972, Val Loss: 1.0144, Val Accuracy: 0.8889\n",
      "Epoch [1180/1500], Train Loss: 0.9065, Train Accuracy: 1.0000, Val Loss: 1.0140, Val Accuracy: 0.8778\n",
      "Epoch [1190/1500], Train Loss: 0.9072, Train Accuracy: 1.0000, Val Loss: 1.0181, Val Accuracy: 0.8778\n",
      "Epoch [1200/1500], Train Loss: 0.9054, Train Accuracy: 1.0000, Val Loss: 1.0128, Val Accuracy: 0.8889\n",
      "Epoch [1210/1500], Train Loss: 0.9087, Train Accuracy: 0.9972, Val Loss: 1.0166, Val Accuracy: 0.8778\n",
      "Epoch [1220/1500], Train Loss: 0.9064, Train Accuracy: 1.0000, Val Loss: 1.0230, Val Accuracy: 0.8667\n",
      "Epoch [1230/1500], Train Loss: 0.9064, Train Accuracy: 1.0000, Val Loss: 1.0074, Val Accuracy: 0.9000\n",
      "Epoch [1240/1500], Train Loss: 0.9068, Train Accuracy: 1.0000, Val Loss: 1.0158, Val Accuracy: 0.8889\n",
      "Epoch [1250/1500], Train Loss: 0.9059, Train Accuracy: 1.0000, Val Loss: 1.0146, Val Accuracy: 0.8778\n",
      "Epoch [1260/1500], Train Loss: 0.9077, Train Accuracy: 0.9972, Val Loss: 1.0130, Val Accuracy: 0.8889\n",
      "Epoch [1270/1500], Train Loss: 0.9061, Train Accuracy: 1.0000, Val Loss: 0.9960, Val Accuracy: 0.9111\n",
      "Epoch [1280/1500], Train Loss: 0.9058, Train Accuracy: 1.0000, Val Loss: 1.0058, Val Accuracy: 0.9000\n",
      "Epoch [1290/1500], Train Loss: 0.9064, Train Accuracy: 1.0000, Val Loss: 1.0055, Val Accuracy: 0.8889\n",
      "Epoch [1300/1500], Train Loss: 0.9058, Train Accuracy: 1.0000, Val Loss: 0.9939, Val Accuracy: 0.9111\n",
      "Epoch [1310/1500], Train Loss: 0.9051, Train Accuracy: 1.0000, Val Loss: 0.9920, Val Accuracy: 0.9111\n",
      "Epoch [1320/1500], Train Loss: 0.9080, Train Accuracy: 0.9972, Val Loss: 0.9973, Val Accuracy: 0.9111\n",
      "Epoch [1330/1500], Train Loss: 0.9050, Train Accuracy: 1.0000, Val Loss: 0.9934, Val Accuracy: 0.9111\n",
      "Epoch [1340/1500], Train Loss: 0.9069, Train Accuracy: 1.0000, Val Loss: 1.0015, Val Accuracy: 0.9000\n",
      "Epoch [1350/1500], Train Loss: 0.9050, Train Accuracy: 1.0000, Val Loss: 1.0078, Val Accuracy: 0.8889\n",
      "Epoch [1360/1500], Train Loss: 0.9097, Train Accuracy: 0.9972, Val Loss: 1.0100, Val Accuracy: 0.8889\n",
      "Epoch [1370/1500], Train Loss: 0.9060, Train Accuracy: 1.0000, Val Loss: 1.0127, Val Accuracy: 0.8889\n",
      "Epoch [1380/1500], Train Loss: 0.9090, Train Accuracy: 0.9972, Val Loss: 1.0173, Val Accuracy: 0.8889\n",
      "Epoch [1390/1500], Train Loss: 0.9096, Train Accuracy: 0.9972, Val Loss: 1.0169, Val Accuracy: 0.8889\n",
      "Epoch [1400/1500], Train Loss: 0.9065, Train Accuracy: 1.0000, Val Loss: 1.0137, Val Accuracy: 0.8778\n",
      "Epoch [1410/1500], Train Loss: 0.9063, Train Accuracy: 0.9972, Val Loss: 1.0127, Val Accuracy: 0.8778\n",
      "Epoch [1420/1500], Train Loss: 0.9075, Train Accuracy: 0.9972, Val Loss: 1.0164, Val Accuracy: 0.8889\n",
      "Epoch [1430/1500], Train Loss: 0.9055, Train Accuracy: 1.0000, Val Loss: 1.0050, Val Accuracy: 0.9000\n",
      "Epoch [1440/1500], Train Loss: 0.9062, Train Accuracy: 1.0000, Val Loss: 1.0093, Val Accuracy: 0.8889\n",
      "Epoch [1450/1500], Train Loss: 0.9074, Train Accuracy: 0.9972, Val Loss: 1.0240, Val Accuracy: 0.8778\n",
      "Epoch [1460/1500], Train Loss: 0.9077, Train Accuracy: 0.9972, Val Loss: 1.0046, Val Accuracy: 0.9000\n",
      "Epoch [1470/1500], Train Loss: 0.9053, Train Accuracy: 1.0000, Val Loss: 1.0066, Val Accuracy: 0.9000\n",
      "Epoch [1480/1500], Train Loss: 0.9059, Train Accuracy: 1.0000, Val Loss: 1.0060, Val Accuracy: 0.9000\n",
      "Epoch [1490/1500], Train Loss: 0.9052, Train Accuracy: 1.0000, Val Loss: 1.0114, Val Accuracy: 0.8889\n",
      "Epoch [1500/1500], Train Loss: 0.9072, Train Accuracy: 0.9972, Val Loss: 1.0077, Val Accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load and preprocess data\n",
    "df2 = pd.read_excel(\"Features1D/Features.xlsx\")\n",
    "X2 = df2.drop(['mood'], axis=1)\n",
    "y2 = df2['mood']\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y2 = le.fit_transform(y2)\n",
    "\n",
    "# Encode categorical features\n",
    "X2['scale'] = le.fit_transform(X2['scale'])\n",
    "X2['key'] = le.fit_transform(X2['key'])\n",
    "\n",
    "# Split data\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, train_size=0.9, random_state=13, shuffle=True, stratify=y2)\n",
    "X2_train, X2_val, y2_train, y2_val = train_test_split(X2_train, y2_train, train_size=0.8, random_state=13, shuffle=True, stratify=y2_train)\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "X2_train_scaled = scaler.fit_transform(X2_train.drop('file', axis=1))\n",
    "X2_val_scaled = scaler.transform(X2_val.drop('file', axis=1))\n",
    "X2_test_scaled = scaler.transform(X2_test.drop('file', axis=1))\n",
    "\n",
    "# Convert to PyTorch tensors with correct shape\n",
    "X2_train_tensor = torch.tensor(X2_train_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "y2_train_tensor = torch.tensor(y2_train, dtype=torch.long)\n",
    "X2_val_tensor = torch.tensor(X2_val_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "y2_val_tensor = torch.tensor(y2_val, dtype=torch.long)\n",
    "X2_test_tensor = torch.tensor(X2_test_scaled, dtype=torch.float32).unsqueeze(1)\n",
    "y2_test_tensor = torch.tensor(y2_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X2_train_tensor, y2_train_tensor)\n",
    "val_dataset = TensorDataset(X2_val_tensor, y2_val_tensor)\n",
    "test_dataset = TensorDataset(X2_test_tensor, y2_test_tensor)\n",
    "\n",
    "batchSize = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batchSize, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Define the model\n",
    "class Conv1DModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=5, padding='same')\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=7, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=7, padding='same')\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Adjust the number of units in the first fully connected layer based on the input shape\n",
    "        self.fc1 = nn.Linear(32 * (X2_train_scaled.shape[1] // 8), 128)\n",
    "        self.dropout1 = nn.Dropout(0.7)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.6)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.bn1(torch.relu(self.conv1(x))))\n",
    "        x = self.pool2(self.bn2(torch.relu(self.conv2(x))))\n",
    "        x = self.pool3(self.bn3(torch.relu(self.conv3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and move to GPU\n",
    "model = Conv1DModel().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_accuracy += (predicted == y_batch).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy /= len(train_loader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            val_outputs = model(X_val_batch)\n",
    "            val_loss += criterion(val_outputs, y_val_batch).item()\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            val_accuracy += (predicted == y_val_batch).sum().item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy /= len(val_loader.dataset)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7149e7d3",
   "metadata": {},
   "source": [
    "**Different number of features**</br>\n",
    "**MFCCs Only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2789432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 12\n",
    "\n",
    "model12 = modelBuilder3L(X2_train_scaled[:,17:],\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca28d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.1895 - loss: 2.0628 - val_accuracy: 0.1889 - val_loss: 1.6109\n",
      "Epoch 2/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3103 - loss: 1.6497 - val_accuracy: 0.2111 - val_loss: 1.6087\n",
      "Epoch 3/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3148 - loss: 1.5789 - val_accuracy: 0.2000 - val_loss: 1.6097\n",
      "Epoch 4/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4275 - loss: 1.3878 - val_accuracy: 0.2000 - val_loss: 1.6147\n",
      "Epoch 5/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4972 - loss: 1.2845 - val_accuracy: 0.2000 - val_loss: 1.6234\n",
      "Epoch 6/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4735 - loss: 1.2578 - val_accuracy: 0.2000 - val_loss: 1.6357\n",
      "Epoch 7/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5455 - loss: 1.1742 - val_accuracy: 0.2000 - val_loss: 1.6483\n",
      "Epoch 8/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6086 - loss: 1.0215 - val_accuracy: 0.2000 - val_loss: 1.6619\n",
      "Epoch 9/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5762 - loss: 1.1022 - val_accuracy: 0.2000 - val_loss: 1.6728\n",
      "Epoch 10/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6177 - loss: 1.0292 - val_accuracy: 0.1889 - val_loss: 1.6798\n",
      "Epoch 11/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6246 - loss: 0.9306 - val_accuracy: 0.1889 - val_loss: 1.6822\n",
      "Epoch 12/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6416 - loss: 0.9432 - val_accuracy: 0.1889 - val_loss: 1.6744\n",
      "Epoch 13/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6933 - loss: 0.9508 - val_accuracy: 0.1889 - val_loss: 1.6485\n",
      "Epoch 14/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6760 - loss: 0.8813 - val_accuracy: 0.2222 - val_loss: 1.6177\n",
      "Epoch 15/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7216 - loss: 0.7791 - val_accuracy: 0.2222 - val_loss: 1.5857\n",
      "Epoch 16/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7110 - loss: 0.7742 - val_accuracy: 0.2444 - val_loss: 1.5259\n",
      "Epoch 17/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.8227 - val_accuracy: 0.2667 - val_loss: 1.4616\n",
      "Epoch 18/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7145 - loss: 0.7431 - val_accuracy: 0.3222 - val_loss: 1.3905\n",
      "Epoch 19/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6994 - loss: 0.7529 - val_accuracy: 0.3667 - val_loss: 1.3441\n",
      "Epoch 20/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7669 - loss: 0.7187 - val_accuracy: 0.4333 - val_loss: 1.2756\n",
      "Epoch 21/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7470 - loss: 0.6911 - val_accuracy: 0.4444 - val_loss: 1.2248\n",
      "Epoch 22/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7534 - loss: 0.6541 - val_accuracy: 0.4778 - val_loss: 1.1622\n",
      "Epoch 23/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.6268 - val_accuracy: 0.5111 - val_loss: 1.0900\n",
      "Epoch 24/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7867 - loss: 0.6048 - val_accuracy: 0.5333 - val_loss: 1.0745\n",
      "Epoch 25/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7588 - loss: 0.6003 - val_accuracy: 0.5556 - val_loss: 1.0396\n",
      "Epoch 26/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8279 - loss: 0.5082 - val_accuracy: 0.5778 - val_loss: 1.0181\n",
      "Epoch 27/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.5527 - val_accuracy: 0.5889 - val_loss: 0.9916\n",
      "Epoch 28/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8473 - loss: 0.5276 - val_accuracy: 0.6000 - val_loss: 0.9684\n",
      "Epoch 29/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.5501 - val_accuracy: 0.6111 - val_loss: 0.9703\n",
      "Epoch 30/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.5183 - val_accuracy: 0.6556 - val_loss: 0.9607\n",
      "Epoch 31/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8861 - loss: 0.4091 - val_accuracy: 0.6556 - val_loss: 0.9561\n",
      "Epoch 32/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8604 - loss: 0.4023 - val_accuracy: 0.6111 - val_loss: 0.9808\n",
      "Epoch 33/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8719 - loss: 0.4294 - val_accuracy: 0.6556 - val_loss: 0.9560\n",
      "Epoch 34/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8555 - loss: 0.4036 - val_accuracy: 0.6222 - val_loss: 0.9790\n",
      "Epoch 35/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8533 - loss: 0.4306 - val_accuracy: 0.6000 - val_loss: 0.9944\n",
      "Epoch 36/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8865 - loss: 0.3798 - val_accuracy: 0.6111 - val_loss: 1.0035\n",
      "Epoch 37/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.4034 - val_accuracy: 0.6222 - val_loss: 0.9719\n",
      "Epoch 38/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8946 - loss: 0.3401 - val_accuracy: 0.6444 - val_loss: 0.9693\n",
      "Epoch 39/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8933 - loss: 0.3604 - val_accuracy: 0.6444 - val_loss: 0.9847\n",
      "Epoch 40/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8453 - loss: 0.4054 - val_accuracy: 0.6333 - val_loss: 0.9933\n",
      "Epoch 41/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8718 - loss: 0.3683 - val_accuracy: 0.6222 - val_loss: 1.0071\n",
      "Epoch 42/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9042 - loss: 0.3390 - val_accuracy: 0.6222 - val_loss: 1.0199\n",
      "Epoch 43/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8978 - loss: 0.3040 - val_accuracy: 0.6222 - val_loss: 1.0623\n",
      "Epoch 44/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9014 - loss: 0.3210 - val_accuracy: 0.6222 - val_loss: 1.0457\n",
      "Epoch 45/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8968 - loss: 0.3350 - val_accuracy: 0.6222 - val_loss: 1.0512\n",
      "Epoch 46/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9035 - loss: 0.2752 - val_accuracy: 0.6222 - val_loss: 1.0740\n",
      "Epoch 47/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8975 - loss: 0.3007 - val_accuracy: 0.6222 - val_loss: 1.0693\n",
      "Epoch 48/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9321 - loss: 0.2577 - val_accuracy: 0.6222 - val_loss: 1.0736\n",
      "Epoch 49/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9154 - loss: 0.2680 - val_accuracy: 0.6222 - val_loss: 1.0750\n",
      "Epoch 50/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9410 - loss: 0.2541 - val_accuracy: 0.6333 - val_loss: 1.0393\n",
      "Epoch 51/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9264 - loss: 0.2638 - val_accuracy: 0.6222 - val_loss: 1.0852\n",
      "Epoch 52/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8981 - loss: 0.2901 - val_accuracy: 0.6444 - val_loss: 1.0998\n",
      "Epoch 53/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9281 - loss: 0.2367 - val_accuracy: 0.6333 - val_loss: 1.0967\n",
      "Epoch 54/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9434 - loss: 0.2194 - val_accuracy: 0.6444 - val_loss: 1.1183\n",
      "Epoch 55/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9507 - loss: 0.2071 - val_accuracy: 0.6556 - val_loss: 1.0923\n",
      "Epoch 56/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9363 - loss: 0.2028 - val_accuracy: 0.6556 - val_loss: 1.1143\n",
      "Epoch 57/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9623 - loss: 0.1857 - val_accuracy: 0.6444 - val_loss: 1.1441\n",
      "Epoch 58/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9435 - loss: 0.2139 - val_accuracy: 0.6556 - val_loss: 1.1658\n",
      "Epoch 59/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9488 - loss: 0.1541 - val_accuracy: 0.6333 - val_loss: 1.1704\n",
      "Epoch 60/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9593 - loss: 0.1790 - val_accuracy: 0.6333 - val_loss: 1.1819\n",
      "Epoch 61/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9529 - loss: 0.1782 - val_accuracy: 0.6444 - val_loss: 1.1434\n",
      "Epoch 62/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9615 - loss: 0.1642 - val_accuracy: 0.6444 - val_loss: 1.1548\n",
      "Epoch 63/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9557 - loss: 0.1729 - val_accuracy: 0.6333 - val_loss: 1.1839\n",
      "Epoch 64/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.1520 - val_accuracy: 0.6444 - val_loss: 1.1879\n",
      "Epoch 65/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9570 - loss: 0.1514 - val_accuracy: 0.6444 - val_loss: 1.2096\n",
      "Epoch 66/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9435 - loss: 0.1936 - val_accuracy: 0.6444 - val_loss: 1.2196\n",
      "Epoch 67/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.1380 - val_accuracy: 0.6556 - val_loss: 1.2049\n",
      "Epoch 68/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 0.1135 - val_accuracy: 0.6556 - val_loss: 1.2250\n",
      "Epoch 69/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9800 - loss: 0.1059 - val_accuracy: 0.6667 - val_loss: 1.2560\n",
      "Epoch 70/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9568 - loss: 0.1517 - val_accuracy: 0.6667 - val_loss: 1.2240\n",
      "Epoch 71/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9692 - loss: 0.1369 - val_accuracy: 0.6556 - val_loss: 1.2079\n",
      "Epoch 72/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9746 - loss: 0.1340 - val_accuracy: 0.6556 - val_loss: 1.2339\n",
      "Epoch 73/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9714 - loss: 0.1137 - val_accuracy: 0.6556 - val_loss: 1.2292\n",
      "Epoch 74/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9745 - loss: 0.1129 - val_accuracy: 0.6556 - val_loss: 1.2766\n",
      "Epoch 75/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0920 - val_accuracy: 0.6556 - val_loss: 1.2703\n",
      "Epoch 76/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9678 - loss: 0.1228 - val_accuracy: 0.6556 - val_loss: 1.2863\n",
      "Epoch 77/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9785 - loss: 0.1111 - val_accuracy: 0.6556 - val_loss: 1.2921\n",
      "Epoch 78/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9622 - loss: 0.1250 - val_accuracy: 0.6667 - val_loss: 1.2741\n",
      "Epoch 79/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9882 - loss: 0.0855 - val_accuracy: 0.6667 - val_loss: 1.2513\n",
      "Epoch 80/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.0955 - val_accuracy: 0.6556 - val_loss: 1.2529\n"
     ]
    }
   ],
   "source": [
    "history12 = model12.fit(X2_train_scaled[:,17:], y2_train, \n",
    "                    validation_data=(X2_val_scaled[:,17:], y2_val), \n",
    "                    batch_size=16, epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313777ce",
   "metadata": {},
   "source": [
    "**Mel Spectrogram + MFCCs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e08c557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 13\n",
    "\n",
    "model13 = modelBuilder3L(X2_train_scaled[:,15:],\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab1fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.2062 - loss: 1.8760 - val_accuracy: 0.2556 - val_loss: 1.6042\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3385 - loss: 1.5969 - val_accuracy: 0.3333 - val_loss: 1.6045\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4506 - loss: 1.3962 - val_accuracy: 0.3444 - val_loss: 1.6011\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4227 - loss: 1.3265 - val_accuracy: 0.3333 - val_loss: 1.5905\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4829 - loss: 1.2833 - val_accuracy: 0.3778 - val_loss: 1.5790\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5969 - loss: 1.0869 - val_accuracy: 0.3111 - val_loss: 1.5690\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5638 - loss: 1.1224 - val_accuracy: 0.3000 - val_loss: 1.5619\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6358 - loss: 0.9994 - val_accuracy: 0.2444 - val_loss: 1.5543\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6427 - loss: 1.0322 - val_accuracy: 0.2444 - val_loss: 1.5494\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6266 - loss: 0.9667 - val_accuracy: 0.2444 - val_loss: 1.5396\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6806 - loss: 0.8604 - val_accuracy: 0.2222 - val_loss: 1.5282\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6997 - loss: 0.8398 - val_accuracy: 0.2333 - val_loss: 1.5145\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6704 - loss: 0.8913 - val_accuracy: 0.2444 - val_loss: 1.4965\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7196 - loss: 0.8218 - val_accuracy: 0.2667 - val_loss: 1.4700\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7186 - loss: 0.8127 - val_accuracy: 0.3222 - val_loss: 1.4413\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7058 - loss: 0.7977 - val_accuracy: 0.3667 - val_loss: 1.4033\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7259 - loss: 0.7639 - val_accuracy: 0.4556 - val_loss: 1.3635\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7632 - loss: 0.6742 - val_accuracy: 0.5111 - val_loss: 1.3235\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7338 - loss: 0.7323 - val_accuracy: 0.5222 - val_loss: 1.2860\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7864 - loss: 0.6262 - val_accuracy: 0.5222 - val_loss: 1.2303\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7829 - loss: 0.6049 - val_accuracy: 0.5222 - val_loss: 1.1744\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7597 - loss: 0.6609 - val_accuracy: 0.5333 - val_loss: 1.1550\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7824 - loss: 0.6265 - val_accuracy: 0.5222 - val_loss: 1.1448\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.5404 - val_accuracy: 0.5556 - val_loss: 1.1243\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.5729 - val_accuracy: 0.5556 - val_loss: 1.1291\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.5532 - val_accuracy: 0.6111 - val_loss: 1.1214\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.5333 - val_accuracy: 0.6222 - val_loss: 1.1397\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.4901 - val_accuracy: 0.6000 - val_loss: 1.1315\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8839 - loss: 0.4887 - val_accuracy: 0.6000 - val_loss: 1.1502\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.4617 - val_accuracy: 0.6000 - val_loss: 1.1502\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 0.4430 - val_accuracy: 0.5778 - val_loss: 1.1483\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8789 - loss: 0.3888 - val_accuracy: 0.5889 - val_loss: 1.1458\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8570 - loss: 0.4182 - val_accuracy: 0.5667 - val_loss: 1.1746\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8917 - loss: 0.4009 - val_accuracy: 0.5778 - val_loss: 1.1821\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8494 - loss: 0.4232 - val_accuracy: 0.5889 - val_loss: 1.1831\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8650 - loss: 0.4286 - val_accuracy: 0.5778 - val_loss: 1.1963\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8678 - loss: 0.3839 - val_accuracy: 0.5889 - val_loss: 1.2009\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8862 - loss: 0.3749 - val_accuracy: 0.5778 - val_loss: 1.2130\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8849 - loss: 0.3473 - val_accuracy: 0.5556 - val_loss: 1.2435\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9295 - loss: 0.2979 - val_accuracy: 0.5667 - val_loss: 1.2448\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8492 - loss: 0.3913 - val_accuracy: 0.5667 - val_loss: 1.2431\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9051 - loss: 0.3350 - val_accuracy: 0.5667 - val_loss: 1.2646\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9158 - loss: 0.3273 - val_accuracy: 0.5667 - val_loss: 1.2721\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9163 - loss: 0.3108 - val_accuracy: 0.5667 - val_loss: 1.2584\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9079 - loss: 0.3284 - val_accuracy: 0.5667 - val_loss: 1.2733\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8760 - loss: 0.3129 - val_accuracy: 0.5667 - val_loss: 1.3024\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.3093 - val_accuracy: 0.5444 - val_loss: 1.3072\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.2377 - val_accuracy: 0.5778 - val_loss: 1.3182\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9109 - loss: 0.2994 - val_accuracy: 0.5667 - val_loss: 1.3112\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9325 - loss: 0.2407 - val_accuracy: 0.5778 - val_loss: 1.3027\n"
     ]
    }
   ],
   "source": [
    "history13 = model13.fit(X2_train_scaled[:,15:], y2_train, \n",
    "                    validation_data=(X2_val_scaled[:,15:], y2_val), \n",
    "                    batch_size=16, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab1b1bd",
   "metadata": {},
   "source": [
    "**Mel Spectrogram + MFCCs + Tonnetz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc8197",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 14\n",
    "\n",
    "model14 = modelBuilder3L(X2_train_scaled[:,13:],\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12d654",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 312ms/step - accuracy: 0.2392 - loss: 1.9402 - val_accuracy: 0.2000 - val_loss: 1.6069\n",
      "Epoch 2/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2747 - loss: 1.8932 - val_accuracy: 0.2000 - val_loss: 1.6065\n",
      "Epoch 3/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2492 - loss: 1.8629 - val_accuracy: 0.2000 - val_loss: 1.6062\n",
      "Epoch 4/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3132 - loss: 1.7802 - val_accuracy: 0.2000 - val_loss: 1.6051\n",
      "Epoch 5/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2938 - loss: 1.7835 - val_accuracy: 0.2222 - val_loss: 1.6045\n",
      "Epoch 6/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3001 - loss: 1.6686 - val_accuracy: 0.2222 - val_loss: 1.6044\n",
      "Epoch 7/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3442 - loss: 1.6087 - val_accuracy: 0.2333 - val_loss: 1.6054\n",
      "Epoch 8/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3624 - loss: 1.5314 - val_accuracy: 0.2222 - val_loss: 1.6065\n",
      "Epoch 9/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3555 - loss: 1.4890 - val_accuracy: 0.2222 - val_loss: 1.6070\n",
      "Epoch 10/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3997 - loss: 1.5440 - val_accuracy: 0.2556 - val_loss: 1.6067\n",
      "Epoch 11/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3932 - loss: 1.4718 - val_accuracy: 0.2444 - val_loss: 1.6061\n",
      "Epoch 12/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3832 - loss: 1.4463 - val_accuracy: 0.3000 - val_loss: 1.6053\n",
      "Epoch 13/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4045 - loss: 1.3887 - val_accuracy: 0.3778 - val_loss: 1.6033\n",
      "Epoch 14/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4247 - loss: 1.4179 - val_accuracy: 0.3556 - val_loss: 1.6011\n",
      "Epoch 15/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4603 - loss: 1.3133 - val_accuracy: 0.3667 - val_loss: 1.5993\n",
      "Epoch 16/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4789 - loss: 1.3255 - val_accuracy: 0.3556 - val_loss: 1.5976\n",
      "Epoch 17/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5085 - loss: 1.2948 - val_accuracy: 0.3556 - val_loss: 1.5960\n",
      "Epoch 18/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4883 - loss: 1.2510 - val_accuracy: 0.3556 - val_loss: 1.5944\n",
      "Epoch 19/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4700 - loss: 1.2704 - val_accuracy: 0.3333 - val_loss: 1.5929\n",
      "Epoch 20/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4696 - loss: 1.2751 - val_accuracy: 0.3000 - val_loss: 1.5918\n",
      "Epoch 21/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5347 - loss: 1.2090 - val_accuracy: 0.2667 - val_loss: 1.5908\n",
      "Epoch 22/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5387 - loss: 1.2212 - val_accuracy: 0.2556 - val_loss: 1.5898\n",
      "Epoch 23/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5716 - loss: 1.1794 - val_accuracy: 0.2444 - val_loss: 1.5890\n",
      "Epoch 24/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5935 - loss: 1.1032 - val_accuracy: 0.2111 - val_loss: 1.5882\n",
      "Epoch 25/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5694 - loss: 1.1298 - val_accuracy: 0.2000 - val_loss: 1.5878\n",
      "Epoch 26/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5356 - loss: 1.1098 - val_accuracy: 0.1778 - val_loss: 1.5874\n",
      "Epoch 27/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6024 - loss: 1.0592 - val_accuracy: 0.1778 - val_loss: 1.5874\n",
      "Epoch 28/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5859 - loss: 1.0841 - val_accuracy: 0.1778 - val_loss: 1.5875\n",
      "Epoch 29/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6003 - loss: 1.0907 - val_accuracy: 0.1778 - val_loss: 1.5878\n",
      "Epoch 30/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6061 - loss: 1.0448 - val_accuracy: 0.1778 - val_loss: 1.5885\n",
      "Epoch 31/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5773 - loss: 1.0604 - val_accuracy: 0.1889 - val_loss: 1.5894\n",
      "Epoch 32/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6258 - loss: 1.0246 - val_accuracy: 0.1889 - val_loss: 1.5906\n",
      "Epoch 33/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6118 - loss: 1.0245 - val_accuracy: 0.1889 - val_loss: 1.5919\n",
      "Epoch 34/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6315 - loss: 0.9755 - val_accuracy: 0.1889 - val_loss: 1.5932\n",
      "Epoch 35/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6508 - loss: 0.9908 - val_accuracy: 0.1889 - val_loss: 1.5945\n",
      "Epoch 36/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6339 - loss: 0.9621 - val_accuracy: 0.1889 - val_loss: 1.5959\n",
      "Epoch 37/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6382 - loss: 0.9538 - val_accuracy: 0.1889 - val_loss: 1.5972\n",
      "Epoch 38/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6721 - loss: 0.9193 - val_accuracy: 0.2000 - val_loss: 1.5985\n",
      "Epoch 39/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6526 - loss: 0.9281 - val_accuracy: 0.2000 - val_loss: 1.5999\n",
      "Epoch 40/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6190 - loss: 0.9866 - val_accuracy: 0.2000 - val_loss: 1.6013\n",
      "Epoch 41/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6740 - loss: 0.9214 - val_accuracy: 0.2000 - val_loss: 1.6028\n",
      "Epoch 42/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6539 - loss: 0.9324 - val_accuracy: 0.2000 - val_loss: 1.6044\n",
      "Epoch 43/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7049 - loss: 0.8753 - val_accuracy: 0.2111 - val_loss: 1.6061\n",
      "Epoch 44/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6626 - loss: 0.9257 - val_accuracy: 0.2222 - val_loss: 1.6078\n",
      "Epoch 45/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7292 - loss: 0.8513 - val_accuracy: 0.2333 - val_loss: 1.6096\n",
      "Epoch 46/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6734 - loss: 0.9189 - val_accuracy: 0.2333 - val_loss: 1.6115\n",
      "Epoch 47/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6966 - loss: 0.8470 - val_accuracy: 0.2333 - val_loss: 1.6134\n",
      "Epoch 48/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7089 - loss: 0.7996 - val_accuracy: 0.2333 - val_loss: 1.6153\n",
      "Epoch 49/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6797 - loss: 0.8196 - val_accuracy: 0.2333 - val_loss: 1.6172\n",
      "Epoch 50/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6855 - loss: 0.8187 - val_accuracy: 0.2333 - val_loss: 1.6191\n",
      "Epoch 51/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7111 - loss: 0.8469 - val_accuracy: 0.2333 - val_loss: 1.6211\n",
      "Epoch 52/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7489 - loss: 0.7569 - val_accuracy: 0.2333 - val_loss: 1.6232\n",
      "Epoch 53/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7302 - loss: 0.7838 - val_accuracy: 0.2444 - val_loss: 1.6254\n",
      "Epoch 54/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7537 - loss: 0.7691 - val_accuracy: 0.2444 - val_loss: 1.6277\n",
      "Epoch 55/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7205 - loss: 0.7887 - val_accuracy: 0.2556 - val_loss: 1.6302\n",
      "Epoch 56/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7316 - loss: 0.7811 - val_accuracy: 0.2667 - val_loss: 1.6327\n",
      "Epoch 57/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7116 - loss: 0.7658 - val_accuracy: 0.2667 - val_loss: 1.6354\n",
      "Epoch 58/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7632 - loss: 0.7361 - val_accuracy: 0.3111 - val_loss: 1.6383\n",
      "Epoch 59/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7207 - loss: 0.7356 - val_accuracy: 0.3111 - val_loss: 1.6412\n",
      "Epoch 60/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7381 - loss: 0.7172 - val_accuracy: 0.3111 - val_loss: 1.6442\n",
      "Epoch 61/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7650 - loss: 0.7192 - val_accuracy: 0.3000 - val_loss: 1.6474\n",
      "Epoch 62/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7702 - loss: 0.7185 - val_accuracy: 0.2778 - val_loss: 1.6505\n",
      "Epoch 63/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7342 - loss: 0.7354 - val_accuracy: 0.2778 - val_loss: 1.6542\n",
      "Epoch 64/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7472 - loss: 0.7382 - val_accuracy: 0.2667 - val_loss: 1.6583\n",
      "Epoch 65/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7550 - loss: 0.7419 - val_accuracy: 0.2556 - val_loss: 1.6626\n",
      "Epoch 66/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7837 - loss: 0.6726 - val_accuracy: 0.2444 - val_loss: 1.6667\n",
      "Epoch 67/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8034 - loss: 0.6457 - val_accuracy: 0.2667 - val_loss: 1.6707\n",
      "Epoch 68/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7990 - loss: 0.6601 - val_accuracy: 0.2667 - val_loss: 1.6748\n",
      "Epoch 69/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7732 - loss: 0.6235 - val_accuracy: 0.2556 - val_loss: 1.6789\n",
      "Epoch 70/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7966 - loss: 0.5960 - val_accuracy: 0.2444 - val_loss: 1.6832\n",
      "Epoch 71/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7977 - loss: 0.6269 - val_accuracy: 0.2556 - val_loss: 1.6877\n",
      "Epoch 72/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7845 - loss: 0.6578 - val_accuracy: 0.2556 - val_loss: 1.6923\n",
      "Epoch 73/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8121 - loss: 0.6198 - val_accuracy: 0.2444 - val_loss: 1.6972\n",
      "Epoch 74/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7726 - loss: 0.6572 - val_accuracy: 0.2333 - val_loss: 1.7020\n",
      "Epoch 75/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7863 - loss: 0.6225 - val_accuracy: 0.2111 - val_loss: 1.7067\n",
      "Epoch 76/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7971 - loss: 0.6327 - val_accuracy: 0.2111 - val_loss: 1.7119\n",
      "Epoch 77/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7982 - loss: 0.6070 - val_accuracy: 0.2111 - val_loss: 1.7174\n",
      "Epoch 78/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8145 - loss: 0.5829 - val_accuracy: 0.2111 - val_loss: 1.7231\n",
      "Epoch 79/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8288 - loss: 0.5432 - val_accuracy: 0.2111 - val_loss: 1.7291\n",
      "Epoch 80/80\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7682 - loss: 0.6367 - val_accuracy: 0.2111 - val_loss: 1.7352\n"
     ]
    }
   ],
   "source": [
    "history14 = model14.fit(X2_train_scaled[:,13:], y2_train, \n",
    "                    validation_data=(X2_val_scaled[:,13:], y2_val), \n",
    "                    batch_size=256, epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d483091",
   "metadata": {},
   "source": [
    "**Mel Spectrogram + MFCCs + Tonnetz + Centroid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b84a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X2_train_scaled_4 = np.concatenate([X2_train_scaled[:,7:9],X2_train_scaled[:,13:]],axis=1)\n",
    "X2_val_scaled_4 = np.concatenate([X2_val_scaled[:,7:9],X2_val_scaled[:,13:]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c71a81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1,k1,a1 = 16,5,'relu'\n",
    "f2,k2,a2 = 32,7,'relu'\n",
    "f3,k3,a3 = 32,7,'relu'\n",
    "d1,dr1,da1,r1 = 128,0.2,'relu',0.15\n",
    "d2,dr2,da2,r2 = 64,0.2,'relu',0.15\n",
    "num = 15\n",
    "\n",
    "model15 = modelBuilder3L(X2_train_scaled_4,\n",
    "                        f1,k1,a1,\n",
    "                        f2,k2,a2,\n",
    "                        f3,k3,a3,\n",
    "                        d1,dr1,da1,r1,\n",
    "                        d2,dr2,da2,r2,\n",
    "                        num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93993958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.2220 - loss: 2.4812 - val_accuracy: 0.2000 - val_loss: 1.6135\n",
      "Epoch 2/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2361 - loss: 1.8604 - val_accuracy: 0.2000 - val_loss: 1.6234\n",
      "Epoch 3/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3873 - loss: 1.5639 - val_accuracy: 0.2000 - val_loss: 1.6331\n",
      "Epoch 4/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4349 - loss: 1.3821 - val_accuracy: 0.2000 - val_loss: 1.6418\n",
      "Epoch 5/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5399 - loss: 1.2326 - val_accuracy: 0.2000 - val_loss: 1.6504\n",
      "Epoch 6/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4808 - loss: 1.2809 - val_accuracy: 0.2000 - val_loss: 1.6562\n",
      "Epoch 7/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5702 - loss: 1.0971 - val_accuracy: 0.2000 - val_loss: 1.6588\n",
      "Epoch 8/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6229 - loss: 1.0266 - val_accuracy: 0.2222 - val_loss: 1.6617\n",
      "Epoch 9/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5644 - loss: 1.1257 - val_accuracy: 0.2556 - val_loss: 1.6662\n",
      "Epoch 10/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6496 - loss: 0.9774 - val_accuracy: 0.3000 - val_loss: 1.6641\n",
      "Epoch 11/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6967 - loss: 0.9252 - val_accuracy: 0.3556 - val_loss: 1.6529\n",
      "Epoch 12/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6745 - loss: 0.9037 - val_accuracy: 0.3778 - val_loss: 1.6362\n",
      "Epoch 13/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6711 - loss: 0.8768 - val_accuracy: 0.3667 - val_loss: 1.6067\n",
      "Epoch 14/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6761 - loss: 0.8817 - val_accuracy: 0.3556 - val_loss: 1.5750\n",
      "Epoch 15/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7200 - loss: 0.8020 - val_accuracy: 0.3556 - val_loss: 1.5313\n",
      "Epoch 16/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7213 - loss: 0.7829 - val_accuracy: 0.3778 - val_loss: 1.4762\n",
      "Epoch 17/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7454 - loss: 0.7252 - val_accuracy: 0.3778 - val_loss: 1.4322\n",
      "Epoch 18/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7297 - loss: 0.7241 - val_accuracy: 0.3889 - val_loss: 1.3793\n",
      "Epoch 19/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7745 - loss: 0.6269 - val_accuracy: 0.4333 - val_loss: 1.3341\n",
      "Epoch 20/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7820 - loss: 0.6488 - val_accuracy: 0.4667 - val_loss: 1.2928\n",
      "Epoch 21/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.6426 - val_accuracy: 0.4889 - val_loss: 1.2480\n",
      "Epoch 22/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7201 - loss: 0.7096 - val_accuracy: 0.4778 - val_loss: 1.1997\n",
      "Epoch 23/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.5839 - val_accuracy: 0.4889 - val_loss: 1.1625\n",
      "Epoch 24/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.5616 - val_accuracy: 0.5111 - val_loss: 1.1408\n",
      "Epoch 25/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7488 - loss: 0.6544 - val_accuracy: 0.5222 - val_loss: 1.1204\n",
      "Epoch 26/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7736 - loss: 0.6173 - val_accuracy: 0.5333 - val_loss: 1.0988\n",
      "Epoch 27/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.5797 - val_accuracy: 0.5333 - val_loss: 1.1064\n",
      "Epoch 28/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8636 - loss: 0.4507 - val_accuracy: 0.5444 - val_loss: 1.0855\n",
      "Epoch 29/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 0.5103 - val_accuracy: 0.5556 - val_loss: 1.0742\n",
      "Epoch 30/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8542 - loss: 0.4480 - val_accuracy: 0.5556 - val_loss: 1.0649\n",
      "Epoch 31/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 0.4701 - val_accuracy: 0.5667 - val_loss: 1.0882\n",
      "Epoch 32/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.4669 - val_accuracy: 0.5667 - val_loss: 1.0633\n",
      "Epoch 33/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8680 - loss: 0.4647 - val_accuracy: 0.5556 - val_loss: 1.0655\n",
      "Epoch 34/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.4671 - val_accuracy: 0.5556 - val_loss: 1.0692\n",
      "Epoch 35/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9026 - loss: 0.3505 - val_accuracy: 0.5444 - val_loss: 1.0567\n",
      "Epoch 36/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8875 - loss: 0.4003 - val_accuracy: 0.5444 - val_loss: 1.0677\n",
      "Epoch 37/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8671 - loss: 0.4284 - val_accuracy: 0.5222 - val_loss: 1.1068\n",
      "Epoch 38/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8883 - loss: 0.3405 - val_accuracy: 0.5444 - val_loss: 1.0586\n",
      "Epoch 39/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8954 - loss: 0.3634 - val_accuracy: 0.5556 - val_loss: 1.0480\n",
      "Epoch 40/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9149 - loss: 0.2982 - val_accuracy: 0.5667 - val_loss: 1.0422\n",
      "Epoch 41/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8962 - loss: 0.3474 - val_accuracy: 0.5778 - val_loss: 1.0401\n",
      "Epoch 42/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9181 - loss: 0.3152 - val_accuracy: 0.5778 - val_loss: 1.0629\n",
      "Epoch 43/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8893 - loss: 0.3225 - val_accuracy: 0.5556 - val_loss: 1.1102\n",
      "Epoch 44/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8909 - loss: 0.3240 - val_accuracy: 0.5778 - val_loss: 1.0631\n",
      "Epoch 45/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8992 - loss: 0.3571 - val_accuracy: 0.5778 - val_loss: 1.1263\n",
      "Epoch 46/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9013 - loss: 0.3087 - val_accuracy: 0.5667 - val_loss: 1.1331\n",
      "Epoch 47/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8997 - loss: 0.3542 - val_accuracy: 0.5556 - val_loss: 1.1582\n",
      "Epoch 48/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9222 - loss: 0.2317 - val_accuracy: 0.5444 - val_loss: 1.1429\n",
      "Epoch 49/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9231 - loss: 0.2482 - val_accuracy: 0.5667 - val_loss: 1.1596\n",
      "Epoch 50/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8996 - loss: 0.2990 - val_accuracy: 0.5667 - val_loss: 1.1351\n",
      "Epoch 51/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8993 - loss: 0.2746 - val_accuracy: 0.5556 - val_loss: 1.1840\n",
      "Epoch 52/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.2426 - val_accuracy: 0.5667 - val_loss: 1.1479\n",
      "Epoch 53/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.2437 - val_accuracy: 0.5556 - val_loss: 1.1937\n",
      "Epoch 54/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9004 - loss: 0.3160 - val_accuracy: 0.5667 - val_loss: 1.1627\n",
      "Epoch 55/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9413 - loss: 0.2066 - val_accuracy: 0.5778 - val_loss: 1.1552\n",
      "Epoch 56/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.1996 - val_accuracy: 0.5778 - val_loss: 1.1825\n",
      "Epoch 57/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9259 - loss: 0.2602 - val_accuracy: 0.5556 - val_loss: 1.1375\n",
      "Epoch 58/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9675 - loss: 0.1884 - val_accuracy: 0.5667 - val_loss: 1.1026\n",
      "Epoch 59/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9384 - loss: 0.2295 - val_accuracy: 0.5889 - val_loss: 1.1242\n",
      "Epoch 60/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.1964 - val_accuracy: 0.6111 - val_loss: 1.1284\n",
      "Epoch 61/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9651 - loss: 0.1667 - val_accuracy: 0.6000 - val_loss: 1.2088\n",
      "Epoch 62/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9595 - loss: 0.2014 - val_accuracy: 0.6000 - val_loss: 1.1618\n",
      "Epoch 63/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9524 - loss: 0.1750 - val_accuracy: 0.5778 - val_loss: 1.1737\n",
      "Epoch 64/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9628 - loss: 0.1479 - val_accuracy: 0.5778 - val_loss: 1.2185\n",
      "Epoch 65/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.1521 - val_accuracy: 0.5778 - val_loss: 1.2012\n",
      "Epoch 66/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.1646 - val_accuracy: 0.6111 - val_loss: 1.1399\n",
      "Epoch 67/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1398 - val_accuracy: 0.6111 - val_loss: 1.1419\n",
      "Epoch 68/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9545 - loss: 0.1721 - val_accuracy: 0.5889 - val_loss: 1.1830\n",
      "Epoch 69/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1296 - val_accuracy: 0.5889 - val_loss: 1.2214\n",
      "Epoch 70/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9413 - loss: 0.1907 - val_accuracy: 0.6000 - val_loss: 1.1952\n",
      "Epoch 71/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9252 - loss: 0.2146 - val_accuracy: 0.6111 - val_loss: 1.1721\n",
      "Epoch 72/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9623 - loss: 0.1351 - val_accuracy: 0.6444 - val_loss: 1.1783\n",
      "Epoch 73/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.1144 - val_accuracy: 0.6333 - val_loss: 1.2176\n",
      "Epoch 74/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9563 - loss: 0.1190 - val_accuracy: 0.6333 - val_loss: 1.2088\n",
      "Epoch 75/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.1625 - val_accuracy: 0.6444 - val_loss: 1.2078\n",
      "Epoch 76/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9351 - loss: 0.1398 - val_accuracy: 0.6333 - val_loss: 1.2150\n",
      "Epoch 77/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9698 - loss: 0.1336 - val_accuracy: 0.6333 - val_loss: 1.2204\n",
      "Epoch 78/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9732 - loss: 0.1054 - val_accuracy: 0.6333 - val_loss: 1.2457\n",
      "Epoch 79/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9642 - loss: 0.1251 - val_accuracy: 0.6222 - val_loss: 1.2517\n",
      "Epoch 80/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9701 - loss: 0.1188 - val_accuracy: 0.6222 - val_loss: 1.2604\n"
     ]
    }
   ],
   "source": [
    "history15 = model15.fit(X2_train_scaled_4, y2_train, \n",
    "                    validation_data=(X2_val_scaled_4, y2_val), \n",
    "                    batch_size=16, epochs=80)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7010ec1e",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "### 4.1 Model Evaluation For Dataset1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17665928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train and Validation accuracy and loss\n",
    "f = plt.figure(figsize = (12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('train validation accuracy')\n",
    "plt.plot(history11.history['accuracy'])\n",
    "plt.plot(history11.history['val_accuracy'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.title('train validation loss')\n",
    "# plt.plot(history1.history['loss'])\n",
    "# plt.plot(history1.history['val_loss'])\n",
    "# plt.legend(['train','validation'])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb3bc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m model1\u001b[38;5;241m.\u001b[39mpredict(X1_test_scaled)\n\u001b[0;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_prob, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "y_prob = model1.predict(X1_test_scaled)\n",
    "y_pred = np.argmax(y_prob, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f7d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acc_1d = round(accuracy_score(y_pred,y1_test),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66767ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_1d = confusion_matrix(y1_test,y_pred)\n",
    "cm_display_1d = ConfusionMatrixDisplay(confusion_matrix = cm_1d, display_labels = ['Angry', 'Happy', 'Relaxed', 'Sad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dac2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y1_test, y_pred, target_names = ['Angry', 'Happy', 'Relaxed', 'Sad']))\n",
    "cm_display_1d.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b5cae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train and Validation accuracy and loss\n",
    "f = plt.figure(figsize = (12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('train validation accuracy')\n",
    "plt.plot(history11.history['accuracy'])\n",
    "plt.plot(history11.history['val_accuracy'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('train validation loss')\n",
    "plt.plot(history11.history['loss'])\n",
    "plt.plot(history11.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model11.predict(X2_test_scaled)\n",
    "y_pred = np.argmax(y_prob, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acc_1d = round(accuracy_score(y_pred,y2_test),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470773d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_1d = confusion_matrix(y2_test,y_pred)\n",
    "cm_display_1d = ConfusionMatrixDisplay(confusion_matrix = cm_1d, display_labels = ['Angry', 'Happy', 'Relaxed', 'Sad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25642c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model11.save('Features1D/Model/Conv1D.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f32ad08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y2_test, y_pred, target_names = ['Angry', 'Happy', 'Relaxed', 'Sad']))\n",
    "cm_display_1d.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0531d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
